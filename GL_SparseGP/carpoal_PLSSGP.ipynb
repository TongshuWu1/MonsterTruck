{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T14:38:26.918208Z",
     "start_time": "2026-02-12T14:38:23.345233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 1 — Imports + Custom Env (Continuous CartPole Swing-Up) + EDGE RESPAWN\n",
    "# + TensorFlow GPU setup (for GPflow/TF compute)\n",
    "# ============================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"pkg_resources is deprecated as an API.*\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from gymnasium.utils import seeding\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TensorFlow GPU setup (THIS is what makes TF/GPflow use GPU)\n",
    "# ============================================================\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # quieter TF logs (optional)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    # Prevent TF from grabbing all VRAM at startup\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"✅ TF version:\", tf.__version__)\n",
    "    print(\"✅ Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "    print(\"✅ GPUs:\", gpus)\n",
    "else:\n",
    "    print(\"⚠️ TF version:\", tf.__version__)\n",
    "    print(\"⚠️ Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "    print(\"⚠️ GPUs: [] (TensorFlow will run on CPU)\")\n",
    "\n",
    "# ============================================================\n",
    "# Dtypes for GPU-friendly pipeline\n",
    "# ============================================================\n",
    "# Env can stay float32; GP features should also be float32 to avoid slow casts.\n",
    "DTYPE_NP = np.float32\n",
    "\n",
    "# ============================================================\n",
    "# Angle helpers\n",
    "# ============================================================\n",
    "def wrap_pi(x):\n",
    "    return (x + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "def obs_to_state(obs):\n",
    "    \"\"\"\n",
    "    obs = [x, x_dot, theta, theta_dot]\n",
    "    Wrap theta to (-pi, pi] for stability.\n",
    "    \"\"\"\n",
    "    x, xdot, th, thdot = float(obs[0]), float(obs[1]), float(obs[2]), float(obs[3])\n",
    "    th = wrap_pi(th)\n",
    "    return x, xdot, th, thdot\n",
    "\n",
    "U_MIN, U_MAX = -1.0, 1.0\n",
    "\n",
    "def state_to_features(x, xdot, theta, thetadot, u,\n",
    "                      x_scale=2.4, v_scale=3.0, w_scale=8.0,\n",
    "                      dtype=DTYPE_NP):\n",
    "    \"\"\"\n",
    "    GP features (D=6), bounded:\n",
    "        [ tanh(x/x_scale),\n",
    "          tanh(xdot/v_scale),\n",
    "          sin(theta),\n",
    "          cos(theta),\n",
    "          tanh(thetadot/w_scale),\n",
    "          u ]\n",
    "    Returns float32 by default (GPU-friendly).\n",
    "    \"\"\"\n",
    "    x_feat = np.tanh(x / x_scale)\n",
    "    xdot_feat = np.tanh(xdot / v_scale)\n",
    "    w_feat = np.tanh(thetadot / w_scale)\n",
    "    return np.array(\n",
    "        [x_feat, xdot_feat, np.sin(theta), np.cos(theta), w_feat, float(u)],\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Custom Continuous CartPole Swing-Up Env (CPU physics; that's OK)\n",
    "# ============================================================\n",
    "class ContinuousCartPoleSwingUpEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"rgb_array\", \"human\"], \"render_fps\": 50}\n",
    "\n",
    "    def __init__(self, render_mode=None, start_down=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # physics\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "\n",
    "        # control\n",
    "        self.force_mag = 30.0\n",
    "        self.tau = 0.02\n",
    "        self.min_action = -1.0\n",
    "        self.max_action = 1.0\n",
    "\n",
    "        # track limits\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # reset mode\n",
    "        self.start_down = bool(start_down)\n",
    "\n",
    "        # render\n",
    "        self.render_mode = render_mode\n",
    "        self.state = None\n",
    "        self.np_random = None\n",
    "        self.seed()\n",
    "\n",
    "        # spaces\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.x_threshold * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "                np.finfo(np.float32).max,\n",
    "                np.finfo(np.float32).max,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([self.min_action], dtype=np.float32),\n",
    "            high=np.array([self.max_action], dtype=np.float32),\n",
    "            shape=(1,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def stepPhysics(self, force):\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta * costheta / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        x = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * xacc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * thetaacc\n",
    "        return (x, x_dot, theta, theta_dot)\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.asarray(action, dtype=np.float32).reshape(1,)\n",
    "        assert self.action_space.contains(action), f\"{action} invalid\"\n",
    "\n",
    "        u = float(action[0])\n",
    "        force = self.force_mag * u\n",
    "\n",
    "        self.state = self.stepPhysics(force)\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "\n",
    "        terminated = bool(x < -self.x_threshold or x > self.x_threshold)\n",
    "        truncated = False  # TimeLimit handles truncation\n",
    "\n",
    "        reward = (\n",
    "            +1.0 * math.cos(theta)\n",
    "            -0.01 * (x * x)\n",
    "            -0.001 * (x_dot * x_dot)\n",
    "            -0.001 * (theta_dot * theta_dot)\n",
    "            -0.001 * (u * u)\n",
    "        )\n",
    "\n",
    "        obs = np.array([x, x_dot, theta, theta_dot], dtype=np.float32)\n",
    "        info = dict(x=x, x_dot=x_dot, theta=theta, theta_dot=theta_dot, u=u)\n",
    "        return obs, float(reward), terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "\n",
    "        x = float(self.np_random.uniform(low=-0.05, high=0.05))\n",
    "        x_dot = float(self.np_random.uniform(low=-0.05, high=0.05))\n",
    "        theta_dot = float(self.np_random.uniform(low=-0.05, high=0.05))\n",
    "\n",
    "        if self.start_down:\n",
    "            theta = float(math.pi + self.np_random.uniform(low=-0.10, high=0.10))\n",
    "        else:\n",
    "            theta = float(self.np_random.uniform(low=-0.10, high=0.10))\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "        obs = np.array(self.state, dtype=np.float32)\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def render(self):\n",
    "        return None\n",
    "\n",
    "    def close(self):\n",
    "        return None\n",
    "\n",
    "class EdgeRespawnWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Continuous stream: if out-of-bounds, we reset immediately but:\n",
    "      - info[\"terminal_obs\"] stores the TRUE next_obs (physics) at the boundary\n",
    "      - info[\"reset_obs\"] stores the post-reset obs used for continuing control\n",
    "      - returned obs is reset_obs\n",
    "      - terminated is forced False so the outer loop doesn't end\n",
    "    \"\"\"\n",
    "    def __init__(self, env, respawn_penalty=-2.0, reset_seed_mode=\"random\", seed=0):\n",
    "        super().__init__(env)\n",
    "        self.respawn_penalty = float(respawn_penalty)\n",
    "        self.reset_seed_mode = str(reset_seed_mode)\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            self._rng = np.random.default_rng(seed)\n",
    "        return self.env.reset(seed=seed, options=options)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs_next, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        if terminated:\n",
    "            info = dict(info)\n",
    "            info[\"respawned\"] = True\n",
    "\n",
    "            # store TRUE physics next_obs for training\n",
    "            info[\"terminal_obs\"] = np.array(obs_next, copy=True)\n",
    "\n",
    "            reward = float(reward) + self.respawn_penalty\n",
    "\n",
    "            seed = int(self._rng.integers(0, 10**9)) if self.reset_seed_mode == \"random\" else None\n",
    "            obs_reset, _ = self.env.reset(seed=seed)\n",
    "\n",
    "            info[\"reset_obs\"] = np.array(obs_reset, copy=True)\n",
    "\n",
    "            # continue control from reset obs\n",
    "            obs_next = obs_reset\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "\n",
    "        return obs_next, float(reward), bool(terminated), bool(truncated), info\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Environment factory\n",
    "# ============================================================\n",
    "MAX_EPISODE_STEPS = 600\n",
    "\n",
    "def make_env(\n",
    "    render_mode=None,\n",
    "    seed=0,\n",
    "    max_episode_steps=MAX_EPISODE_STEPS,\n",
    "    start_down=True,\n",
    "    edge_respawn=True,\n",
    "    respawn_penalty=-2.0,\n",
    "):\n",
    "    env = ContinuousCartPoleSwingUpEnv(render_mode=render_mode, start_down=start_down)\n",
    "    env = TimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "    if edge_respawn:\n",
    "        env = EdgeRespawnWrapper(env, respawn_penalty=respawn_penalty, seed=seed)\n",
    "    env.reset(seed=seed)\n",
    "    return env\n",
    "\n",
    "# ============================================================\n",
    "# Sanity check\n",
    "# ============================================================\n",
    "env = make_env(render_mode=None, seed=0, start_down=True, edge_respawn=True)\n",
    "obs, _ = env.reset(seed=0)\n",
    "s = obs_to_state(obs)\n",
    "\n",
    "print(\"✅ Env ready (edge_respawn=True)\")\n",
    "print(\"obs:\", obs)\n",
    "print(\"state:\", s)\n",
    "print(\"action space:\", env.action_space)\n",
    "env.close()\n"
   ],
   "id": "ff4c96c6db3948c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ TF version: 2.20.0\n",
      "⚠️ Built with CUDA: False\n",
      "⚠️ GPUs: [] (TensorFlow will run on CPU)\n",
      "✅ Env ready (edge_respawn=True)\n",
      "obs: [ 0.01369617 -0.02302133  3.0448983  -0.04590265]\n",
      "state: (0.013696168549358845, -0.023021329194307327, 3.044898271560669, -0.04590264707803726)\n",
      "action space: Box(-1.0, 1.0, (1,), float32)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-02-12T14:38:30.585608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 2 — Random data collection + PIL render (NO teleport training)\n",
    "#   ✅ Uses info[\"terminal_obs\"] when respawned=True (keeps real physics transition)\n",
    "#   ✅ Never trains on reset teleport\n",
    "#   ✅ Collects dataset in float64 (GP training friendly)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "NP_DTYPE = np.float64  # dataset dtype (GP side)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Pure-PIL renderer: (x, theta) -> RGB frame\n",
    "# ------------------------------------------------------------\n",
    "def render_cartpole_frame_from_state(\n",
    "    x, theta,\n",
    "    x_threshold=2.4,\n",
    "    W=720, H=450,\n",
    "    cart_width=70,\n",
    "    cart_height=35,\n",
    "    pole_length_px=180,\n",
    "    wheel_radius=12,\n",
    "):\n",
    "    img = Image.new(\"RGB\", (W, H), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    track_y = int(H * 0.70)\n",
    "    draw.line((int(W * 0.10), track_y, int(W * 0.90), track_y), fill=(40, 40, 40), width=4)\n",
    "\n",
    "    x = float(x)\n",
    "    x_clipped = max(-x_threshold, min(x_threshold, x))\n",
    "    t = (x_clipped + x_threshold) / (2.0 * x_threshold)\n",
    "    cart_x = int(W * 0.10 + t * (W * 0.80))\n",
    "    cart_y = track_y - cart_height // 2\n",
    "\n",
    "    x0 = cart_x - cart_width // 2\n",
    "    y0 = cart_y - cart_height // 2\n",
    "    x1 = cart_x + cart_width // 2\n",
    "    y1 = cart_y + cart_height // 2\n",
    "    draw.rectangle((x0, y0, x1, y1), fill=(120, 160, 230), outline=(0, 0, 0))\n",
    "\n",
    "    w1x = cart_x - int(cart_width * 0.25)\n",
    "    w2x = cart_x + int(cart_width * 0.25)\n",
    "    wy = track_y\n",
    "    for wx in [w1x, w2x]:\n",
    "        draw.ellipse((wx - wheel_radius, wy - wheel_radius, wx + wheel_radius, wy + wheel_radius),\n",
    "                     fill=(60, 60, 60), outline=(0, 0, 0))\n",
    "\n",
    "    theta = float(theta)\n",
    "    pivot_x = cart_x\n",
    "    pivot_y = y0  # cart top\n",
    "    tip_x = pivot_x + int(pole_length_px * np.sin(theta))\n",
    "    tip_y = pivot_y - int(pole_length_px * np.cos(theta))\n",
    "    draw.line((pivot_x, pivot_y, tip_x, tip_y), fill=(200, 60, 60), width=8)\n",
    "    draw.ellipse((pivot_x - 6, pivot_y - 6, pivot_x + 6, pivot_y + 6),\n",
    "                 fill=(0, 0, 0), outline=(0, 0, 0))\n",
    "\n",
    "    return np.array(img, dtype=np.uint8)\n",
    "\n",
    "def show_gif(frames_uint8, fps=20):\n",
    "    fig = plt.figure(figsize=(7.2, 4.5))\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames_uint8[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames_uint8[i])\n",
    "        return (im,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(frames_uint8), interval=1000 / fps)\n",
    "    plt.close(fig)\n",
    "    display(HTML(anim.to_jshtml()))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Random collection (keeps REAL terminal transition when respawned)\n",
    "# ------------------------------------------------------------\n",
    "def collect_random_dataset_with_render(\n",
    "    n_steps=1500,\n",
    "    seed=0,\n",
    "    resize=(720, 450),\n",
    "    fps=20,\n",
    "    edge_respawn=True,\n",
    "    respawn_penalty=-2.0,\n",
    "    verbose=False,\n",
    "):\n",
    "    env = make_env(\n",
    "        render_mode=None,\n",
    "        seed=seed,\n",
    "        start_down=True,\n",
    "        edge_respawn=edge_respawn,\n",
    "        respawn_penalty=respawn_penalty,\n",
    "    )\n",
    "\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    x, xdot, th, thdot = obs_to_state(obs)\n",
    "\n",
    "    frames = []\n",
    "    traj = {\n",
    "        \"x\": [], \"xdot\": [], \"theta\": [], \"thetadot\": [],\n",
    "        \"u\": [], \"reward\": [], \"respawned\": [],\n",
    "    }\n",
    "\n",
    "    X_list, ydx_list, ydxdot_list, ydth_list, ydthdot_list = [], [], [], [], []\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        u = float(env.action_space.sample()[0])\n",
    "\n",
    "        # frame from current state BEFORE stepping\n",
    "        frames.append(render_cartpole_frame_from_state(x, th, W=resize[0], H=resize[1]))\n",
    "\n",
    "        # step\n",
    "        obs2, r, terminated, truncated, info = env.step(np.array([u], dtype=np.float32))\n",
    "\n",
    "        respawned = bool(info.get(\"respawned\", False))\n",
    "\n",
    "        # use TRUE physics next_obs if respawned\n",
    "        if respawned and (\"terminal_obs\" in info):\n",
    "            obs2_for_training = info[\"terminal_obs\"]\n",
    "        else:\n",
    "            obs2_for_training = obs2\n",
    "\n",
    "        x2, xdot2, th2, thdot2 = obs_to_state(obs2_for_training)\n",
    "\n",
    "        # logs\n",
    "        traj[\"x\"].append(x); traj[\"xdot\"].append(xdot); traj[\"theta\"].append(th); traj[\"thetadot\"].append(thdot)\n",
    "        traj[\"u\"].append(u); traj[\"reward\"].append(float(r)); traj[\"respawned\"].append(respawned)\n",
    "\n",
    "        # ALWAYS add a valid transition (no teleports)\n",
    "        X = state_to_features(x, xdot, th, thdot, u, dtype=NP_DTYPE).astype(NP_DTYPE)\n",
    "        dx = float(x2 - x)\n",
    "        dxdot = float(xdot2 - xdot)\n",
    "        dth = float(wrap_pi(th2 - th))\n",
    "        dthdot = float(thdot2 - thdot)\n",
    "\n",
    "        X_list.append(X)\n",
    "        ydx_list.append([dx])\n",
    "        ydxdot_list.append([dxdot])\n",
    "        ydth_list.append([dth])\n",
    "        ydthdot_list.append([dthdot])\n",
    "\n",
    "        if verbose and (t % 200 == 0):\n",
    "            print(f\"[t={t}] respawned={respawned}  x={x:.2f} th={th:.2f} u={u:+.2f}\")\n",
    "\n",
    "        # advance CONTROL state using returned obs2 (which is reset_obs if respawned)\n",
    "        x, xdot, th, thdot = obs_to_state(obs2)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    X0 = np.asarray(X_list, dtype=NP_DTYPE)\n",
    "    Ydx0 = np.asarray(ydx_list, dtype=NP_DTYPE)\n",
    "    Ydxdot0 = np.asarray(ydxdot_list, dtype=NP_DTYPE)\n",
    "    Ydth0 = np.asarray(ydth_list, dtype=NP_DTYPE)\n",
    "    Ydthdot0 = np.asarray(ydthdot_list, dtype=NP_DTYPE)\n",
    "\n",
    "    return X0, Ydx0, Ydxdot0, Ydth0, Ydthdot0, frames, traj\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run data collection + visualize\n",
    "# ------------------------------------------------------------\n",
    "N_STEPS_RANDOM = 300\n",
    "SEED_RANDOM = 0\n",
    "FPS = 20\n",
    "RECORD_RGB = True\n",
    "\n",
    "X0, Ydx0, Ydxdot0, Ydth0, Ydthdot0, frames0, traj0 = collect_random_dataset_with_render(\n",
    "    n_steps=N_STEPS_RANDOM,\n",
    "    seed=SEED_RANDOM,\n",
    "    resize=(720, 450),\n",
    "    fps=FPS,\n",
    "    edge_respawn=True,\n",
    "    respawn_penalty=-2.0,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"✅ Random dataset collected (NO teleport training)\")\n",
    "print(\"X0:\", X0.shape)\n",
    "print(\"Ydx0:\", Ydx0.shape, \" Ydxdot0:\", Ydxdot0.shape, \" Ydth0:\", Ydth0.shape, \" Ydthdot0:\", Ydthdot0.shape)\n",
    "\n",
    "if RECORD_RGB:\n",
    "    show_gif(frames0, fps=FPS)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plots\n",
    "# ------------------------------------------------------------\n",
    "x_arr = np.array(traj0[\"x\"])\n",
    "xdot_arr = np.array(traj0[\"xdot\"])\n",
    "th_arr = np.array(traj0[\"theta\"])\n",
    "thdot_arr = np.array(traj0[\"thetadot\"])\n",
    "u_arr = np.array(traj0[\"u\"])\n",
    "rew_arr = np.array(traj0[\"reward\"])\n",
    "resp_arr = np.array(traj0[\"respawned\"])\n",
    "t = np.arange(len(x_arr)) * 0.02\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n",
    "axs[0].plot(t, x_arr); axs[0].set_ylabel(\"x\")\n",
    "axs[1].plot(t, xdot_arr); axs[1].set_ylabel(\"xdot\")\n",
    "axs[2].plot(t, th_arr); axs[2].set_ylabel(\"theta\")\n",
    "axs[3].plot(t, thdot_arr); axs[3].set_ylabel(\"thetadot\")\n",
    "axs[4].plot(t, u_arr); axs[4].set_ylabel(\"u\"); axs[4].set_xlabel(\"time (s)\")\n",
    "for ax in axs: ax.grid(True, alpha=0.25)\n",
    "fig.suptitle(\"Random rollout trajectories (terminal transitions kept, teleports excluded)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(x_arr, xdot_arr, linewidth=1.0)\n",
    "plt.scatter(x_arr[resp_arr], xdot_arr[resp_arr], s=18, label=\"respawned step\", alpha=0.8)\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"xdot\")\n",
    "plt.title(\"Phase plot: x vs xdot (random rollout)\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "8732720f3bfff952",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random dataset collected (NO teleport training)\n",
      "X0: (300, 6)\n",
      "Ydx0: (300, 1)  Ydxdot0: (300, 1)  Ydth0: (300, 1)  Ydthdot0: (300, 1)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 3 — Stable SVGP init (for later OSGPR streaming)\n",
    "# FIXES:\n",
    "#   ✅ Use float64 for GPflow (much more stable)\n",
    "#   ✅ Increase jitter\n",
    "#   ✅ Safer kernel initialization\n",
    "#   ✅ Smaller LR (avoid exploding nat params)\n",
    "#   ✅ Sanity checks for NaNs/Infs\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow.utilities import set_trainable\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Use float64 + bigger jitter (key fix)\n",
    "# ----------------------------\n",
    "gpflow.config.set_default_float(tf.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)     # try 1e-5 if still unstable\n",
    "GP_DTYPE = tf.float64\n",
    "\n",
    "DTYPE_NP = np.float64\n",
    "\n",
    "def assert_finite(name, arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if not np.all(np.isfinite(arr)):\n",
    "        bad = np.where(~np.isfinite(arr))\n",
    "        raise ValueError(f\"{name} has non-finite values at indices {bad}.\")\n",
    "\n",
    "assert_finite(\"X0\", X0)\n",
    "assert_finite(\"Ydx0\", Ydx0)\n",
    "assert_finite(\"Ydxdot0\", Ydxdot0)\n",
    "assert_finite(\"Ydth0\", Ydth0)\n",
    "assert_finite(\"Ydthdot0\", Ydthdot0)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) k-center inducing init (same as before, but float64)\n",
    "# ----------------------------\n",
    "def kcenter_greedy_indices(X, M, seed=0):\n",
    "    N = X.shape[0]\n",
    "    if M >= N:\n",
    "        return np.arange(N, dtype=np.int64)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first = int(rng.integers(0, N))\n",
    "    idx = [first]\n",
    "    d2 = np.sum((X - X[first:first+1])**2, axis=1)\n",
    "\n",
    "    for _ in range(1, M):\n",
    "        i = int(np.argmax(d2))\n",
    "        idx.append(i)\n",
    "        d2 = np.minimum(d2, np.sum((X - X[i:i+1])**2, axis=1))\n",
    "\n",
    "    return np.array(idx, dtype=np.int64)\n",
    "\n",
    "def init_global_inducing_points(X0, M_GLOBAL_MAX=256, method=\"kcenter\", seed=0):\n",
    "    X0 = np.asarray(X0, dtype=DTYPE_NP)\n",
    "    N0 = X0.shape[0]\n",
    "    M_GLOBAL = int(min(M_GLOBAL_MAX, N0))\n",
    "\n",
    "    if N0 <= M_GLOBAL_MAX:\n",
    "        idx = np.arange(N0, dtype=np.int64)\n",
    "        Z = X0.copy()\n",
    "    else:\n",
    "        if method == \"kcenter\":\n",
    "            idx = kcenter_greedy_indices(X0, M_GLOBAL, seed=seed)\n",
    "        elif method == \"random\":\n",
    "            rng = np.random.default_rng(seed)\n",
    "            idx = rng.choice(N0, size=M_GLOBAL, replace=False).astype(np.int64)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method={method}\")\n",
    "        Z = X0[idx].copy()\n",
    "\n",
    "    return M_GLOBAL, Z, idx\n",
    "\n",
    "M_GLOBAL_MAX = 256\n",
    "M_GLOBAL, Z_GLOBAL, Z_INIT_IDX = init_global_inducing_points(X0, M_GLOBAL_MAX=M_GLOBAL_MAX, method=\"kcenter\", seed=0)\n",
    "\n",
    "print(f\"✅ GLOBAL inducing init: N0={X0.shape[0]}  M_GLOBAL_MAX={M_GLOBAL_MAX}  ->  M_GLOBAL={M_GLOBAL}\")\n",
    "print(\"Z_GLOBAL shape:\", Z_GLOBAL.shape)\n",
    "print(\"Using ALL data as inducing?\", (X0.shape[0] <= M_GLOBAL_MAX))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Model creation (SVGP)\n",
    "#    Safer kernel init:\n",
    "#      - variance = 1.0\n",
    "#      - lengthscales = 0.5 (not too small/large)\n",
    "# ----------------------------\n",
    "def make_svgp_model(X, Y, Z_init, likelihood_var=1e-3):\n",
    "    X = tf.convert_to_tensor(np.asarray(X, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Y = tf.convert_to_tensor(np.asarray(Y, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Z = tf.convert_to_tensor(np.asarray(Z_init, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "\n",
    "    D = int(X.shape[1])\n",
    "\n",
    "    kernel = gpflow.kernels.SquaredExponential(\n",
    "        variance=tf.convert_to_tensor(1.0, dtype=GP_DTYPE),\n",
    "        lengthscales=tf.convert_to_tensor(np.ones(D) * 0.5, dtype=GP_DTYPE),\n",
    "    )\n",
    "\n",
    "    inducing = gpflow.inducing_variables.InducingPoints(Z)\n",
    "\n",
    "    m = gpflow.models.SVGP(\n",
    "        kernel=kernel,\n",
    "        likelihood=gpflow.likelihoods.Gaussian(variance=tf.convert_to_tensor(likelihood_var, dtype=GP_DTYPE)),\n",
    "        inducing_variable=inducing,\n",
    "        num_latent_gps=1,\n",
    "        whiten=True,\n",
    "    )\n",
    "    return m\n",
    "\n",
    "m_dx     = make_svgp_model(X0, Ydx0,     Z_GLOBAL, likelihood_var=1e-3)\n",
    "m_dxdot  = make_svgp_model(X0, Ydxdot0,  Z_GLOBAL, likelihood_var=1e-3)\n",
    "m_dth    = make_svgp_model(X0, Ydth0,    Z_GLOBAL, likelihood_var=1e-3)\n",
    "m_dthdot = make_svgp_model(X0, Ydthdot0, Z_GLOBAL, likelihood_var=1e-3)\n",
    "\n",
    "# keep likelihood variance fixed (stable)\n",
    "set_trainable(m_dx.likelihood.variance, False)\n",
    "set_trainable(m_dxdot.likelihood.variance, False)\n",
    "set_trainable(m_dth.likelihood.variance, False)\n",
    "set_trainable(m_dthdot.likelihood.variance, False)\n",
    "\n",
    "print(\"✅ Built initial sparse models (SVGP) for: Δx, Δxdot, Δθ, Δθdot\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Stable training loop\n",
    "#    - smaller LR\n",
    "#    - stop early if NaN appears\n",
    "# ----------------------------\n",
    "def train_svgp(model, X, Y, iters=400, lr=0.005, verbose=True):\n",
    "    X = tf.convert_to_tensor(np.asarray(X, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Y = tf.convert_to_tensor(np.asarray(Y, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "\n",
    "    opt = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.elbo((X, Y))\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    for k in range(iters):\n",
    "        loss = step()\n",
    "        if tf.math.is_nan(loss) or tf.math.is_inf(loss):\n",
    "            raise FloatingPointError(f\"SVGP training diverged at iter {k}: loss={loss.numpy()}\")\n",
    "        if verbose and (k % 50 == 0 or k == iters - 1):\n",
    "            tf.print(\"iter\", k, \"loss\", loss)\n",
    "\n",
    "INIT_ITERS = 400\n",
    "INIT_LR = 0.005\n",
    "\n",
    "train_svgp(m_dx,     X0, Ydx0,     iters=INIT_ITERS, lr=INIT_LR, verbose=True)\n",
    "train_svgp(m_dxdot,  X0, Ydxdot0,  iters=INIT_ITERS, lr=INIT_LR, verbose=True)\n",
    "train_svgp(m_dth,    X0, Ydth0,    iters=INIT_ITERS, lr=INIT_LR, verbose=True)\n",
    "train_svgp(m_dthdot, X0, Ydthdot0, iters=INIT_ITERS, lr=INIT_LR, verbose=True)\n",
    "\n",
    "print(\"✅ Initial training complete (stable float64)\")\n"
   ],
   "id": "fb459217c42595bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 4 — (float64) Evaluate GLOBAL models + SAME plots as your original code\n",
    "#   ✅ Test RMSE (global models)\n",
    "#   ✅ Slice: sweep x, compare u=+1/-1, show mean ±2σ + training points + inducing marks\n",
    "#   ✅ Surface: mean over (x, xdot) colored by std (+ inducing)\n",
    "#   ❌ No std-only surface\n",
    "#\n",
    "# Assumes from Cell 3:\n",
    "#   - gpflow default float is tf.float64\n",
    "#   - X0, Ydx0, ... exist (we'll cast to float64 here safely)\n",
    "#   - m_dx, m_dxdot, m_dth, m_dthdot exist\n",
    "#   - Z_GLOBAL is fixed in inducing variables\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Ensure float64 copies of datasets (safe, doesn't change originals)\n",
    "# ------------------------------------------------------------\n",
    "X0_64      = np.asarray(X0,      dtype=np.float64)\n",
    "Ydx0_64    = np.asarray(Ydx0,    dtype=np.float64)\n",
    "Ydxdot0_64 = np.asarray(Ydxdot0, dtype=np.float64)\n",
    "Ydth0_64   = np.asarray(Ydth0,   dtype=np.float64)\n",
    "Ydthdot0_64= np.asarray(Ydthdot0,dtype=np.float64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Make train/test split if not already defined (same spirit as original)\n",
    "# ------------------------------------------------------------\n",
    "def _ensure_split_from_X0(test_frac=0.2, seed=0):\n",
    "    global Xtr, Xte, Ydx_tr, Ydx_te, Ydxdot_tr, Ydxdot_te, Ydth_tr, Ydth_te, Ydthdot_tr, Ydthdot_te\n",
    "    if \"Xtr\" in globals() and \"Xte\" in globals():\n",
    "        return\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = X0_64.shape[0]\n",
    "    perm = rng.permutation(N)\n",
    "    n_te = int(test_frac * N)\n",
    "    te = perm[:n_te]\n",
    "    tr = perm[n_te:]\n",
    "\n",
    "    Xtr = X0_64[tr]\n",
    "    Xte = X0_64[te]\n",
    "\n",
    "    Ydx_tr, Ydx_te         = Ydx0_64[tr],     Ydx0_64[te]\n",
    "    Ydxdot_tr, Ydxdot_te   = Ydxdot0_64[tr],  Ydxdot0_64[te]\n",
    "    Ydth_tr, Ydth_te       = Ydth0_64[tr],    Ydth0_64[te]\n",
    "    Ydthdot_tr, Ydthdot_te = Ydthdot0_64[tr], Ydthdot0_64[te]\n",
    "\n",
    "_ensure_split_from_X0(test_frac=0.2, seed=0)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Fast predict mean/std (keeps your \"cached predictor\" pattern if available)\n",
    "# ------------------------------------------------------------\n",
    "def gp_predict_mu_std_fast(model, X):\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    if hasattr(model, \"predict_f_cached\"):\n",
    "        mu_tf, var_tf = model.predict_f_cached(X, full_cov=False)\n",
    "    else:\n",
    "        mu_tf, var_tf = model.predict_f(X, full_cov=False)\n",
    "    mu = mu_tf.numpy().reshape(-1)\n",
    "    var = var_tf.numpy().reshape(-1)\n",
    "    std = np.sqrt(np.maximum(var, 1e-12))\n",
    "    return mu, std\n",
    "\n",
    "def get_inducing_Z_np(model):\n",
    "    return model.inducing_variable.Z.numpy().astype(np.float64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Metrics\n",
    "# ------------------------------------------------------------\n",
    "def rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def print_global_rmse():\n",
    "    mu_dx, _     = gp_predict_mu_std_fast(m_dx,     Xte)\n",
    "    mu_dxdot, _  = gp_predict_mu_std_fast(m_dxdot,  Xte)\n",
    "    mu_dth, _    = gp_predict_mu_std_fast(m_dth,    Xte)\n",
    "    mu_dthdot, _ = gp_predict_mu_std_fast(m_dthdot, Xte)\n",
    "\n",
    "    print(\"=== Test RMSE (global models) ===\")\n",
    "    print(f\"dx        RMSE: {rmse_np(mu_dx,     Ydx_te):.6f}\")\n",
    "    print(f\"dxdot     RMSE: {rmse_np(mu_dxdot,  Ydxdot_te):.6f}\")\n",
    "    print(f\"dtheta    RMSE: {rmse_np(mu_dth,    Ydth_te):.6f}\")\n",
    "    print(f\"dthetadot RMSE: {rmse_np(mu_dthdot, Ydthdot_te):.6f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Slice plot: sweep physical x, compare u=+1/-1, mean ± 2σ + data + inducing\n",
    "# ------------------------------------------------------------\n",
    "def plot_slice_x_two_actions_cartpole(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    title=\"Slice\",\n",
    "    y_label=\"Δy\",\n",
    "    xdot_fixed=0.0,\n",
    "    theta_fixed=0.0,\n",
    "    thetadot_fixed=0.0,\n",
    "    x_min=-2.4, x_max=2.4,\n",
    "    n_grid=260,\n",
    "    u_list=(+1.0, -1.0),\n",
    "    y_min=None, y_max=None,\n",
    "    x_tick_step=0.6,\n",
    "    y_tick_step=None,\n",
    "    show_data=True,\n",
    "    show_inducing=True,\n",
    "    tol_xdot_feat=0.12,\n",
    "    tol_theta=0.25,\n",
    "    tol_w_feat=0.12,\n",
    "    tol_u=0.10,\n",
    "):\n",
    "    x_grid = np.linspace(x_min, x_max, n_grid, dtype=np.float64)\n",
    "    Z = get_inducing_Z_np(model)\n",
    "\n",
    "    curves = []\n",
    "    auto_ymin, auto_ymax = +np.inf, -np.inf\n",
    "\n",
    "    for u_fixed in u_list:\n",
    "        X_query = np.vstack([\n",
    "            state_to_features(float(x), float(xdot_fixed), float(theta_fixed), float(thetadot_fixed), float(u_fixed)).astype(np.float64)\n",
    "            for x in x_grid\n",
    "        ])\n",
    "        mu, std = gp_predict_mu_std_fast(model, X_query)\n",
    "        lo, hi = mu - 2 * std, mu + 2 * std\n",
    "        curves.append((u_fixed, mu, lo, hi))\n",
    "        auto_ymin = min(auto_ymin, float(lo.min()))\n",
    "        auto_ymax = max(auto_ymax, float(hi.max()))\n",
    "\n",
    "    if y_min is None: y_min = auto_ymin\n",
    "    if y_max is None: y_max = auto_ymax\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    X_train = np.asarray(X_train, dtype=np.float64)\n",
    "    y_train = np.asarray(y_train, dtype=np.float64).reshape(-1)\n",
    "\n",
    "    # fixed features for filtering \"near slice\"\n",
    "    xdot_feat0 = np.tanh(float(xdot_fixed) / 3.0)\n",
    "    w_feat0    = np.tanh(float(thetadot_fixed) / 8.0)\n",
    "\n",
    "    if show_data:\n",
    "        th_train = np.arctan2(X_train[:, 2], X_train[:, 3])\n",
    "        mask_data = (\n",
    "            (np.abs(X_train[:, 1] - xdot_feat0) < tol_xdot_feat) &\n",
    "            (np.abs(wrap_pi(th_train - float(theta_fixed))) < tol_theta) &\n",
    "            (np.abs(X_train[:, 4] - w_feat0) < tol_w_feat)\n",
    "        )\n",
    "        if np.any(mask_data):\n",
    "            x_feat = X_train[mask_data, 0]\n",
    "            x_phys = 2.4 * np.arctanh(np.clip(x_feat, -0.999999, 0.999999))\n",
    "            plt.scatter(x_phys, y_train[mask_data], s=10, alpha=0.35, label=\"train (near slice)\")\n",
    "\n",
    "    for u_fixed, mu, lo, hi in curves:\n",
    "        plt.plot(x_grid, mu, linewidth=2, label=f\"u={u_fixed:+.1f}\")\n",
    "        plt.fill_between(x_grid, lo, hi, alpha=0.18)\n",
    "\n",
    "    if show_inducing:\n",
    "        thZ = np.arctan2(Z[:, 2], Z[:, 3])\n",
    "        maskZ_base = (\n",
    "            (np.abs(Z[:, 1] - xdot_feat0) < tol_xdot_feat) &\n",
    "            (np.abs(wrap_pi(thZ - float(theta_fixed))) < tol_theta) &\n",
    "            (np.abs(Z[:, 4] - w_feat0) < tol_w_feat)\n",
    "        )\n",
    "        # mark inducing at top edge\n",
    "        for u_fixed, *_ in curves:\n",
    "            maskZ = maskZ_base & (np.abs(Z[:, 5] - float(u_fixed)) < tol_u)\n",
    "            if np.any(maskZ):\n",
    "                x_feat = Z[maskZ, 0]\n",
    "                x_phys = 2.4 * np.arctanh(np.clip(x_feat, -0.999999, 0.999999))\n",
    "                plt.scatter(x_phys, np.full_like(x_phys, y_max), s=18, marker=\"x\",\n",
    "                            label=f\"Z (u={u_fixed:+.1f})\", alpha=0.85)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([y_min, y_max])\n",
    "    plt.grid(True, alpha=0.25)\n",
    "\n",
    "    xticks = np.arange(np.ceil(x_min / x_tick_step) * x_tick_step, x_max + 1e-9, x_tick_step)\n",
    "    plt.xticks(xticks)\n",
    "    if y_tick_step is not None:\n",
    "        yticks = np.arange(np.ceil(y_min / y_tick_step) * y_tick_step, y_max + 1e-9, y_tick_step)\n",
    "        plt.yticks(yticks)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Surface: mean over (x, xdot) colored by std (+ inducing)\n",
    "#    (Same as original; no std-only surface)\n",
    "# ------------------------------------------------------------\n",
    "def plot_surface_x_xdot_mean_colored_by_std(\n",
    "    model,\n",
    "    title=\"3D Surface (interactive)\",\n",
    "    z_label=\"Δy\",\n",
    "    theta_fixed=0.0,\n",
    "    thetadot_fixed=0.0,\n",
    "    u_fixed=+1.0,\n",
    "    x_min=-2.4, x_max=2.4,\n",
    "    xdot_min=-3.0, xdot_max=3.0,\n",
    "    n_grid=70,\n",
    "    show_inducing=True,\n",
    "    tol_theta=0.25,\n",
    "    tol_w_feat=0.12,\n",
    "    tol_u=0.10,\n",
    "):\n",
    "    x_grid = np.linspace(x_min, x_max, n_grid, dtype=np.float64)\n",
    "    xd_grid = np.linspace(xdot_min, xdot_max, n_grid, dtype=np.float64)\n",
    "    X, XD = np.meshgrid(x_grid, xd_grid)\n",
    "\n",
    "    X_feat = np.vstack([\n",
    "        state_to_features(float(x), float(xdot), float(theta_fixed), float(thetadot_fixed), float(u_fixed)).astype(np.float64)\n",
    "        for x, xdot in zip(X.ravel(), XD.ravel())\n",
    "    ])\n",
    "\n",
    "    mu, std = gp_predict_mu_std_fast(model, X_feat)\n",
    "    Mean = mu.reshape(X.shape)\n",
    "    Std  = std.reshape(X.shape)\n",
    "\n",
    "    surface = go.Surface(\n",
    "        x=X, y=XD, z=Mean,\n",
    "        surfacecolor=Std,              # color by std\n",
    "        colorscale=\"Viridis\",\n",
    "        colorbar=dict(title=\"Std\"),\n",
    "        opacity=0.95,\n",
    "        showscale=True,\n",
    "        name=\"surface\",\n",
    "    )\n",
    "    traces = [surface]\n",
    "\n",
    "    if show_inducing:\n",
    "        Z = get_inducing_Z_np(model)\n",
    "        thZ = np.arctan2(Z[:, 2], Z[:, 3])\n",
    "        w_feat0 = np.tanh(float(thetadot_fixed) / 8.0)\n",
    "\n",
    "        maskZ = (\n",
    "            (np.abs(wrap_pi(thZ - float(theta_fixed))) < tol_theta) &\n",
    "            (np.abs(Z[:, 4] - w_feat0) < tol_w_feat) &\n",
    "            (np.abs(Z[:, 5] - float(u_fixed)) < tol_u)\n",
    "        )\n",
    "\n",
    "        if np.any(maskZ):\n",
    "            Zm = Z[maskZ]\n",
    "            x_phys    = 2.4 * np.arctanh(np.clip(Zm[:, 0], -0.999999, 0.999999))\n",
    "            xdot_phys = 3.0 * np.arctanh(np.clip(Zm[:, 1], -0.999999, 0.999999))\n",
    "\n",
    "            traces.append(\n",
    "                go.Scatter3d(\n",
    "                    x=x_phys, y=xdot_phys, z=np.full_like(x_phys, float(np.nanmax(Mean))),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=3.5),\n",
    "                    name=\"inducing (filtered)\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=f\"{title} | fixed u={float(u_fixed):+.1f}, theta={float(theta_fixed):.2f}, thetadot={float(thetadot_fixed):.2f}\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"x\", range=[x_min, x_max]),\n",
    "            yaxis=dict(title=\"xdot\", range=[xdot_min, xdot_max]),\n",
    "            zaxis=dict(title=z_label),\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=50),\n",
    "        height=650,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) One-call eval bundle (use dxdot by default, like your original)\n",
    "# ------------------------------------------------------------\n",
    "def eval_and_plot_global(tag=\"GLOBAL\", model_for_plots=None,\n",
    "                         theta_fixed=0.0, thetadot_fixed=0.0, u_fixed=+1.0):\n",
    "    if model_for_plots is None:\n",
    "        model_for_plots = m_dxdot\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"GLOBAL EVAL: {tag}\")\n",
    "    print(\"==============================\")\n",
    "    print_global_rmse()\n",
    "\n",
    "    # Slice: x sweep, u=+1/-1\n",
    "    plot_slice_x_two_actions_cartpole(\n",
    "        model=model_for_plots,\n",
    "        X_train=Xtr,\n",
    "        y_train=Ydxdot_tr if (model_for_plots is m_dxdot) else Ydx_tr,\n",
    "        title=f\"{tag} slice: mean ±2σ (u=+1/-1) + inducing\",\n",
    "        y_label=\"Δxdot\" if (model_for_plots is m_dxdot) else \"Δx\",\n",
    "        xdot_fixed=0.0,\n",
    "        theta_fixed=theta_fixed,\n",
    "        thetadot_fixed=thetadot_fixed,\n",
    "        x_min=-2.4, x_max=2.4,\n",
    "        n_grid=260,\n",
    "        u_list=(+1.0, -1.0),\n",
    "        show_data=True,\n",
    "        show_inducing=True,\n",
    "    )\n",
    "\n",
    "    # Surface: mean colored by std (no std-only surface)\n",
    "    plot_surface_x_xdot_mean_colored_by_std(\n",
    "        model=model_for_plots,\n",
    "        title=f\"{tag} surface: mean colored by std (+ inducing)\",\n",
    "        z_label=\"Δxdot\" if (model_for_plots is m_dxdot) else \"Δx\",\n",
    "        theta_fixed=theta_fixed,\n",
    "        thetadot_fixed=thetadot_fixed,\n",
    "        u_fixed=u_fixed,\n",
    "        x_min=-2.4, x_max=2.4,\n",
    "        xdot_min=-3.0, xdot_max=3.0,\n",
    "        n_grid=70,\n",
    "        show_inducing=True,\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# RUN\n",
    "# ----------------------------\n",
    "eval_and_plot_global(tag=\"GLOBAL (initial, float64)\", model_for_plots=m_dxdot, u_fixed=+1.0)\n"
   ],
   "id": "1d916b6311bb9503",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 5 — OSGPR streaming update (float64, fixed inducing)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow.utilities import set_trainable\n",
    "\n",
    "GP_DTYPE = tf.float64\n",
    "DTYPE_NP = np.float64\n",
    "\n",
    "def extract_posterior_summary(model):\n",
    "    \"\"\"\n",
    "    Get posterior summary at inducing points:\n",
    "      Z, mu_u, Su, Kuu\n",
    "    \"\"\"\n",
    "    Z = model.inducing_variable.Z\n",
    "    Kuu = model.kernel.K(Z)\n",
    "\n",
    "    mu = model.q_mu\n",
    "    q_sqrt = model.q_sqrt\n",
    "    L = q_sqrt[0] if len(q_sqrt.shape) == 3 else q_sqrt\n",
    "    Sv = tf.matmul(L, L, transpose_b=True)\n",
    "\n",
    "    if getattr(model, \"whiten\", False):\n",
    "        jitter = gpflow.config.default_jitter()\n",
    "        M = tf.shape(Kuu)[0]\n",
    "        Lk = tf.linalg.cholesky(Kuu + jitter * tf.eye(M, dtype=GP_DTYPE))\n",
    "        mu_u = tf.matmul(Lk, mu)\n",
    "        Su_u = tf.matmul(Lk, tf.matmul(Sv, Lk, transpose_b=True))\n",
    "    else:\n",
    "        mu_u = mu\n",
    "        Su_u = Sv\n",
    "\n",
    "    return {\"Z\": Z, \"mu_u\": mu_u, \"Su\": Su_u, \"Kuu\": Kuu}\n",
    "\n",
    "def make_osgpr_from_summary(kernel, likelihood, Z_new, X_new, Y_new, Z_old, mu_u_old, Su_old, Kuu_old):\n",
    "    if not hasattr(gpflow.models, \"OSGPR\"):\n",
    "        raise RuntimeError(\"gpflow.models.OSGPR not found.\")\n",
    "    inducing = gpflow.inducing_variables.InducingPoints(Z_new)\n",
    "    return gpflow.models.OSGPR(\n",
    "        data=(X_new, Y_new),\n",
    "        kernel=kernel,\n",
    "        likelihood=likelihood,\n",
    "        inducing_variable=inducing,\n",
    "        mu_old=mu_u_old,\n",
    "        Su_old=Su_old,\n",
    "        Kaa_old=Kuu_old,\n",
    "        Z_old=Z_old,\n",
    "    )\n",
    "\n",
    "def train_osgpr(model, iters=50, lr=0.01):\n",
    "    opt = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.elbo()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    for k in range(iters):\n",
    "        loss = step()\n",
    "        if tf.math.is_nan(loss) or tf.math.is_inf(loss):\n",
    "            raise FloatingPointError(f\"OSGPR diverged at iter {k}: loss={loss.numpy()}\")\n",
    "\n",
    "def osgpr_stream_update_fixedZ(\n",
    "    model_old,\n",
    "    X_new_np,\n",
    "    Y_new_np,\n",
    "    Z_global_np,\n",
    "    iters=50,\n",
    "    lr=0.01,\n",
    "    freeze_hypers=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Update model with new data using OSGPR; keep inducing points fixed to Z_global_np.\n",
    "    \"\"\"\n",
    "    X_new = tf.convert_to_tensor(np.asarray(X_new_np, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Y_new = tf.convert_to_tensor(np.asarray(Y_new_np, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Z_new = tf.convert_to_tensor(np.asarray(Z_global_np, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "\n",
    "    summ = extract_posterior_summary(model_old)\n",
    "\n",
    "    model_new = make_osgpr_from_summary(\n",
    "        kernel=model_old.kernel,\n",
    "        likelihood=model_old.likelihood,\n",
    "        Z_new=Z_new,\n",
    "        X_new=X_new,\n",
    "        Y_new=Y_new,\n",
    "        Z_old=summ[\"Z\"],\n",
    "        mu_u_old=summ[\"mu_u\"],\n",
    "        Su_old=summ[\"Su\"],\n",
    "        Kuu_old=summ[\"Kuu\"],\n",
    "    )\n",
    "\n",
    "    if freeze_hypers:\n",
    "        set_trainable(model_new.kernel, False)\n",
    "        set_trainable(model_new.likelihood, False)\n",
    "        set_trainable(model_new.inducing_variable.Z, False)\n",
    "\n",
    "    train_osgpr(model_new, iters=iters, lr=lr)\n",
    "    return model_new\n"
   ],
   "id": "832532d1d84b0ba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 5 — OSGPR streaming update (float64, Z trainable each update)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow.utilities import set_trainable\n",
    "\n",
    "GP_DTYPE = tf.float64\n",
    "DTYPE_NP = np.float64\n",
    "\n",
    "def extract_posterior_summary(model):\n",
    "    Z = model.inducing_variable.Z\n",
    "    Kuu = model.kernel.K(Z)\n",
    "\n",
    "    mu = model.q_mu\n",
    "    q_sqrt = model.q_sqrt\n",
    "    L = q_sqrt[0] if len(q_sqrt.shape) == 3 else q_sqrt\n",
    "    Sv = tf.matmul(L, L, transpose_b=True)\n",
    "\n",
    "    if getattr(model, \"whiten\", False):\n",
    "        jitter = gpflow.config.default_jitter()\n",
    "        M = tf.shape(Kuu)[0]\n",
    "        Lk = tf.linalg.cholesky(Kuu + jitter * tf.eye(M, dtype=GP_DTYPE))\n",
    "        mu_u = tf.matmul(Lk, mu)\n",
    "        Su_u = tf.matmul(Lk, tf.matmul(Sv, Lk, transpose_b=True))\n",
    "    else:\n",
    "        mu_u = mu\n",
    "        Su_u = Sv\n",
    "\n",
    "    return {\"Z\": Z, \"mu_u\": mu_u, \"Su\": Su_u, \"Kuu\": Kuu}\n",
    "\n",
    "def make_osgpr_from_summary(kernel, likelihood, Z_new, X_new, Y_new, Z_old, mu_u_old, Su_old, Kuu_old):\n",
    "    if not hasattr(gpflow.models, \"OSGPR\"):\n",
    "        raise RuntimeError(\"gpflow.models.OSGPR not found.\")\n",
    "    inducing = gpflow.inducing_variables.InducingPoints(Z_new)\n",
    "    return gpflow.models.OSGPR(\n",
    "        data=(X_new, Y_new),\n",
    "        kernel=kernel,\n",
    "        likelihood=likelihood,\n",
    "        inducing_variable=inducing,\n",
    "        mu_old=mu_u_old,\n",
    "        Su_old=Su_old,\n",
    "        Kaa_old=Kuu_old,\n",
    "        Z_old=Z_old,\n",
    "    )\n",
    "\n",
    "def train_osgpr(model, iters=50, lr=0.01):\n",
    "    opt = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.elbo()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    for k in range(iters):\n",
    "        loss = step()\n",
    "        if tf.math.is_nan(loss) or tf.math.is_inf(loss):\n",
    "            raise FloatingPointError(f\"OSGPR diverged at iter {k}: loss={loss.numpy()}\")\n",
    "\n",
    "def osgpr_stream_update_trainableZ(\n",
    "    model_old,\n",
    "    X_new_np,\n",
    "    Y_new_np,\n",
    "    iters=50,\n",
    "    lr=0.01,\n",
    "    freeze_hypers=True,\n",
    "):\n",
    "    X_new = tf.convert_to_tensor(np.asarray(X_new_np, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "    Y_new = tf.convert_to_tensor(np.asarray(Y_new_np, dtype=DTYPE_NP), dtype=GP_DTYPE)\n",
    "\n",
    "    summ = extract_posterior_summary(model_old)\n",
    "\n",
    "    Z_init = tf.identity(summ[\"Z\"])\n",
    "\n",
    "    model_new = make_osgpr_from_summary(\n",
    "        kernel=model_old.kernel,\n",
    "        likelihood=model_old.likelihood,\n",
    "        Z_new=Z_init,\n",
    "        X_new=X_new,\n",
    "        Y_new=Y_new,\n",
    "        Z_old=summ[\"Z\"],\n",
    "        mu_u_old=summ[\"mu_u\"],\n",
    "        Su_old=summ[\"Su\"],\n",
    "        Kuu_old=summ[\"Kuu\"],\n",
    "    )\n",
    "\n",
    "    if freeze_hypers:\n",
    "        set_trainable(model_new.kernel, False)\n",
    "        set_trainable(model_new.likelihood, False)\n",
    "\n",
    "    set_trainable(model_new.inducing_variable.Z, True)\n",
    "\n",
    "    train_osgpr(model_new, iters=iters, lr=lr)\n",
    "    return model_new\n"
   ],
   "id": "3edef4610ed8a843",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 6 — Split global anchor selection (rare) and tube selection (every step), float64\n",
    "#   ✅ Deterministic chi-square mass tube: chi2_radius_sq = chi2.ppf(alpha, df=D)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import chi2  # <-- NEW\n",
    "\n",
    "NP_DTYPE = np.float64\n",
    "TF_DTYPE = tf.float64\n",
    "\n",
    "# ---------- D-opt greedy ----------\n",
    "\n",
    "def greedy_dopt_select_from_kernel(K, k, jitter=1e-6, log_eps=1e-300):\n",
    "    K = np.asarray(K, dtype=np.float64)\n",
    "    n = K.shape[0]\n",
    "    k = int(min(k, n))\n",
    "    if k <= 0:\n",
    "        return np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "    diag = np.diag(K).copy() + float(jitter)\n",
    "    chosen = []\n",
    "    Lchol = None\n",
    "\n",
    "    for t in range(k):\n",
    "        if t == 0:\n",
    "            safe = np.maximum(diag, log_eps)\n",
    "            i = int(np.argmax(np.log(safe)))\n",
    "            chosen.append(i)\n",
    "            Lchol = np.sqrt(max(diag[i], log_eps)).reshape(1, 1)\n",
    "            continue\n",
    "\n",
    "        S = np.array(chosen, dtype=np.int64)\n",
    "\n",
    "        K_S = K[:, S]                       # (n,t)\n",
    "        v = np.linalg.solve(Lchol, K_S.T)   # (t,n)\n",
    "        sq = np.sum(v * v, axis=0)          # (n,)\n",
    "        schur = diag - sq\n",
    "\n",
    "        schur[S] = -np.inf\n",
    "\n",
    "        schur_pos = np.maximum(schur, log_eps)\n",
    "        scores = np.log(schur_pos)\n",
    "        scores[S] = -np.inf\n",
    "\n",
    "        i = int(np.argmax(scores))\n",
    "        chosen.append(i)\n",
    "\n",
    "        k_iS = K[i, S].reshape(1, -1)\n",
    "        w = np.linalg.solve(Lchol, k_iS.T)\n",
    "        alpha2 = diag[i] - float(np.sum(w * w))\n",
    "        alpha2 = max(alpha2, log_eps)\n",
    "        alpha = np.sqrt(alpha2)\n",
    "\n",
    "        Lnew = np.zeros((t + 1, t + 1), dtype=np.float64)\n",
    "        Lnew[:t, :t] = Lchol\n",
    "        Lnew[t, :t] = w.reshape(-1)\n",
    "        Lnew[t, t] = alpha\n",
    "        Lchol = Lnew\n",
    "\n",
    "    return np.array(chosen, dtype=np.int64)\n",
    "\n",
    "\n",
    "# ---------- weights + tube stats ----------\n",
    "\n",
    "def normalize_nonnegative_weights(w, eps=1e-12):\n",
    "    w = np.asarray(w, dtype=NP_DTYPE).reshape(-1)\n",
    "    w = np.maximum(w, 0.0)\n",
    "    s = float(np.sum(w))\n",
    "    if s < eps:\n",
    "        return np.ones_like(w) / max(len(w), 1)\n",
    "    return w / s\n",
    "\n",
    "def compute_weighted_moments(rollout_inputs, rollout_weights):\n",
    "    X = np.asarray(rollout_inputs, dtype=NP_DTYPE)  # (K,H,D)\n",
    "    K, H, D = X.shape\n",
    "    w = normalize_nonnegative_weights(rollout_weights).reshape(K, 1, 1)\n",
    "\n",
    "    tube_mean = np.sum(w * X, axis=0)  # (H,D)\n",
    "    Xc = X - tube_mean[None, :, :]\n",
    "    tube_cov = np.einsum(\"khd,khe->hde\", (w * Xc), Xc)  # (H,D,D)\n",
    "    return tube_mean, tube_cov\n",
    "\n",
    "def min_mahalanobis_and_argmin(points_Z, tube_mean, tube_cov, cov_eps=1e-6):\n",
    "    Z = np.asarray(points_Z, dtype=NP_DTYPE)\n",
    "    mu = np.asarray(tube_mean, dtype=NP_DTYPE)\n",
    "    Sig = np.asarray(tube_cov, dtype=NP_DTYPE)\n",
    "\n",
    "    M, D = Z.shape\n",
    "    H = mu.shape[0]\n",
    "    I = np.eye(D, dtype=NP_DTYPE)\n",
    "\n",
    "    dmin = np.full((M,), np.inf, dtype=NP_DTYPE)\n",
    "    tmin = np.zeros((M,), dtype=np.int64)\n",
    "\n",
    "    for t in range(H):\n",
    "        St = Sig[t] + cov_eps * I\n",
    "        L = np.linalg.cholesky(St)\n",
    "\n",
    "        diff = (Z - mu[t:t+1, :]).T\n",
    "        y = np.linalg.solve(L, diff)\n",
    "        y2 = np.linalg.solve(L.T, y)\n",
    "        quad = np.sum(diff * y2, axis=0)\n",
    "\n",
    "        mask = quad < dmin\n",
    "        dmin[mask] = quad[mask]\n",
    "        tmin[mask] = t\n",
    "\n",
    "    return dmin, tmin\n",
    "\n",
    "def split_even_quota(total, num_bins):\n",
    "    num_bins = int(max(1, num_bins))\n",
    "    base = total // num_bins\n",
    "    rem = total - base * num_bins\n",
    "    q = np.full((num_bins,), base, dtype=np.int64)\n",
    "    if rem > 0:\n",
    "        q[:rem] += 1\n",
    "    return q\n",
    "\n",
    "def get_Z_global(model):\n",
    "    return model.inducing_variable.Z.numpy().astype(NP_DTYPE)\n",
    "\n",
    "# ---------- NEW: deterministic chi-square radius ----------\n",
    "\n",
    "def chi2_radius_sq(alpha, D):\n",
    "    \"\"\"\n",
    "    Deterministic radius threshold for Mahalanobis tube:\n",
    "        (x-mu)^T Sigma^{-1} (x-mu) <= chi2.ppf(alpha, df=D)\n",
    "    \"\"\"\n",
    "    alpha = float(alpha)\n",
    "    D = int(D)\n",
    "    alpha = min(max(alpha, 1e-6), 1.0 - 1e-12)\n",
    "    return float(chi2.ppf(alpha, df=D))\n",
    "\n",
    "\n",
    "# ---------- 1) Global anchor selection (call only after global update) ----------\n",
    "\n",
    "def select_global_anchors(model, num_anchors=16, dopt_jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Select anchors across the entire current Z_global via greedy D-opt.\n",
    "    Call this only when the global model/inducing locations Z_global have been updated.\n",
    "    Returns indices into Z_global.\n",
    "    \"\"\"\n",
    "    Zg = get_Z_global(model)\n",
    "    M = Zg.shape[0]\n",
    "    num_anchors = int(min(num_anchors, M))\n",
    "    if num_anchors <= 0:\n",
    "        return np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "    K_all = model.kernel.K(tf.convert_to_tensor(Zg, dtype=TF_DTYPE)).numpy().astype(NP_DTYPE)\n",
    "    anchor_idx = greedy_dopt_select_from_kernel(K_all, k=num_anchors, jitter=dopt_jitter)\n",
    "    return anchor_idx.astype(np.int64)\n",
    "\n",
    "\n",
    "# ---------- 2) Tube subset selection (call every step) ----------\n",
    "\n",
    "def select_tube_subset(\n",
    "    model,\n",
    "    rollout_inputs,        # (K,H,D) GP-input rollouts\n",
    "    rollout_weights,       # (K,)\n",
    "    total_subset_size=64,\n",
    "    anchor_idx=None,       # indices into Z_global (fixed until next global update)\n",
    "    time_bins=16,\n",
    "    cov_eps=1e-6,\n",
    "    dopt_jitter=1e-6,\n",
    "    fallback_candidates=400,\n",
    "\n",
    "    # --- NEW: choose ONE of the following two ---\n",
    "    alpha=None,            # e.g. 0.99 (recommended for paper)\n",
    "    chi2_radius_sq_override=None,  # if you insist on passing a scalar threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a confidence tube from rollouts and fill the remaining budget (total_subset_size - len(anchors))\n",
    "    using stratified greedy D-opt inside the tube, excluding anchors.\n",
    "\n",
    "    Deterministic tube threshold:\n",
    "        chi2_radius_sq = chi2.ppf(alpha, df=D)\n",
    "\n",
    "    Returns:\n",
    "      subset_idx: (total_subset_size,) indices into Z_global (anchors + tube points)\n",
    "      tube_mean, tube_cov\n",
    "      tube_candidates_idx\n",
    "      chi2_radius_sq_used\n",
    "    \"\"\"\n",
    "    Zg = get_Z_global(model)\n",
    "    M = Zg.shape[0]\n",
    "\n",
    "    if anchor_idx is None:\n",
    "        anchor_idx = np.zeros((0,), dtype=np.int64)\n",
    "    anchor_idx = np.unique(np.asarray(anchor_idx, dtype=np.int64))\n",
    "    anchor_idx = anchor_idx[(anchor_idx >= 0) & (anchor_idx < M)]\n",
    "\n",
    "    tube_mean, tube_cov = compute_weighted_moments(rollout_inputs, rollout_weights)\n",
    "    H, D = tube_mean.shape[0], tube_mean.shape[1]\n",
    "\n",
    "    # --- NEW: determine chi2 threshold deterministically ---\n",
    "    if chi2_radius_sq_override is not None:\n",
    "        chi2_thr = float(chi2_radius_sq_override)\n",
    "    else:\n",
    "        if alpha is None:\n",
    "            raise ValueError(\"select_tube_subset: provide alpha (e.g. 0.99) or chi2_radius_sq_override.\")\n",
    "        chi2_thr = chi2_radius_sq(alpha, D)\n",
    "\n",
    "    dmin, tmin = min_mahalanobis_and_argmin(Zg, tube_mean, tube_cov, cov_eps=cov_eps)\n",
    "    tube_candidates_idx = np.where(dmin <= chi2_thr)[0].astype(np.int64)\n",
    "\n",
    "    remaining_budget = int(total_subset_size - anchor_idx.size)\n",
    "    remaining_budget = max(0, remaining_budget)\n",
    "\n",
    "    # If too few tube candidates to fill, expand by nearest dmin\n",
    "    if tube_candidates_idx.size < remaining_budget:\n",
    "        L = int(min(max(fallback_candidates, remaining_budget), M))\n",
    "        tube_candidates_idx = np.argsort(dmin)[:L].astype(np.int64)\n",
    "\n",
    "    # Exclude anchors from tube pool\n",
    "    tube_pool = tube_candidates_idx[~np.isin(tube_candidates_idx, anchor_idx)]\n",
    "    tmin_pool = tmin[tube_pool]\n",
    "\n",
    "    selected = set(int(i) for i in anchor_idx)\n",
    "\n",
    "    # Stratified fill across horizon\n",
    "    if remaining_budget > 0 and tube_pool.size > 0:\n",
    "        B = int(max(1, min(time_bins, H)))\n",
    "        edges = np.linspace(0, H, B + 1, dtype=np.int64)\n",
    "        quotas = split_even_quota(remaining_budget, B)\n",
    "\n",
    "        for b in range(B):\n",
    "            if len(selected) >= total_subset_size:\n",
    "                break\n",
    "\n",
    "            a, c = int(edges[b]), int(edges[b + 1])\n",
    "            if c <= a:\n",
    "                continue\n",
    "\n",
    "            in_bin = (tmin_pool >= a) & (tmin_pool < c)\n",
    "            bin_pool = tube_pool[in_bin]\n",
    "            if bin_pool.size == 0:\n",
    "                continue\n",
    "\n",
    "            k_b = int(min(quotas[b], bin_pool.size, total_subset_size - len(selected)))\n",
    "            if k_b <= 0:\n",
    "                continue\n",
    "\n",
    "            Zb = Zg[bin_pool]\n",
    "            Kb = model.kernel.K(tf.convert_to_tensor(Zb, dtype=TF_DTYPE)).numpy().astype(NP_DTYPE)\n",
    "            pick = greedy_dopt_select_from_kernel(Kb, k=k_b, jitter=dopt_jitter)\n",
    "\n",
    "            for gidx in bin_pool[pick]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    # Fill any remaining slots by D-opt over leftover tube pool\n",
    "    if len(selected) < total_subset_size:\n",
    "        need = int(total_subset_size - len(selected))\n",
    "        leftover = tube_pool[~np.isin(tube_pool, np.array(list(selected), dtype=np.int64))]\n",
    "        if leftover.size > 0 and need > 0:\n",
    "            Zl = Zg[leftover]\n",
    "            Kl = model.kernel.K(tf.convert_to_tensor(Zl, dtype=TF_DTYPE)).numpy().astype(NP_DTYPE)\n",
    "            pick = greedy_dopt_select_from_kernel(Kl, k=min(need, leftover.size), jitter=dopt_jitter)\n",
    "            for gidx in leftover[pick]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    # Last-resort fill (rare): nearest-by-dmin among remaining global points\n",
    "    if len(selected) < total_subset_size:\n",
    "        need = int(total_subset_size - len(selected))\n",
    "        remaining = np.setdiff1d(np.arange(M, dtype=np.int64), np.array(list(selected), dtype=np.int64), assume_unique=False)\n",
    "        if remaining.size > 0:\n",
    "            order = remaining[np.argsort(dmin[remaining])]\n",
    "            for gidx in order[:need]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    subset_idx = np.array(sorted(selected), dtype=np.int64)[:total_subset_size]\n",
    "    return subset_idx, tube_mean, tube_cov, tube_candidates_idx, chi2_thr\n"
   ],
   "id": "69ba29a41d98f265",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 7 — MPPI + Online global SVGP + planning-tube Z_local ⊂ Z_global\n",
    "#   ✅ Each RUN independent: reset model params + reset dataset to X0\n",
    "#   ✅ NO per-retrain prints\n",
    "#   ✅ Logs wall-time vs timestep + training-time vs timestep\n",
    "#   ✅ Plots mean curves over N_RUNS\n",
    "#   ✅ At end: learned model surfaces for EACH run\n",
    "# ============================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "from gpflow.utilities import set_trainable, parameter_dict, multiple_assign\n",
    "\n",
    "# -----------------------\n",
    "# Dtypes (float64 everywhere)\n",
    "# -----------------------\n",
    "NP_DTYPE = np.float64\n",
    "TF_DTYPE = tf.float64\n",
    "gpflow.config.set_default_float(TF_DTYPE)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "\n",
    "# -----------------------\n",
    "# MPPI config\n",
    "# -----------------------\n",
    "HORIZON   = 50\n",
    "K_SAMPLES = 256\n",
    "SIGMA     = 0.6\n",
    "LAMBDA    = 1.0\n",
    "\n",
    "# success / hold\n",
    "X_BAND      = 0.70\n",
    "UPRIGHT_COS = 0.85\n",
    "HOLD_GOAL   = 150\n",
    "\n",
    "# cost weights\n",
    "CENTER_W  = 1.0\n",
    "U_W       = 0.005\n",
    "UPRIGHT_W = 2.0\n",
    "\n",
    "# exploration/unc schedule\n",
    "EXPLORE_STEPS = 200\n",
    "UNC_W_MAX     = 15.0\n",
    "UNC_W_MIN     = 0.0\n",
    "\n",
    "# online global update\n",
    "RETRAIN_EVERY = 40\n",
    "RETRAIN_STEPS = 200\n",
    "RETRAIN_LR    = 2e-3\n",
    "\n",
    "# subset sizes\n",
    "NUM_ANCHORS       = 16\n",
    "LOCAL_SUBSET_SIZE = 64\n",
    "TUBE_ALPHA        = 0.99      # ✅ paper setting\n",
    "TUBE_NUM_BINS     = 5\n",
    "\n",
    "# experiment\n",
    "N_RUNS           = 3\n",
    "EPISODES_PER_RUN = 3\n",
    "MAX_STEPS_PER_EP = 600\n",
    "\n",
    "# render (we will EXCLUDE render time from timing logs)\n",
    "RENDER_W, RENDER_H = 720, 450\n",
    "FPS_RENDER = 20\n",
    "\n",
    "# bounds\n",
    "if \"U_MIN\" not in globals(): U_MIN = -1.0\n",
    "if \"U_MAX\" not in globals(): U_MAX = +1.0\n",
    "\n",
    "# -----------------------\n",
    "# helper: exploration weight\n",
    "# -----------------------\n",
    "@tf.function\n",
    "def exploration_weight_tf(t_global):\n",
    "    t = tf.cast(t_global, TF_DTYPE)\n",
    "    explore = tf.cast(EXPLORE_STEPS, TF_DTYPE)\n",
    "    a = tf.clip_by_value(1.0 - t / tf.maximum(explore, 1.0), 0.0, 1.0)\n",
    "    return tf.cast(UNC_W_MIN, TF_DTYPE) + (tf.cast(UNC_W_MAX, TF_DTYPE) - tf.cast(UNC_W_MIN, TF_DTYPE)) * a\n",
    "\n",
    "# -----------------------\n",
    "# angle wrap\n",
    "# -----------------------\n",
    "@tf.function\n",
    "def tf_wrap_pi(th):\n",
    "    two_pi = tf.constant(2.0 * np.pi, dtype=TF_DTYPE)\n",
    "    pi = tf.constant(np.pi, dtype=TF_DTYPE)\n",
    "    return tf.math.floormod(th + pi, two_pi) - pi\n",
    "\n",
    "# -----------------------\n",
    "# features from state (must match your feature map)\n",
    "# -----------------------\n",
    "@tf.function\n",
    "def tf_features_from_state(s, u, x_scale=2.4, v_scale=3.0, w_scale=8.0):\n",
    "    x     = s[:, 0]\n",
    "    xdot  = s[:, 1]\n",
    "    th    = s[:, 2]\n",
    "    thdot = s[:, 3]\n",
    "    x_feat    = tf.math.tanh(x / tf.cast(x_scale, TF_DTYPE))\n",
    "    xdot_feat = tf.math.tanh(xdot / tf.cast(v_scale, TF_DTYPE))\n",
    "    w_feat    = tf.math.tanh(thdot / tf.cast(w_scale, TF_DTYPE))\n",
    "    return tf.stack([x_feat, xdot_feat, tf.sin(th), tf.cos(th), w_feat, u], axis=1)  # (K,6)\n",
    "\n",
    "# -----------------------\n",
    "# costs\n",
    "# -----------------------\n",
    "@tf.function\n",
    "def stage_cost_cartpole_tf(S, U, x_init, unc_bonus=None, unc_w=0.0):\n",
    "    th = S[:, 2]\n",
    "    x  = S[:, 0]\n",
    "    c = (\n",
    "        tf.cast(UPRIGHT_W, TF_DTYPE) * (1.0 - tf.cos(th))\n",
    "        + tf.cast(CENTER_W, TF_DTYPE) * tf.square(x - x_init)\n",
    "        + tf.cast(U_W, TF_DTYPE) * tf.square(U)\n",
    "    )\n",
    "    if (unc_bonus is not None) and (unc_w > 0.0):\n",
    "        c = c - tf.cast(unc_w, TF_DTYPE) * tf.cast(unc_bonus, TF_DTYPE)\n",
    "    return c\n",
    "\n",
    "@tf.function\n",
    "def terminal_cost_hold_like_tf(S, x_init):\n",
    "    th = S[:, 2]\n",
    "    x  = S[:, 0]\n",
    "    cT = tf.zeros_like(th)\n",
    "    good = tf.logical_and(tf.cos(th) >= tf.cast(UPRIGHT_COS, TF_DTYPE),\n",
    "                          tf.abs(x - x_init) <= tf.cast(X_BAND, TF_DTYPE))\n",
    "    cT = tf.where(good, cT - tf.cast(5.0, TF_DTYPE), cT)\n",
    "    return cT\n",
    "\n",
    "# -----------------------\n",
    "# local models: build once per run, update in-place each step\n",
    "# -----------------------\n",
    "def init_local_like_global(global_model, M, likelihood_var=1e-3):\n",
    "    D = int(global_model.inducing_variable.Z.shape[1])\n",
    "    Z_dummy = np.zeros((int(M), D), dtype=NP_DTYPE)\n",
    "    kernel = global_model.kernel\n",
    "    inducing = gpflow.inducing_variables.InducingPoints(tf.convert_to_tensor(Z_dummy, TF_DTYPE))\n",
    "    m_loc = gpflow.models.SVGP(\n",
    "        kernel=kernel,\n",
    "        likelihood=gpflow.likelihoods.Gaussian(variance=tf.convert_to_tensor(likelihood_var, TF_DTYPE)),\n",
    "        inducing_variable=inducing,\n",
    "        num_latent_gps=1,\n",
    "        whiten=True,\n",
    "    )\n",
    "    set_trainable(m_loc.likelihood.variance, False)\n",
    "    set_trainable(m_loc.inducing_variable.Z, False)\n",
    "    return m_loc\n",
    "\n",
    "def update_local_from_global_inplace(global_model, local_model, Z_local_np, jitter=1e-6):\n",
    "    Z_local = tf.convert_to_tensor(np.asarray(Z_local_np, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "    local_model.inducing_variable.Z.assign(Z_local)\n",
    "\n",
    "    mu_f, var_f = global_model.predict_f(Z_local)  # (M,1)\n",
    "    mu_f  = tf.reshape(mu_f,  (-1, 1))\n",
    "    var_f = tf.reshape(var_f, (-1, 1))\n",
    "\n",
    "    Kuu = local_model.kernel.K(Z_local)\n",
    "    M = tf.shape(Kuu)[0]\n",
    "    L = tf.linalg.cholesky(Kuu + tf.cast(jitter, TF_DTYPE) * tf.eye(M, dtype=TF_DTYPE))\n",
    "\n",
    "    q_mu = tf.linalg.triangular_solve(L, mu_f)\n",
    "\n",
    "    std_f = tf.sqrt(tf.maximum(var_f, tf.cast(1e-12, TF_DTYPE)))\n",
    "    std_v = 0.75 * std_f\n",
    "    q_sqrt = tf.linalg.diag(tf.reshape(std_v, (-1,)))\n",
    "    q_sqrt = tf.reshape(q_sqrt, (1, tf.shape(q_sqrt)[0], tf.shape(q_sqrt)[1]))\n",
    "\n",
    "    local_model.q_mu.assign(q_mu)\n",
    "    local_model.q_sqrt.assign(q_sqrt)\n",
    "\n",
    "# -----------------------\n",
    "# MPPI step (TF/GPU)\n",
    "# -----------------------\n",
    "@tf.function(reduce_retracing=True)\n",
    "def mppi_step_tf(\n",
    "    state0, x_init, u_nom, t_global,\n",
    "    loc_dx, loc_dxdot, loc_dth, loc_dthdot,\n",
    "    K=256, H=50, sigma=0.6, lam=1.0, u_min=-1.0, u_max=1.0,\n",
    "):\n",
    "    K = tf.cast(K, tf.int32)\n",
    "    H = tf.cast(H, tf.int32)\n",
    "    sigma = tf.cast(sigma, TF_DTYPE)\n",
    "    lam   = tf.cast(lam,   TF_DTYPE)\n",
    "    u_min = tf.cast(u_min, TF_DTYPE)\n",
    "    u_max = tf.cast(u_max, TF_DTYPE)\n",
    "\n",
    "    eps = tf.random.normal(shape=(K, H), mean=0.0, stddev=sigma, dtype=TF_DTYPE)\n",
    "    U = tf.clip_by_value(u_nom[None, :] + eps, u_min, u_max)  # (K,H)\n",
    "\n",
    "    s = tf.tile(tf.reshape(tf.cast(state0, TF_DTYPE), (1, 4)), (K, 1))  # (K,4)\n",
    "    feat_ta = tf.TensorArray(dtype=TF_DTYPE, size=H, clear_after_read=False)\n",
    "    costs = tf.zeros((K,), dtype=TF_DTYPE)\n",
    "\n",
    "    unc_w = exploration_weight_tf(t_global)\n",
    "    x_init = tf.cast(x_init, TF_DTYPE)\n",
    "\n",
    "    t = tf.constant(0, dtype=tf.int32)\n",
    "    def cond(t, s, costs, feat_ta): return t < H\n",
    "\n",
    "    def body(t, s, costs, feat_ta):\n",
    "        u_t = U[:, t]\n",
    "        X_feat = tf_features_from_state(s, u_t)  # (K,6)\n",
    "        feat_ta = feat_ta.write(t, X_feat)\n",
    "\n",
    "        mu_dx, _         = loc_dx.predict_f(X_feat)\n",
    "        mu_dxdot, v_dxdot= loc_dxdot.predict_f(X_feat)\n",
    "        mu_dth, _        = loc_dth.predict_f(X_feat)\n",
    "        mu_dthdot, _     = loc_dthdot.predict_f(X_feat)\n",
    "\n",
    "        dx     = tf.reshape(mu_dx, (-1,))\n",
    "        dxdot  = tf.reshape(mu_dxdot, (-1,))\n",
    "        dth    = tf.reshape(mu_dth, (-1,))\n",
    "        dthdot = tf.reshape(mu_dthdot, (-1,))\n",
    "\n",
    "        x     = s[:, 0] + dx\n",
    "        xdot  = s[:, 1] + dxdot\n",
    "        th    = tf_wrap_pi(s[:, 2] + dth)\n",
    "        thdot = s[:, 3] + dthdot\n",
    "        s_new = tf.stack([x, xdot, th, thdot], axis=1)\n",
    "\n",
    "        unc_bonus = tf.reshape(v_dxdot, (-1,))\n",
    "        costs_new = costs + stage_cost_cartpole_tf(s_new, u_t, x_init=x_init, unc_bonus=unc_bonus, unc_w=unc_w)\n",
    "        return t + 1, s_new, costs_new, feat_ta\n",
    "\n",
    "    _, s_final, costs, feat_ta = tf.while_loop(cond, body, [t, s, costs, feat_ta], parallel_iterations=1)\n",
    "    costs = costs + terminal_cost_hold_like_tf(s_final, x_init=x_init)\n",
    "\n",
    "    rollout_inputs = tf.transpose(feat_ta.stack(), perm=[1, 0, 2])  # (K,H,6)\n",
    "\n",
    "    cmin = tf.reduce_min(costs)\n",
    "    w_unnorm = tf.exp(-(costs - cmin) / tf.maximum(lam, tf.cast(1e-12, TF_DTYPE)))\n",
    "    weights = w_unnorm / (tf.reduce_sum(w_unnorm) + tf.cast(1e-12, TF_DTYPE))\n",
    "\n",
    "    u_nom_new = tf.reduce_sum(weights[:, None] * U, axis=0)  # (H,)\n",
    "    u0 = u_nom_new[0]\n",
    "    u_nom_new = tf.concat([u_nom_new[1:], u_nom_new[-1:]], axis=0)\n",
    "\n",
    "    return u0, u_nom_new, rollout_inputs, weights\n",
    "\n",
    "# -----------------------\n",
    "# global retrain burst\n",
    "# -----------------------\n",
    "def make_train_step(model, optimizer):\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def _step(Xb, Yb):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.elbo((Xb, Yb))\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "    return _step\n",
    "\n",
    "def retrain_global_burst(X_all, Y_dx, Y_dxdot, Y_dth, Y_dthdot, steps=200, batch_size=256, lr=2e-3, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = int(X_all.shape[0])\n",
    "    idx_all = np.arange(N)\n",
    "\n",
    "    for m in (m_dx, m_dxdot, m_dth, m_dthdot):\n",
    "        set_trainable(m.inducing_variable.Z, True)\n",
    "\n",
    "    lr_f = float(lr)\n",
    "    opt_dx     = tf.optimizers.Adam(learning_rate=lr_f)\n",
    "    opt_dxdot  = tf.optimizers.Adam(learning_rate=lr_f)\n",
    "    opt_dth    = tf.optimizers.Adam(learning_rate=lr_f)\n",
    "    opt_dthdot = tf.optimizers.Adam(learning_rate=lr_f)\n",
    "\n",
    "    step_dx     = make_train_step(m_dx, opt_dx)\n",
    "    step_dxdot  = make_train_step(m_dxdot, opt_dxdot)\n",
    "    step_dth    = make_train_step(m_dth, opt_dth)\n",
    "    step_dthdot = make_train_step(m_dthdot, opt_dthdot)\n",
    "\n",
    "    X_tf = tf.convert_to_tensor(np.asarray(X_all, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "    Ydx_tf     = tf.convert_to_tensor(np.asarray(Y_dx, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "    Ydxdot_tf  = tf.convert_to_tensor(np.asarray(Y_dxdot, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "    Ydth_tf    = tf.convert_to_tensor(np.asarray(Y_dth, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "    Ydthdot_tf = tf.convert_to_tensor(np.asarray(Y_dthdot, dtype=NP_DTYPE), dtype=TF_DTYPE)\n",
    "\n",
    "    B = min(int(batch_size), N)\n",
    "    for _ in range(int(steps)):\n",
    "        b = rng.choice(idx_all, size=B, replace=False)\n",
    "        Xb = tf.gather(X_tf, b)\n",
    "        _  = step_dx(Xb, tf.gather(Ydx_tf, b))\n",
    "        _  = step_dxdot(Xb, tf.gather(Ydxdot_tf, b))\n",
    "        _  = step_dth(Xb, tf.gather(Ydth_tf, b))\n",
    "        _  = step_dthdot(Xb, tf.gather(Ydthdot_tf, b))\n",
    "\n",
    "    for m in (m_dx, m_dxdot, m_dth, m_dthdot):\n",
    "        set_trainable(m.inducing_variable.Z, False)\n",
    "\n",
    "# -----------------------\n",
    "# ✅ reset point: capture init params ONCE (current state = “scratch init”)\n",
    "# -----------------------\n",
    "INIT_PARAMS = {\n",
    "    \"dx\":     parameter_dict(m_dx),\n",
    "    \"dxdot\":  parameter_dict(m_dxdot),\n",
    "    \"dth\":    parameter_dict(m_dth),\n",
    "    \"dthdot\": parameter_dict(m_dthdot),\n",
    "}\n",
    "\n",
    "def reset_models_to_scratch():\n",
    "    multiple_assign(m_dx,     INIT_PARAMS[\"dx\"])\n",
    "    multiple_assign(m_dxdot,  INIT_PARAMS[\"dxdot\"])\n",
    "    multiple_assign(m_dth,    INIT_PARAMS[\"dth\"])\n",
    "    multiple_assign(m_dthdot, INIT_PARAMS[\"dthdot\"])\n",
    "\n",
    "# -----------------------\n",
    "# surfaces plot helper (per run)\n",
    "# -----------------------\n",
    "def plot_learned_surfaces_for_run(run_id, m_dx, m_dxdot, m_dth, m_dthdot,\n",
    "                                  x_lim=2.4, th_lim=np.pi, nx=121, nth=121,\n",
    "                                  xdot0=0.0, thdot0=0.0, u0=0.0):\n",
    "    xs = np.linspace(-x_lim, x_lim, nx, dtype=NP_DTYPE)\n",
    "    ths = np.linspace(-th_lim, th_lim, nth, dtype=NP_DTYPE)\n",
    "    XX, TT = np.meshgrid(xs, ths, indexing=\"xy\")  # (nth,nx)\n",
    "\n",
    "    # build features for each grid point\n",
    "    Xfeat = np.zeros((nx*nth, 6), dtype=NP_DTYPE)\n",
    "    idx = 0\n",
    "    for j in range(nth):\n",
    "        for i in range(nx):\n",
    "            x = float(XX[j, i])\n",
    "            th = float(TT[j, i])\n",
    "            Xfeat[idx, :] = state_to_features(x, float(xdot0), th, float(thdot0), float(u0), dtype=NP_DTYPE)\n",
    "            idx += 1\n",
    "\n",
    "    Xtf = tf.convert_to_tensor(Xfeat, dtype=TF_DTYPE)\n",
    "\n",
    "    def pred_grid(model):\n",
    "        mu, _ = model.predict_f(Xtf)\n",
    "        Z = mu.numpy().astype(NP_DTYPE).reshape(nth, nx)\n",
    "        return Z\n",
    "\n",
    "    Z_dx     = pred_grid(m_dx)\n",
    "    Z_dxdot  = pred_grid(m_dxdot)\n",
    "    Z_dth    = pred_grid(m_dth)\n",
    "    Z_dthdot = pred_grid(m_dthdot)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 9), constrained_layout=True)\n",
    "    fig.suptitle(f\"Run {run_id+1}: learned global model surfaces (slice: xdot=0, thdot=0, u=0)\", fontsize=14)\n",
    "\n",
    "    def show(ax, Z, title):\n",
    "        im = ax.imshow(Z, origin=\"lower\",\n",
    "                       extent=[xs[0], xs[-1], ths[0], ths[-1]],\n",
    "                       aspect=\"auto\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"theta\")\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    show(axs[0,0], Z_dx,     \"E[Δx | x,θ]\")\n",
    "    show(axs[0,1], Z_dxdot,  \"E[Δxdot | x,θ]\")\n",
    "    show(axs[1,0], Z_dth,    \"E[Δθ | x,θ]\")\n",
    "    show(axs[1,1], Z_dthdot, \"E[Δθdot | x,θ]\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# RUNS (independent trials) + timing logs\n",
    "# -----------------------\n",
    "run_wall_traces  = []   # list of arrays: wall_time_cum vs step\n",
    "run_train_traces = []   # list of arrays: train_time_cum vs step\n",
    "run_models_snap  = []   # store final models params per run for surfaces\n",
    "\n",
    "for run_id in range(N_RUNS):\n",
    "    np.random.seed(100 + run_id)\n",
    "    tf.random.set_seed(10_000 + run_id)\n",
    "\n",
    "    # fresh models + fresh dataset (from scratch)\n",
    "    reset_models_to_scratch()\n",
    "\n",
    "    X_global       = np.asarray(X0,      dtype=NP_DTYPE).copy()\n",
    "    Ydx_global     = np.asarray(Ydx0,    dtype=NP_DTYPE).copy()\n",
    "    Ydxdot_global  = np.asarray(Ydxdot0, dtype=NP_DTYPE).copy()\n",
    "    Ydth_global    = np.asarray(Ydth0,   dtype=NP_DTYPE).copy()\n",
    "    Ydthdot_global = np.asarray(Ydthdot0,dtype=NP_DTYPE).copy()\n",
    "\n",
    "    env = make_env(render_mode=None, seed=1000 + run_id, start_down=True, edge_respawn=True)\n",
    "\n",
    "    anchors_idx = select_global_anchors(m_dx, num_anchors=NUM_ANCHORS, dopt_jitter=1e-6)\n",
    "\n",
    "    # fresh locals per run\n",
    "    Mloc = int(LOCAL_SUBSET_SIZE)\n",
    "    loc_dx     = init_local_like_global(m_dx,     Mloc, likelihood_var=1e-3)\n",
    "    loc_dxdot  = init_local_like_global(m_dxdot,  Mloc, likelihood_var=1e-3)\n",
    "    loc_dth    = init_local_like_global(m_dth,    Mloc, likelihood_var=1e-3)\n",
    "    loc_dthdot = init_local_like_global(m_dthdot, Mloc, likelihood_var=1e-3)\n",
    "\n",
    "    # init local subset\n",
    "    Zg_np = m_dx.inducing_variable.Z.numpy().astype(NP_DTYPE)\n",
    "    if len(anchors_idx) < LOCAL_SUBSET_SIZE:\n",
    "        fill = np.argsort(np.linalg.norm(Zg_np, axis=1))[:LOCAL_SUBSET_SIZE]\n",
    "        init_subset = np.unique(np.concatenate([anchors_idx, fill], axis=0))[:LOCAL_SUBSET_SIZE]\n",
    "    else:\n",
    "        init_subset = np.asarray(anchors_idx[:LOCAL_SUBSET_SIZE], dtype=np.int64)\n",
    "\n",
    "    Zloc0 = Zg_np[np.asarray(init_subset, dtype=np.int64)]\n",
    "    update_local_from_global_inplace(m_dx,     loc_dx,     Zloc0)\n",
    "    update_local_from_global_inplace(m_dxdot,  loc_dxdot,  Zloc0)\n",
    "    update_local_from_global_inplace(m_dth,    loc_dth,    Zloc0)\n",
    "    update_local_from_global_inplace(m_dthdot, loc_dthdot, Zloc0)\n",
    "\n",
    "    # timing logs (exclude rendering)\n",
    "    wall_time_cum = []\n",
    "    train_time_cum = []\n",
    "    t_run0 = time.perf_counter()\n",
    "    train_acc = 0.0\n",
    "\n",
    "    total_exec_steps = 0\n",
    "\n",
    "    for ep in range(EPISODES_PER_RUN):\n",
    "        obs, _ = env.reset(seed=2000 + 100*run_id + ep)\n",
    "        x, xdot, th, thdot = obs_to_state(obs)\n",
    "        state = np.asarray([x, xdot, th, thdot], dtype=NP_DTYPE)\n",
    "        x_init = float(state[0])\n",
    "\n",
    "        u_nom = np.zeros((HORIZON,), dtype=NP_DTYPE)\n",
    "        upright_streak = 0\n",
    "\n",
    "        X_new_buf, Ydx_new_buf, Ydxdot_new_buf, Ydth_new_buf, Ydthdot_new_buf = [], [], [], [], []\n",
    "        ep_frames = []\n",
    "\n",
    "        for step in range(MAX_STEPS_PER_EP):\n",
    "            # --- MPPI ---\n",
    "            u0_tf, u_nom_tf, rollout_inputs_tf, weights_tf = mppi_step_tf(\n",
    "                state0=tf.convert_to_tensor(state, dtype=TF_DTYPE),\n",
    "                x_init=tf.convert_to_tensor(x_init, dtype=TF_DTYPE),\n",
    "                u_nom=tf.convert_to_tensor(u_nom, dtype=TF_DTYPE),\n",
    "                t_global=tf.convert_to_tensor(total_exec_steps, dtype=tf.int32),\n",
    "                loc_dx=loc_dx,\n",
    "                loc_dxdot=loc_dxdot,\n",
    "                loc_dth=loc_dth,\n",
    "                loc_dthdot=loc_dthdot,\n",
    "                K=K_SAMPLES,\n",
    "                H=HORIZON,\n",
    "                sigma=SIGMA,\n",
    "                lam=LAMBDA,\n",
    "                u_min=float(U_MIN),\n",
    "                u_max=float(U_MAX),\n",
    "            )\n",
    "\n",
    "            u0 = float(u0_tf.numpy())\n",
    "            u_nom = u_nom_tf.numpy().astype(NP_DTYPE)\n",
    "            rollout_inputs = rollout_inputs_tf.numpy().astype(NP_DTYPE)\n",
    "            weights = weights_tf.numpy().astype(NP_DTYPE)\n",
    "\n",
    "            # --- env step ---\n",
    "            next_obs, reward, terminated, truncated, info = env.step(np.array([u0], dtype=np.float32))\n",
    "            nx, nxdot, nth, nthdot = obs_to_state(next_obs)\n",
    "            next_state = np.asarray([nx, nxdot, nth, nthdot], dtype=NP_DTYPE)\n",
    "\n",
    "            # render time excluded from timing curves\n",
    "            t_vis0 = time.perf_counter()\n",
    "            ep_frames.append(render_cartpole_frame_from_state(float(next_state[0]), float(next_state[2]), W=RENDER_W, H=RENDER_H))\n",
    "            t_vis1 = time.perf_counter()\n",
    "\n",
    "            # --- training transition (respect respawn) ---\n",
    "            respawned = bool(info.get(\"respawned\", False))\n",
    "            if respawned and (\"terminal_obs\" in info):\n",
    "                train_next_obs = info[\"terminal_obs\"]\n",
    "            else:\n",
    "                train_next_obs = next_obs\n",
    "\n",
    "            tx, txdot, tth, tthdot = obs_to_state(train_next_obs)\n",
    "            train_next_state = np.asarray([tx, txdot, tth, tthdot], dtype=NP_DTYPE)\n",
    "\n",
    "            Xfeat = np.asarray(\n",
    "                state_to_features(float(state[0]), float(state[1]), float(state[2]), float(state[3]), float(u0), dtype=NP_DTYPE),\n",
    "                dtype=NP_DTYPE\n",
    "            )\n",
    "            dx     = float(train_next_state[0] - state[0])\n",
    "            dxdot  = float(train_next_state[1] - state[1])\n",
    "            dth    = float(wrap_pi(train_next_state[2] - state[2]))\n",
    "            dthdot = float(train_next_state[3] - state[3])\n",
    "\n",
    "            X_new_buf.append(Xfeat)\n",
    "            Ydx_new_buf.append([dx])\n",
    "            Ydxdot_new_buf.append([dxdot])\n",
    "            Ydth_new_buf.append([dth])\n",
    "            Ydthdot_new_buf.append([dthdot])\n",
    "\n",
    "            # upright streak\n",
    "            good = (np.cos(next_state[2]) >= UPRIGHT_COS) and (abs(next_state[0] - x_init) <= X_BAND)\n",
    "            upright_streak = (upright_streak + 1) if good else 0\n",
    "\n",
    "            # --- tube subset (deterministic chi-square mass tube, alpha=0.99) ---\n",
    "            subset_idx, tube_mean, tube_cov, cand_idx, chi2_thr = select_tube_subset(\n",
    "                model=m_dx,\n",
    "                rollout_inputs=rollout_inputs,\n",
    "                rollout_weights=weights,\n",
    "                total_subset_size=LOCAL_SUBSET_SIZE,\n",
    "                anchor_idx=anchors_idx,\n",
    "                time_bins=TUBE_NUM_BINS,\n",
    "                cov_eps=1e-6,\n",
    "                dopt_jitter=1e-6,\n",
    "                fallback_candidates=400,\n",
    "                alpha=TUBE_ALPHA,\n",
    "            )\n",
    "\n",
    "            # update locals\n",
    "            Zg_np = m_dx.inducing_variable.Z.numpy().astype(NP_DTYPE)\n",
    "            Zloc = Zg_np[np.asarray(subset_idx, dtype=np.int64)]\n",
    "            update_local_from_global_inplace(m_dx,     loc_dx,     Zloc)\n",
    "            update_local_from_global_inplace(m_dxdot,  loc_dxdot,  Zloc)\n",
    "            update_local_from_global_inplace(m_dth,    loc_dth,    Zloc)\n",
    "            update_local_from_global_inplace(m_dthdot, loc_dthdot, Zloc)\n",
    "\n",
    "            # advance\n",
    "            state = next_state\n",
    "            total_exec_steps += 1\n",
    "\n",
    "            # --- global retrain (timed) ---\n",
    "            if (total_exec_steps % RETRAIN_EVERY) == 0:\n",
    "                X_new = np.asarray(X_new_buf, dtype=NP_DTYPE)\n",
    "                Ydx_new     = np.asarray(Ydx_new_buf, dtype=NP_DTYPE)\n",
    "                Ydxdot_new  = np.asarray(Ydxdot_new_buf, dtype=NP_DTYPE)\n",
    "                Ydth_new    = np.asarray(Ydth_new_buf, dtype=NP_DTYPE)\n",
    "                Ydthdot_new = np.asarray(Ydthdot_new_buf, dtype=NP_DTYPE)\n",
    "\n",
    "                X_global       = np.concatenate([X_global,       X_new], axis=0)\n",
    "                Ydx_global     = np.concatenate([Ydx_global,     Ydx_new], axis=0)\n",
    "                Ydxdot_global  = np.concatenate([Ydxdot_global,  Ydxdot_new], axis=0)\n",
    "                Ydth_global    = np.concatenate([Ydth_global,    Ydth_new], axis=0)\n",
    "                Ydthdot_global = np.concatenate([Ydthdot_global, Ydthdot_new], axis=0)\n",
    "\n",
    "                t_tr0 = time.perf_counter()\n",
    "                retrain_global_burst(\n",
    "                    X_all=X_global,\n",
    "                    Y_dx=Ydx_global,\n",
    "                    Y_dxdot=Ydxdot_global,\n",
    "                    Y_dth=Ydth_global,\n",
    "                    Y_dthdot=Ydthdot_global,\n",
    "                    steps=RETRAIN_STEPS,\n",
    "                    batch_size=256,\n",
    "                    lr=RETRAIN_LR,\n",
    "                    seed=run_id*10_000 + ep*1_000 + step,\n",
    "                )\n",
    "                t_tr1 = time.perf_counter()\n",
    "                train_acc += (t_tr1 - t_tr0)\n",
    "\n",
    "                # refresh anchors after global changes\n",
    "                anchors_idx = select_global_anchors(m_dx, num_anchors=NUM_ANCHORS, dopt_jitter=1e-6)\n",
    "\n",
    "                # refresh locals on same subset (optional but consistent)\n",
    "                Zg_np = m_dx.inducing_variable.Z.numpy().astype(NP_DTYPE)\n",
    "                Zloc = Zg_np[np.asarray(subset_idx, dtype=np.int64)]\n",
    "                update_local_from_global_inplace(m_dx,     loc_dx,     Zloc)\n",
    "                update_local_from_global_inplace(m_dxdot,  loc_dxdot,  Zloc)\n",
    "                update_local_from_global_inplace(m_dth,    loc_dth,    Zloc)\n",
    "                update_local_from_global_inplace(m_dthdot, loc_dthdot, Zloc)\n",
    "\n",
    "                X_new_buf.clear(); Ydx_new_buf.clear(); Ydxdot_new_buf.clear(); Ydth_new_buf.clear(); Ydthdot_new_buf.clear()\n",
    "\n",
    "            # --- timing record (exclude rendering) ---\n",
    "            # wall time excludes visualization for a fair runtime curve\n",
    "            wall_now = (time.perf_counter() - t_run0) - (t_vis1 - t_vis0)\n",
    "            wall_time_cum.append(float(wall_now))\n",
    "            train_time_cum.append(float(train_acc))\n",
    "\n",
    "            # success condition\n",
    "            if upright_streak >= HOLD_GOAL:\n",
    "                break\n",
    "\n",
    "        # episode render (outside timing)\n",
    "        show_gif(ep_frames, fps=FPS_RENDER)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    run_wall_traces.append(np.asarray(wall_time_cum, dtype=NP_DTYPE))\n",
    "    run_train_traces.append(np.asarray(train_time_cum, dtype=NP_DTYPE))\n",
    "\n",
    "    # snapshot model params for surfaces\n",
    "    run_models_snap.append({\n",
    "        \"dx\":     parameter_dict(m_dx),\n",
    "        \"dxdot\":  parameter_dict(m_dxdot),\n",
    "        \"dth\":    parameter_dict(m_dth),\n",
    "        \"dthdot\": parameter_dict(m_dthdot),\n",
    "    })\n",
    "\n",
    "# -----------------------\n",
    "# Mean curves over runs (pad with NaNs)\n",
    "# -----------------------\n",
    "maxT = max(len(a) for a in run_wall_traces)\n",
    "W = np.full((N_RUNS, maxT), np.nan, dtype=NP_DTYPE)\n",
    "Tr = np.full((N_RUNS, maxT), np.nan, dtype=NP_DTYPE)\n",
    "\n",
    "for r in range(N_RUNS):\n",
    "    W[r, :len(run_wall_traces[r])] = run_wall_traces[r]\n",
    "    Tr[r, :len(run_train_traces[r])] = run_train_traces[r]\n",
    "\n",
    "mean_wall = np.nanmean(W, axis=0)\n",
    "mean_train = np.nanmean(Tr, axis=0)\n",
    "\n",
    "# -----------------------\n",
    "# Plot: wall time vs timestep + training time vs timestep (means)\n",
    "# -----------------------\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(mean_wall)\n",
    "plt.xlabel(\"timestep\")\n",
    "plt.ylabel(\"cumulative wall time (s)\")\n",
    "plt.title(f\"Mean cumulative wall time vs timestep (N_RUNS={N_RUNS})\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(mean_train)\n",
    "plt.xlabel(\"timestep\")\n",
    "plt.ylabel(\"cumulative training time (s)\")\n",
    "plt.title(f\"Mean cumulative training time vs timestep (N_RUNS={N_RUNS})\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Restore each run's final model and plot learned surfaces\n",
    "# -----------------------\n",
    "for run_id in range(N_RUNS):\n",
    "    multiple_assign(m_dx,     run_models_snap[run_id][\"dx\"])\n",
    "    multiple_assign(m_dxdot,  run_models_snap[run_id][\"dxdot\"])\n",
    "    multiple_assign(m_dth,    run_models_snap[run_id][\"dth\"])\n",
    "    multiple_assign(m_dthdot, run_models_snap[run_id][\"dthdot\"])\n",
    "\n",
    "    plot_learned_surfaces_for_run(\n",
    "        run_id=run_id,\n",
    "        m_dx=m_dx, m_dxdot=m_dxdot, m_dth=m_dth, m_dthdot=m_dthdot,\n",
    "        x_lim=2.4, th_lim=np.pi, nx=121, nth=121,\n",
    "        xdot0=0.0, thdot0=0.0, u0=0.0\n",
    "    )\n"
   ],
   "id": "aa86faf39f677870",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cffe10f892ba985c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
