{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 1 — Acrobot ONLY (Custom Continuous Acrobot Env)\n",
    "#   - Continuous torque action u in [-1, +1]\n",
    "#   - Observation: [cos(th1), sin(th1), cos(th2), sin(th2), thdot1, thdot2]\n",
    "#   - State (for modeling): (th1, th2, thdot1, thdot2)\n",
    "#   - Reward: -1 per step until terminal (Acrobot spirit)\n",
    "#   - Terminal: (-cos(th1) - cos(th1+th2)) > 1.0\n",
    "#   - TimeLimit wrapper supported via make_env(...)\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from gymnasium.utils import seeding\n",
    "\n",
    "# ----------------------------\n",
    "# TF GPU setup (sanity)\n",
    "# ----------------------------\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"TF built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs visible:\", gpus)\n",
    "print(\"Logical GPUs:\", tf.config.list_logical_devices(\"GPU\"))\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# ----------------------------\n",
    "# Dtypes\n",
    "# ----------------------------\n",
    "DTYPE_NP = np.float64\n",
    "U_MIN, U_MAX = -1.0, +1.0\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def wrap_pi(x):\n",
    "    return (x + np.pi) % (2.0 * np.pi) - np.pi\n",
    "\n",
    "def obs_to_state(obs):\n",
    "    \"\"\"\n",
    "    Acrobot observation:\n",
    "      obs = [cos(th1), sin(th1), cos(th2), sin(th2), thdot1, thdot2]\n",
    "    Convert to (th1, th2, thdot1, thdot2).\n",
    "    \"\"\"\n",
    "    c1, s1, c2, s2, thdot1, thdot2 = map(float, obs)\n",
    "    th1 = wrap_pi(math.atan2(s1, c1))\n",
    "    th2 = wrap_pi(math.atan2(s2, c2))\n",
    "    return np.array([th1, th2, thdot1, thdot2], dtype=DTYPE_NP)\n",
    "\n",
    "def state_to_features(th1, th2, thdot1, thdot2, u,\n",
    "                      w1_scale=8.0, w2_scale=10.0,\n",
    "                      dtype=DTYPE_NP):\n",
    "    \"\"\"\n",
    "    Default bounded feature map (D=7):\n",
    "      [sin(th1), cos(th1), sin(th2), cos(th2), tanh(thdot1/w1), tanh(thdot2/w2), u]\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [np.sin(th1), np.cos(th1), np.sin(th2), np.cos(th2),\n",
    "         np.tanh(thdot1 / w1_scale), np.tanh(thdot2 / w2_scale),\n",
    "         float(u)],\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Custom Continuous Acrobot Env\n",
    "# ----------------------------\n",
    "class ContinuousAcrobotEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"rgb_array\", \"human\"], \"render_fps\": 15}\n",
    "\n",
    "    def __init__(self, render_mode=None, torque_mag=1.0, dt=0.2,\n",
    "                 max_vel1=4*np.pi, max_vel2=9*np.pi):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # Standard-ish Acrobot params (close to classic-control)\n",
    "        self.LINK_LENGTH_1 = 1.0\n",
    "        self.LINK_LENGTH_2 = 1.0\n",
    "        self.LINK_MASS_1 = 1.0\n",
    "        self.LINK_MASS_2 = 1.0\n",
    "        self.LINK_COM_POS_1 = 0.5\n",
    "        self.LINK_COM_POS_2 = 0.5\n",
    "        self.LINK_MOI = 1.0\n",
    "        self.g = 9.8\n",
    "\n",
    "        self.dt = float(dt)\n",
    "        self.torque_mag = float(torque_mag)\n",
    "        self.max_vel1 = float(max_vel1)\n",
    "        self.max_vel2 = float(max_vel2)\n",
    "\n",
    "        # Continuous action u in [-1,1], scaled by torque_mag\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0], dtype=np.float32),\n",
    "            high=np.array([+1.0], dtype=np.float32),\n",
    "            shape=(1,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Observation: [cos(th1), sin(th1), cos(th2), sin(th2), thdot1, thdot2]\n",
    "        high = np.array([1.0, 1.0, 1.0, 1.0, self.max_vel1, self.max_vel2], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.np_random = None\n",
    "        self.state = None  # (th1, th2, thdot1, thdot2)\n",
    "        self.seed()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _terminal(self, th1, th2):\n",
    "        # Same idea as classic Acrobot-v1: tip above threshold\n",
    "        # y = -cos(th1) - cos(th1+th2); terminal if y > 1\n",
    "        return (-math.cos(th1) - math.cos(th1 + th2)) > 1.0\n",
    "\n",
    "    def _get_obs(self):\n",
    "        th1, th2, thdot1, thdot2 = self.state\n",
    "        return np.array([\n",
    "            math.cos(th1), math.sin(th1),\n",
    "            math.cos(th2), math.sin(th2),\n",
    "            thdot1, thdot2\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "\n",
    "        # Small random init near downward-ish\n",
    "        th1 = float(self.np_random.uniform(low=-0.1, high=0.1))\n",
    "        th2 = float(self.np_random.uniform(low=-0.1, high=0.1))\n",
    "        thdot1 = float(self.np_random.uniform(low=-0.1, high=0.1))\n",
    "        thdot2 = float(self.np_random.uniform(low=-0.1, high=0.1))\n",
    "\n",
    "        self.state = (wrap_pi(th1), wrap_pi(th2), thdot1, thdot2)\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.asarray(action, dtype=np.float32).reshape(1,)\n",
    "        assert self.action_space.contains(action), f\"{action} invalid\"\n",
    "\n",
    "        u = float(np.clip(action[0], -1.0, 1.0)) * self.torque_mag\n",
    "\n",
    "        th1, th2, thdot1, thdot2 = self.state\n",
    "\n",
    "        # --- Dynamics (standard acrobot equations; torque applied at joint 2) ---\n",
    "        m1 = self.LINK_MASS_1\n",
    "        m2 = self.LINK_MASS_2\n",
    "        l1 = self.LINK_LENGTH_1\n",
    "        l2 = self.LINK_LENGTH_2\n",
    "        lc1 = self.LINK_COM_POS_1\n",
    "        lc2 = self.LINK_COM_POS_2\n",
    "        I1 = self.LINK_MOI\n",
    "        I2 = self.LINK_MOI\n",
    "        g = self.g\n",
    "\n",
    "        d1 = m1*lc1**2 + m2*(l1**2 + lc2**2 + 2*l1*lc2*math.cos(th2)) + I1 + I2\n",
    "        d2 = m2*(lc2**2 + l1*lc2*math.cos(th2)) + I2\n",
    "\n",
    "        phi2 = m2*lc2*g*math.cos(th1 + th2 - math.pi/2.0)\n",
    "        phi1 = (-m2*l1*lc2*(thdot2**2)*math.sin(th2)\n",
    "                - 2*m2*l1*lc2*thdot2*thdot1*math.sin(th2)\n",
    "                + (m1*lc1 + m2*l1)*g*math.cos(th1 - math.pi/2.0)\n",
    "                + phi2)\n",
    "\n",
    "        denom = (m2*lc2**2 + I2 - (d2**2)/d1)\n",
    "        if abs(denom) < 1e-10:\n",
    "            denom = 1e-10\n",
    "\n",
    "        thddot2 = (u + (d2/d1)*phi1 - m2*l1*lc2*(thdot1**2)*math.sin(th2) - phi2) / denom\n",
    "        thddot1 = -(d2*thddot2 + phi1) / d1\n",
    "\n",
    "        # Integrate\n",
    "        thdot1 = thdot1 + self.dt * thddot1\n",
    "        thdot2 = thdot2 + self.dt * thddot2\n",
    "\n",
    "        # Clamp velocities\n",
    "        thdot1 = float(np.clip(thdot1, -self.max_vel1, self.max_vel1))\n",
    "        thdot2 = float(np.clip(thdot2, -self.max_vel2, self.max_vel2))\n",
    "\n",
    "        th1 = wrap_pi(th1 + self.dt * thdot1)\n",
    "        th2 = wrap_pi(th2 + self.dt * thdot2)\n",
    "\n",
    "        self.state = (th1, th2, thdot1, thdot2)\n",
    "\n",
    "        terminated = False\n",
    "        truncated = False  # TimeLimit wrapper will handle truncation\n",
    "\n",
    "        # Reward: -1 per step until success; 0 at terminal (common Acrobot convention)\n",
    "        reward = 0.0 if terminated else -1.0\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = {\"u\": float(u), \"th1\": th1, \"th2\": th2, \"thdot1\": thdot1, \"thdot2\": thdot2}\n",
    "        return obs, float(reward), terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        return None\n",
    "\n",
    "    def close(self):\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# Factory (keep the same name make_env for later cells)\n",
    "# ----------------------------\n",
    "MAX_EPISODE_STEPS = 2000\n",
    "\n",
    "def make_env(render_mode=None, seed=0, max_episode_steps=MAX_EPISODE_STEPS,\n",
    "             torque_mag=1.0, dt=0.2):\n",
    "    env = ContinuousAcrobotEnv(render_mode=render_mode, torque_mag=torque_mag, dt=dt)\n",
    "    env = TimeLimit(env, max_episode_steps=max_episode_steps)\n",
    "    env.reset(seed=seed)\n",
    "    return env\n",
    "\n",
    "# ----------------------------\n",
    "# Quick sanity test\n",
    "# ----------------------------\n",
    "env = make_env(render_mode=None, seed=0)\n",
    "obs, _ = env.reset(seed=0)\n",
    "s = obs_to_state(obs)\n",
    "\n",
    "print(\"✅ ContinuousAcrobot ready\")\n",
    "print(\"obs shape:\", obs.shape, \"obs:\", obs)\n",
    "print(\"state (th1, th2, thdot1, thdot2):\", s)\n",
    "print(\"action_space:\", env.action_space, \"sample:\", env.action_space.sample())\n",
    "\n",
    "# step a few times\n",
    "for i in range(3):\n",
    "    a = env.action_space.sample()\n",
    "    obs2, r, term, trunc, info = env.step(a)\n",
    "    print(f\"step {i}: r={r}, term={term}, info_u={info['u']:.3f}\")\n",
    "\n",
    "env.close()\n"
   ],
   "id": "6eb2d796ef722ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 2 — Random collection path + render + collect (X,Y)  ✅ Acrobot version\n",
    "#\n",
    "# \"Everybody's Acrobot\" conventions:\n",
    "#   - obs = [cos(th1), sin(th1), cos(th2), sin(th2), thdot1, thdot2]\n",
    "#   - success proxy height: y_tip = -cos(th1) - cos(th1+th2)\n",
    "#   - terminal when y_tip > 1.0 (env already uses this)\n",
    "#\n",
    "# What you get:\n",
    "#   - Random actions for n_steps\n",
    "#   - Collect executed transitions:\n",
    "#       X0: (N,7) = [sin th1, cos th1, sin th2, cos th2, tanh(w1/s1), tanh(w2/s2), u]\n",
    "#       Ydth1, Ydth2, Ydw1, Ydw2  (each (N,1))\n",
    "#   - Simple stick-figure rendering (pure PIL) + inline animation\n",
    "#   - Plots:\n",
    "#       y_tip(t), theta1/2(t), w1/2(t), u(t), phase plots\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# ----------------------------\n",
    "# Safety: require Cell 1 symbols\n",
    "# ----------------------------\n",
    "required = [\n",
    "    \"make_env\", \"obs_to_state\", \"wrap_pi\",\n",
    "    \"state_to_features\", \"U_MIN\", \"U_MAX\"\n",
    "]\n",
    "missing = [k for k in required if k not in globals()]\n",
    "if len(missing) > 0:\n",
    "    raise NameError(f\"Cell 2 missing required symbols from Cell 1: {missing}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Simple stick-figure renderer for Acrobot (pure PIL)\n",
    "# ----------------------------\n",
    "def render_acrobot_frame_from_state(\n",
    "    th1, th2,\n",
    "    W=720, H=450,\n",
    "    link1_px=150,\n",
    "    link2_px=150,\n",
    "    joint_r=10,\n",
    "    link_w=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw 2-link acrobot:\n",
    "      base at center-top-ish, link1 angle th1 from vertical,\n",
    "      link2 angle th2 relative to link1 (standard Acrobot convention).\n",
    "    \"\"\"\n",
    "    img = Image.new(\"RGB\", (W, H), (245, 245, 245))\n",
    "    dr = ImageDraw.Draw(img)\n",
    "\n",
    "    # base position\n",
    "    cx = int(W * 0.5)\n",
    "    cy = int(H * 0.28)\n",
    "\n",
    "    # coordinate system: y down in image\n",
    "    # convention:\n",
    "    #   link1 vector: (dx1, dy1) = (L1*sin(th1), L1*cos(th1))\n",
    "    #   because th1=0 means pointing DOWN (classic acrobot); that's okay visually\n",
    "    x1 = cx + int(link1_px * np.sin(th1))\n",
    "    y1 = cy + int(link1_px * np.cos(th1))\n",
    "\n",
    "    th12 = th1 + th2\n",
    "    x2 = x1 + int(link2_px * np.sin(th12))\n",
    "    y2 = y1 + int(link2_px * np.cos(th12))\n",
    "\n",
    "    # draw ground/reference line\n",
    "    dr.line([(0, cy), (W, cy)], fill=(220, 220, 220), width=3)\n",
    "\n",
    "    # draw links\n",
    "    dr.line([(cx, cy), (x1, y1)], fill=(60, 90, 160), width=link_w)\n",
    "    dr.line([(x1, y1), (x2, y2)], fill=(180, 50, 50), width=link_w)\n",
    "\n",
    "    # joints\n",
    "    def circ(x, y, r, col):\n",
    "        dr.ellipse([x-r, y-r, x+r, y+r], fill=col, outline=(25, 25, 25), width=2)\n",
    "\n",
    "    circ(cx, cy, joint_r, (30, 30, 30))\n",
    "    circ(x1, y1, joint_r, (30, 30, 30))\n",
    "    circ(x2, y2, joint_r, (30, 30, 30))\n",
    "\n",
    "    return np.asarray(img, dtype=np.uint8)\n",
    "\n",
    "# ----------------------------\n",
    "# Acrobot \"everybody metric\": tip height proxy\n",
    "# ----------------------------\n",
    "def acrobot_tip_height_proxy(th1, th2):\n",
    "    # classic acrobot uses: y = -cos(th1) - cos(th1+th2)\n",
    "    return float(-np.cos(th1) - np.cos(th1 + th2))\n",
    "\n",
    "# ----------------------------\n",
    "# Random collection (rendered)\n",
    "# ----------------------------\n",
    "def collect_random_transitions_rendered_acrobot(\n",
    "    n_steps=2000,\n",
    "    seed=0,\n",
    "    max_episode_steps=2000,\n",
    "    # env params\n",
    "    torque_mag=1.0,\n",
    "    dt=0.2,\n",
    "    # rendering\n",
    "    record_rgb=True,\n",
    "    frame_stride=3,\n",
    "    resize=(720, 450),\n",
    "    fps=15,\n",
    "    # reset behavior\n",
    "    reset_on_done=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    env = make_env(\n",
    "        render_mode=None,\n",
    "        seed=seed,\n",
    "        max_episode_steps=max_episode_steps,\n",
    "        torque_mag=torque_mag,\n",
    "        dt=dt\n",
    "    )\n",
    "\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    s = obs_to_state(obs)  # (th1, th2, w1, w2)\n",
    "    th1, th2, w1, w2 = map(float, s)\n",
    "\n",
    "    X_list, Ydth1_list, Ydth2_list, Ydw1_list, Ydw2_list = [], [], [], [], []\n",
    "\n",
    "    traj_th1, traj_th2, traj_w1, traj_w2, traj_u, traj_y = [], [], [], [], [], []\n",
    "    frames = []\n",
    "    resets = 0\n",
    "    terminals = 0\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        u = float(rng.uniform(U_MIN, U_MAX))\n",
    "\n",
    "        obs2, reward, terminated, truncated, info = env.step(np.array([u], dtype=np.float32))\n",
    "        s2 = obs_to_state(obs2)\n",
    "        th1_2, th2_2, w1_2, w2_2 = map(float, s2)\n",
    "\n",
    "        # collect GP transition (delta targets)\n",
    "        X_list.append(state_to_features(th1, th2, w1, w2, u))\n",
    "        Ydth1_list.append([wrap_pi(th1_2 - th1)])\n",
    "        Ydth2_list.append([wrap_pi(th2_2 - th2)])\n",
    "        Ydw1_list.append([w1_2 - w1])\n",
    "        Ydw2_list.append([w2_2 - w2])\n",
    "\n",
    "        # log traj\n",
    "        traj_th1.append(th1); traj_th2.append(th2)\n",
    "        traj_w1.append(w1);   traj_w2.append(w2)\n",
    "        traj_u.append(u)\n",
    "        traj_y.append(acrobot_tip_height_proxy(th1, th2))\n",
    "\n",
    "        # render\n",
    "        if record_rgb and ((t % frame_stride) == 0):\n",
    "            W, H = int(resize[0]), int(resize[1])\n",
    "            frames.append(render_acrobot_frame_from_state(th1_2, th2_2, W=W, H=H))\n",
    "\n",
    "        # advance\n",
    "        th1, th2, w1, w2 = th1_2, th2_2, w1_2, w2_2\n",
    "\n",
    "        if terminated or truncated:\n",
    "            terminals += int(terminated)\n",
    "            if reset_on_done:\n",
    "                resets += 1\n",
    "                obs, info = env.reset(seed=int(seed + 1000 + t))\n",
    "                s = obs_to_state(obs)\n",
    "                th1, th2, w1, w2 = map(float, s)\n",
    "                if verbose:\n",
    "                    print(f\"[t={t:04d}] reset (terminated={terminated}, truncated={truncated})\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    X0 = np.asarray(X_list, dtype=np.float64)\n",
    "    Ydth1 = np.asarray(Ydth1_list, dtype=np.float64).reshape(-1, 1)\n",
    "    Ydth2 = np.asarray(Ydth2_list, dtype=np.float64).reshape(-1, 1)\n",
    "    Ydw1  = np.asarray(Ydw1_list, dtype=np.float64).reshape(-1, 1)\n",
    "    Ydw2  = np.asarray(Ydw2_list, dtype=np.float64).reshape(-1, 1)\n",
    "\n",
    "    traj = dict(\n",
    "        th1=np.asarray(traj_th1, dtype=np.float64),\n",
    "        th2=np.asarray(traj_th2, dtype=np.float64),\n",
    "        w1=np.asarray(traj_w1, dtype=np.float64),\n",
    "        w2=np.asarray(traj_w2, dtype=np.float64),\n",
    "        u=np.asarray(traj_u, dtype=np.float64),\n",
    "        y_tip=np.asarray(traj_y, dtype=np.float64),\n",
    "        resets=int(resets),\n",
    "        terminals=int(terminals),\n",
    "        steps=int(n_steps),\n",
    "        kept=int(X0.shape[0]),\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) animation\n",
    "    # ----------------------------\n",
    "    if record_rgb and (len(frames) > 0):\n",
    "        fig = plt.figure(figsize=(resize[0] / 100, resize[1] / 100), dpi=100)\n",
    "        plt.axis(\"off\")\n",
    "        im = plt.imshow(frames[0])\n",
    "\n",
    "        def animate_fn(i):\n",
    "            im.set_data(frames[i])\n",
    "            return [im]\n",
    "\n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, animate_fn,\n",
    "            frames=len(frames),\n",
    "            interval=1000 / float(fps),\n",
    "            blit=True\n",
    "        )\n",
    "        plt.close(fig)\n",
    "        display(HTML(ani.to_jshtml()))\n",
    "    else:\n",
    "        print(\"⚠️ No frames collected (record_rgb=False or frame_stride too large).\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) plots (Acrobot standard)\n",
    "    # ----------------------------\n",
    "    T = len(traj[\"th1\"])\n",
    "    tgrid = np.arange(T)\n",
    "\n",
    "    plt.figure(figsize=(9, 3.2))\n",
    "    plt.plot(tgrid, traj[\"y_tip\"], linewidth=2)\n",
    "    plt.axhline(1.0, linestyle=\"--\", linewidth=2)\n",
    "    plt.xlabel(\"t\"); plt.ylabel(\"y_tip = -cos(th1) - cos(th1+th2)\")\n",
    "    plt.title(\"Acrobot swing-up progress (tip height proxy)\")\n",
    "    plt.grid(True, alpha=0.25); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 3.2))\n",
    "    plt.plot(tgrid, traj[\"th1\"], linewidth=2, label=\"th1\")\n",
    "    plt.plot(tgrid, traj[\"th2\"], linewidth=2, label=\"th2\")\n",
    "    plt.xlabel(\"t\"); plt.ylabel(\"angle (rad)\")\n",
    "    plt.title(\"Angles (wrapped)\")\n",
    "    plt.grid(True, alpha=0.25); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 3.2))\n",
    "    plt.plot(tgrid, traj[\"w1\"], linewidth=2, label=\"w1\")\n",
    "    plt.plot(tgrid, traj[\"w2\"], linewidth=2, label=\"w2\")\n",
    "    plt.xlabel(\"t\"); plt.ylabel(\"angular velocity (rad/s)\")\n",
    "    plt.title(\"Angular velocities\")\n",
    "    plt.grid(True, alpha=0.25); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 3.0))\n",
    "    plt.plot(tgrid, traj[\"u\"], linewidth=2)\n",
    "    plt.xlabel(\"t\"); plt.ylabel(\"u (torque command)\")\n",
    "    plt.title(\"Random continuous actions u(t)\")\n",
    "    plt.grid(True, alpha=0.25); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6.2, 5.2))\n",
    "    plt.scatter(traj[\"th1\"], traj[\"w1\"], s=10, alpha=0.5)\n",
    "    plt.xlabel(\"th1\"); plt.ylabel(\"w1\")\n",
    "    plt.title(\"Phase: th1 vs w1\")\n",
    "    plt.grid(True, alpha=0.25); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6.2, 5.2))\n",
    "    plt.scatter(traj[\"th2\"], traj[\"w2\"], s=10, alpha=0.5)\n",
    "    plt.xlabel(\"th2\"); plt.ylabel(\"w2\")\n",
    "    plt.title(\"Phase: th2 vs w2\")\n",
    "    plt.grid(True, alpha=0.25); plt.tight_layout(); plt.show()\n",
    "\n",
    "    print(\"Collected X0 shape:\", X0.shape, \" (features)\")\n",
    "    print(\"Targets shapes:\", Ydth1.shape, Ydth2.shape, Ydw1.shape, Ydw2.shape)\n",
    "    print(f\"Kept={traj['kept']}  resets={traj['resets']}  terminals={traj['terminals']}\")\n",
    "\n",
    "    return X0, Ydth1, Ydth2, Ydw1, Ydw2, frames, traj\n",
    "\n",
    "\n",
    "# ---- run it ----\n",
    "SEED = 0\n",
    "X0, Ydth1_0, Ydth2_0, Ydw1_0, Ydw2_0, frames0, traj0 = collect_random_transitions_rendered_acrobot(\n",
    "    n_steps=6000,\n",
    "    seed=SEED,\n",
    "    max_episode_steps=2000,\n",
    "    torque_mag=1.0,\n",
    "    dt=0.2,\n",
    "    record_rgb=True,\n",
    "    frame_stride=3,\n",
    "    resize=(720, 450),\n",
    "    fps=15,\n",
    "    reset_on_done=True,\n",
    "    verbose=False,\n",
    ")\n"
   ],
   "id": "8595a10710cb7901",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Cell 3 — OSGPR-VFE core (Streaming Sparse GP) + training + summaries + anchors  ✅ ACROBOT\n",
    "#\n",
    "# Same OSGPR/VFE machinery as your CartPole pipeline, but with the ACROBOT feature map:\n",
    "#   - State S is (B,4) = [th1, th2, w1, w2]\n",
    "#   - Features are 7D: [sin(th1), cos(th1), sin(th2), cos(th2), tanh(w1/s1), tanh(w2/s2), u]\n",
    "#\n",
    "# Provides:\n",
    "#   - batch_state_to_features(): (B,4)+(B,) -> (B,7)   ✅ Acrobot\n",
    "#   - OSGPR_VFE (single-output)\n",
    "#   - train_osgpr()\n",
    "#   - prior_summary(), extract_summary_from_model()\n",
    "#   - greedy_dopt_anchors_from_K()\n",
    "#   - rebuild_osgpr_from_old_summary(): returns (model_new, train_time, neg_obj)\n",
    "# ===========================\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "from gpflow.models import GPModel, InternalDataTrainingLossMixin\n",
    "from gpflow import covariances\n",
    "\n",
    "# ---- numerics ----\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "print(\"TF built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "try:\n",
    "    print(\"GPUs visible:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "except Exception as e:\n",
    "    print(\"GPU query failed:\", e)\n",
    "\n",
    "DTYPE = gpflow.default_float()\n",
    "\n",
    "# ---------------------------\n",
    "# helpers\n",
    "# ---------------------------\n",
    "def sym_jitter(A, jitter=1e-6):\n",
    "    \"\"\"Make symmetric + add jitter (numpy).\"\"\"\n",
    "    A = np.asarray(A, dtype=np.float64)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    A = A + float(jitter) * np.eye(A.shape[0], dtype=np.float64)\n",
    "    return A\n",
    "\n",
    "def finite_mask(*arrs):\n",
    "    \"\"\"Row-wise finite mask across arrays.\"\"\"\n",
    "    m = None\n",
    "    for a in arrs:\n",
    "        a = np.asarray(a)\n",
    "        mm = np.isfinite(a).all(axis=1) if a.ndim == 2 else np.isfinite(a)\n",
    "        m = mm if m is None else (m & mm)\n",
    "    return m\n",
    "\n",
    "def clone_kernel(kernel):\n",
    "    \"\"\"\n",
    "    Clone a GPflow kernel (to avoid variable-sharing across models).\n",
    "    gpflow.utilities.deepcopy exists in many versions; fallback to copy.deepcopy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from gpflow.utilities import deepcopy as gf_deepcopy\n",
    "        return gf_deepcopy(kernel)\n",
    "    except Exception:\n",
    "        return copy.deepcopy(kernel)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Batch feature map (FAST) — used by MPPI later  ✅ ACROBOT\n",
    "# ------------------------------------------------------------\n",
    "def batch_state_to_features(S, U, w1_scale=8.0, w2_scale=10.0):\n",
    "    \"\"\"\n",
    "    Vectorized mapping from Acrobot state to 7D GP features.\n",
    "\n",
    "    S: (B,4)  [th1, th2, w1, w2]\n",
    "    U: (B,)   action in [-1,1]  (or env action bounds)\n",
    "    Returns:\n",
    "      Xfeat: (B,7) [sin(th1), cos(th1), sin(th2), cos(th2),\n",
    "                    tanh(w1/w1_scale), tanh(w2/w2_scale), u]\n",
    "    \"\"\"\n",
    "    S = np.asarray(S, dtype=np.float64)\n",
    "    U = np.asarray(U, dtype=np.float64).reshape(-1)\n",
    "    assert S.ndim == 2 and S.shape[1] == 4, \"S must be (B,4)=[th1, th2, w1, w2]\"\n",
    "    assert U.shape[0] == S.shape[0], \"U must match batch size\"\n",
    "\n",
    "    th1 = S[:, 0]\n",
    "    th2 = S[:, 1]\n",
    "    w1  = S[:, 2]\n",
    "    w2  = S[:, 3]\n",
    "\n",
    "    Xf = np.empty((S.shape[0], 7), dtype=np.float64)\n",
    "    Xf[:, 0] = np.sin(th1)\n",
    "    Xf[:, 1] = np.cos(th1)\n",
    "    Xf[:, 2] = np.sin(th2)\n",
    "    Xf[:, 3] = np.cos(th2)\n",
    "    Xf[:, 4] = np.tanh(w1 / w1_scale)\n",
    "    Xf[:, 5] = np.tanh(w2 / w2_scale)\n",
    "    Xf[:, 6] = U\n",
    "    return Xf\n",
    "\n",
    "# ============================================================\n",
    "# OSGPR-VFE model — regression-only, single-output\n",
    "# ============================================================\n",
    "class OSGPR_VFE(GPModel, InternalDataTrainingLossMixin):\n",
    "    \"\"\"\n",
    "    Online Sparse Variational GP Regression (VFE), SINGLE-OUTPUT.\n",
    "\n",
    "    Provide:\n",
    "      - current batch data (X, Y)\n",
    "      - old summary q_old(u)=N(mu_old, Su_old) at Z_old\n",
    "      - Kaa_old = K(Z_old,Z_old) from old step\n",
    "      - new inducing Z (usually Z_GLOBAL; you MAY refresh Z over time, but size should be capped)\n",
    "\n",
    "    Includes:\n",
    "      - predict_f (correct but slower)\n",
    "      - build_predict_cache + predict_f_cached (FAST diag predictions)\n",
    "    \"\"\"\n",
    "    def __init__(self, data, kernel, mu_old, Su_old, Kaa_old, Z_old, Z, mean_function=None):\n",
    "        X, Y = gpflow.models.util.data_input_to_tensor(data)\n",
    "        self.X, self.Y = X, Y\n",
    "\n",
    "        likelihood = gpflow.likelihoods.Gaussian()\n",
    "        num_latent_gps = GPModel.calc_num_latent_gps_from_data(data, kernel, likelihood)\n",
    "        super().__init__(kernel, likelihood, mean_function, num_latent_gps)\n",
    "\n",
    "        Z = np.asarray(Z, dtype=np.float64)\n",
    "        assert Z.ndim == 2, \"Z must be (M, D)\"\n",
    "        self.inducing_variable = InducingPoints(Z)\n",
    "        gpflow.set_trainable(self.inducing_variable, False)\n",
    "\n",
    "        mu_old  = np.asarray(mu_old, dtype=np.float64).reshape(-1, 1)\n",
    "        Su_old  = sym_jitter(Su_old, 1e-6)\n",
    "        Kaa_old = sym_jitter(Kaa_old, 1e-6)\n",
    "        Z_old   = np.asarray(Z_old, dtype=np.float64)\n",
    "\n",
    "        self.mu_old  = tf.Variable(mu_old,  trainable=False, dtype=DTYPE)\n",
    "        self.Su_old  = tf.Variable(Su_old,  trainable=False, dtype=DTYPE)\n",
    "        self.Kaa_old = tf.Variable(Kaa_old, trainable=False, dtype=DTYPE)\n",
    "        self.Z_old   = tf.Variable(Z_old,   trainable=False, dtype=DTYPE)\n",
    "\n",
    "        if self.mean_function is None:\n",
    "            self.mean_function = gpflow.mean_functions.Zero()\n",
    "\n",
    "        # cache for fast predict\n",
    "        self._cache_ready = False\n",
    "        self._cache_Lb = None\n",
    "        self._cache_LD = None\n",
    "        self._cache_rhs = None\n",
    "\n",
    "    def _common_terms(self):\n",
    "        \"\"\"\n",
    "        Build common matrices used by both ELBO and prediction.\n",
    "\n",
    "        Z   : new inducing (Mb)\n",
    "        Za  : old inducing (Ma) == self.Z_old\n",
    "        X   : current batch inputs\n",
    "\n",
    "        Kbf = K(Z, X)    [Mb, N]\n",
    "        Kbb = K(Z, Z)    [Mb, Mb]\n",
    "        Kba = K(Z, Za)   [Mb, Ma]\n",
    "        \"\"\"\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        sigma2 = self.likelihood.variance\n",
    "\n",
    "        Saa = self.Su_old  # [Ma,Ma]\n",
    "        ma  = self.mu_old  # [Ma,1]\n",
    "\n",
    "        Kbf = covariances.Kuf(self.inducing_variable, self.kernel, self.X)           # [Mb, N]\n",
    "        Kbb = covariances.Kuu(self.inducing_variable, self.kernel, jitter=jitter)   # [Mb, Mb]\n",
    "        Kba = covariances.Kuf(self.inducing_variable, self.kernel, self.Z_old)      # [Mb, Ma]\n",
    "\n",
    "        Kaa_cur = gpflow.utilities.add_noise_cov(self.kernel(self.Z_old), jitter)   # [Ma,Ma]\n",
    "        Kaa     = gpflow.utilities.add_noise_cov(self.Kaa_old, jitter)              # [Ma,Ma]\n",
    "\n",
    "        err = self.Y - self.mean_function(self.X)  # [N,1]\n",
    "\n",
    "        # c = Kbf*(Y/sigma2) + Kba*(Saa^{-1} ma)\n",
    "        Sainv_ma = tf.linalg.solve(Saa, ma)                                # [Ma,1]\n",
    "        c = tf.matmul(Kbf, self.Y / sigma2) + tf.matmul(Kba, Sainv_ma)     # [Mb,1]\n",
    "\n",
    "        # Cholesky(Kbb)\n",
    "        Lb = tf.linalg.cholesky(Kbb)                                       # [Mb,Mb]\n",
    "        Lbinv_c   = tf.linalg.triangular_solve(Lb, c,   lower=True)        # [Mb,1]\n",
    "        Lbinv_Kba = tf.linalg.triangular_solve(Lb, Kba, lower=True)        # [Mb,Ma]\n",
    "        Lbinv_Kbf = tf.linalg.triangular_solve(Lb, Kbf, lower=True) / tf.sqrt(sigma2)  # [Mb,N]\n",
    "\n",
    "        d1 = tf.matmul(Lbinv_Kbf, Lbinv_Kbf, transpose_b=True)             # [Mb,Mb]\n",
    "\n",
    "        # T = (Lb^{-1}Kba)^T  => [Ma,Mb]\n",
    "        T = tf.linalg.matrix_transpose(Lbinv_Kba)\n",
    "\n",
    "        # d2\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        LSainv_T = tf.linalg.triangular_solve(LSa, T, lower=True)\n",
    "        d2 = tf.matmul(LSainv_T, LSainv_T, transpose_a=True)               # [Mb,Mb]\n",
    "\n",
    "        # d3\n",
    "        La = tf.linalg.cholesky(Kaa)\n",
    "        Lainv_T = tf.linalg.triangular_solve(La, T, lower=True)\n",
    "        d3 = tf.matmul(Lainv_T, Lainv_T, transpose_a=True)                 # [Mb,Mb]\n",
    "\n",
    "        Mb = self.inducing_variable.num_inducing\n",
    "        D = tf.eye(Mb, dtype=DTYPE) + d1 + d2 - d3\n",
    "        D = gpflow.utilities.add_noise_cov(D, jitter)\n",
    "        LD = tf.linalg.cholesky(D)\n",
    "\n",
    "        rhs = tf.linalg.triangular_solve(LD, Lbinv_c, lower=True)          # [Mb,1]\n",
    "\n",
    "        Qff_diag = tf.reduce_sum(tf.square(Lbinv_Kbf), axis=0)             # [N]\n",
    "\n",
    "        tf.debugging.assert_all_finite(Lb,  \"Lb has NaN/Inf\")\n",
    "        tf.debugging.assert_all_finite(LD,  \"LD has NaN/Inf\")\n",
    "        tf.debugging.assert_all_finite(rhs, \"rhs has NaN/Inf\")\n",
    "\n",
    "        return (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD, Lbinv_Kba, rhs, err, Qff_diag)\n",
    "\n",
    "    def maximum_log_likelihood_objective(self):\n",
    "        sigma2 = self.likelihood.variance\n",
    "        N = tf.cast(tf.shape(self.X)[0], DTYPE)\n",
    "\n",
    "        Saa = self.Su_old\n",
    "        ma  = self.mu_old\n",
    "        Kfdiag = self.kernel(self.X, full_cov=False)\n",
    "\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, rhs, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        Lainv_ma = tf.linalg.triangular_solve(LSa, ma, lower=True)\n",
    "\n",
    "        bound = -0.5 * N * np.log(2.0 * np.pi)\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(err)) / sigma2\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(Lainv_ma))\n",
    "        bound +=  0.5 * tf.reduce_sum(tf.square(rhs))\n",
    "\n",
    "        bound += -0.5 * N * tf.math.log(sigma2)\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LD)))\n",
    "\n",
    "        bound += -0.5 * tf.reduce_sum(Kfdiag) / sigma2\n",
    "        bound +=  0.5 * tf.reduce_sum(Qff_diag)\n",
    "\n",
    "        bound += tf.reduce_sum(tf.math.log(tf.linalg.diag_part(La)))\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LSa)))\n",
    "\n",
    "        # correction term involving Kaa_cur - Qaa\n",
    "        Kaadiff = Kaa_cur - tf.matmul(Lbinv_Kba, Lbinv_Kba, transpose_a=True)\n",
    "        Sainv_Kaadiff = tf.linalg.solve(Saa, Kaadiff)\n",
    "        Kainv_Kaadiff = tf.linalg.solve(Kaa, Kaadiff)\n",
    "\n",
    "        bound += -0.5 * tf.reduce_sum(\n",
    "            tf.linalg.diag_part(Sainv_Kaadiff) - tf.linalg.diag_part(Kainv_Kaadiff)\n",
    "        )\n",
    "        return bound\n",
    "\n",
    "    def predict_f(self, Xnew, full_cov=False):\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "\n",
    "        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)  # [Mb, Nnew]\n",
    "        (_, _, _, _, _, _, Lb, _, LD, _, rhs, _, _) = self._common_terms()\n",
    "\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, rhs, transpose_a=True)  # [Nnew,1]\n",
    "\n",
    "        if full_cov:\n",
    "            Kss = self.kernel(Xnew) + jitter * tf.eye(tf.shape(Xnew)[0], dtype=DTYPE)\n",
    "            var = (\n",
    "                Kss\n",
    "                - tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n",
    "                + tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_Kbs, transpose_a=True)\n",
    "            )\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "        else:\n",
    "            var = (\n",
    "                self.kernel(Xnew, full_cov=False)\n",
    "                - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "                + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "            )\n",
    "            var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "\n",
    "    def build_predict_cache(self):\n",
    "        \"\"\"Build cached matrices for fast predict_f_cached(). Call after training / after each update.\"\"\"\n",
    "        (_, _, _, _, _, _, Lb, _, LD, _, rhs, _, _) = self._common_terms()\n",
    "        self._cache_Lb = Lb\n",
    "        self._cache_LD = LD\n",
    "        self._cache_rhs = rhs\n",
    "        self._cache_ready = True\n",
    "\n",
    "    def predict_f_cached(self, Xnew, full_cov=False):\n",
    "        \"\"\"Fast diag prediction using cached Lb, LD, rhs.\"\"\"\n",
    "        if not self._cache_ready:\n",
    "            return self.predict_f(Xnew, full_cov=full_cov)\n",
    "\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        Lb  = self._cache_Lb\n",
    "        LD  = self._cache_LD\n",
    "        rhs = self._cache_rhs\n",
    "\n",
    "        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)  # [Mb,Nnew]\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, rhs, transpose_a=True)\n",
    "\n",
    "        if full_cov:\n",
    "            Kss = self.kernel(Xnew) + jitter * tf.eye(tf.shape(Xnew)[0], dtype=DTYPE)\n",
    "            var = (\n",
    "                Kss\n",
    "                - tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n",
    "                + tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_Kbs, transpose_a=True)\n",
    "            )\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "        else:\n",
    "            var = (\n",
    "                self.kernel(Xnew, full_cov=False)\n",
    "                - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "                + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "            )\n",
    "            var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "\n",
    "# ----------------------------\n",
    "# training helper\n",
    "# ----------------------------\n",
    "def train_osgpr(model, iters=250, lr=0.02, clip_norm=10.0):\n",
    "    \"\"\"Adam optimize the negative ELBO.\"\"\"\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.maximum_log_likelihood_objective()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        if clip_norm is not None:\n",
    "            grads = [tf.clip_by_norm(g, clip_norm) if g is not None else None for g in grads]\n",
    "        opt.apply_gradients([(g, v) for g, v in zip(grads, model.trainable_variables) if g is not None])\n",
    "        return loss\n",
    "\n",
    "    t0 = time.time()\n",
    "    last = None\n",
    "    for _ in range(int(iters)):\n",
    "        last = step()\n",
    "    return float(time.time() - t0), float(last.numpy())\n",
    "\n",
    "# ----------------------------\n",
    "# summaries (to chain online)\n",
    "# ----------------------------\n",
    "def prior_summary(kernel, Z):\n",
    "    \"\"\"\n",
    "    Prior summary at inducing Z for the first model:\n",
    "      mu0 = 0\n",
    "      Su0 = Kzz\n",
    "      Kaa0 = Kzz\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float64)\n",
    "    Kzz = kernel.K(Z).numpy()\n",
    "    Kzz = sym_jitter(Kzz, 1e-6)\n",
    "    mu0 = np.zeros((Z.shape[0], 1), dtype=np.float64)\n",
    "    return mu0, Kzz, Kzz, Z\n",
    "\n",
    "def extract_summary_from_model(model):\n",
    "    \"\"\"\n",
    "    Extract q(u)=N(mu,Su) at model's current inducing Z plus Kaa=K(Z,Z).\n",
    "    \"\"\"\n",
    "    Z = model.inducing_variable.Z.numpy().astype(np.float64)\n",
    "\n",
    "    mu_tf, Sig_tf = model.predict_f(Z, full_cov=True)\n",
    "    mu = mu_tf.numpy().reshape(-1, 1)\n",
    "\n",
    "    Su = Sig_tf.numpy()\n",
    "    if Su.ndim == 3:\n",
    "        Su = Su[0]\n",
    "    Su = sym_jitter(Su, 1e-6)\n",
    "\n",
    "    Kaa = model.kernel.K(Z).numpy()\n",
    "    Kaa = sym_jitter(Kaa, 1e-6)\n",
    "    return mu, Su, Kaa, Z\n",
    "\n",
    "# ============================================================\n",
    "# Anchors: greedy D-opt (log-det) on Kzz\n",
    "# ============================================================\n",
    "def greedy_dopt_anchors_from_K(Kzz, m_anchors=24, lam=1e-6):\n",
    "    \"\"\"\n",
    "    Greedy log-det anchor selection on PSD Kzz using incremental Cholesky updates.\n",
    "    Returns indices of size m_anchors.\n",
    "    \"\"\"\n",
    "    K = np.asarray(Kzz, dtype=np.float64)\n",
    "    M = K.shape[0]\n",
    "    assert K.shape == (M, M)\n",
    "    K = sym_jitter(K, lam)\n",
    "\n",
    "    chosen = []\n",
    "    diag = np.clip(np.diag(K).copy(), 1e-12, None)\n",
    "    remaining = np.ones(M, dtype=bool)\n",
    "    L = None\n",
    "\n",
    "    for k in range(min(int(m_anchors), M)):\n",
    "        if k == 0:\n",
    "            i = int(np.argmax(diag))\n",
    "            chosen.append(i)\n",
    "            remaining[i] = False\n",
    "            L = np.array([[np.sqrt(diag[i])]], dtype=np.float64)\n",
    "            continue\n",
    "\n",
    "        S = np.array(chosen, dtype=np.int64)\n",
    "        Ks_all = K[np.ix_(S, np.arange(M))]     # (k,M)\n",
    "\n",
    "        v = np.linalg.solve(L, Ks_all)          # (k,M)\n",
    "        vn2 = np.sum(v * v, axis=0)             # (M,)\n",
    "        s2 = diag - vn2\n",
    "        s2 = np.where(remaining, s2, -np.inf)\n",
    "\n",
    "        i = int(np.argmax(s2))\n",
    "        if not np.isfinite(s2[i]) or s2[i] <= 1e-12:\n",
    "            cand = np.where(remaining)[0]\n",
    "            if len(cand) == 0:\n",
    "                break\n",
    "            i = int(cand[np.argmax(diag[cand])])\n",
    "            s2_i = max(diag[i], 1e-12)\n",
    "        else:\n",
    "            s2_i = float(s2[i])\n",
    "\n",
    "        chosen.append(i)\n",
    "        remaining[i] = False\n",
    "\n",
    "        kvec = K[np.ix_(S, [i])].reshape(-1, 1)  # (k,1)\n",
    "        w = np.linalg.solve(L, kvec)             # (k,1)\n",
    "        alpha = np.sqrt(max(s2_i, 1e-12))\n",
    "\n",
    "        L_new = np.zeros((k + 1, k + 1), dtype=np.float64)\n",
    "        L_new[:k, :k] = L\n",
    "        L_new[k, :k] = w.reshape(-1)\n",
    "        L_new[k, k] = alpha\n",
    "        L = L_new\n",
    "\n",
    "    return np.array(chosen, dtype=np.int64)\n",
    "\n",
    "# ============================================================\n",
    "# Online update builder (GLOBAL update step)\n",
    "# ============================================================\n",
    "def rebuild_osgpr_from_old_summary(\n",
    "    model_old,\n",
    "    X_new,\n",
    "    Y_new,\n",
    "    Z_new=None,\n",
    "    iters=120,\n",
    "    lr=0.02,\n",
    "    noise=1e-4,\n",
    "    freeze_kernel=False,\n",
    "    clip_norm=10.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a NEW OSGPR_VFE model using:\n",
    "      - old posterior summary extracted from model_old at its inducing Z_old\n",
    "      - new executed batch (X_new, Y_new)\n",
    "      - inducing set Z_new (defaults to model_old.Z; you may pass a refreshed Z here)\n",
    "\n",
    "    Returns:\n",
    "      model_new, train_time_sec, last_neg_obj\n",
    "    \"\"\"\n",
    "    # old summary\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(model_old)\n",
    "\n",
    "    # inducing set for the new model\n",
    "    if Z_new is None:\n",
    "        Z_use = Z_old\n",
    "    else:\n",
    "        Z_use = np.asarray(Z_new, dtype=np.float64)\n",
    "\n",
    "    # clone kernel to avoid variable-sharing surprises\n",
    "    k_new = clone_kernel(model_old.kernel)\n",
    "\n",
    "    m = OSGPR_VFE(\n",
    "        data=(np.asarray(X_new, dtype=np.float64), np.asarray(Y_new, dtype=np.float64)),\n",
    "        kernel=k_new,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_use,\n",
    "    )\n",
    "    m.likelihood.variance.assign(float(noise))\n",
    "\n",
    "    if freeze_kernel:\n",
    "        try:\n",
    "            m.kernel.variance.trainable = False\n",
    "            m.kernel.lengthscales.trainable = False\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    t_sec, neg = train_osgpr(m, iters=iters, lr=lr, clip_norm=clip_norm)\n",
    "    m.build_predict_cache()\n",
    "    return m, float(t_sec), float(neg)\n",
    "\n",
    "print(\"✅ OSGPR core + helpers ready (Cell 3 — ACROBOT feature map + pipeline)\")\n"
   ],
   "id": "cfa6c764cdcd8d0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Cell 4 — Train INITIAL GLOBAL OSGPR models (ACROBOT, 4 outputs)\n",
    "#   + GLOBAL evaluation plots (mean + uncertainty)\n",
    "#   + Anchor reselection utilities (for the new pipeline)\n",
    "#\n",
    "# Inputs expected from your CURRENT Cell 2 (Acrobot):\n",
    "#   X0:      (N, D)  features (you said (N,7))\n",
    "#   Ydth1_0: (N,1)   Δtheta1\n",
    "#   Ydth2_0: (N,1)   Δtheta2\n",
    "#   Ydw1_0:  (N,1)   Δomega1\n",
    "#   Ydw2_0:  (N,1)   Δomega2\n",
    "#\n",
    "# Produces:\n",
    "#   m_dth1, m_dth2, m_dw1, m_dw2   (GLOBAL OSGPR models)\n",
    "#   Z_GLOBAL  (fixed)\n",
    "#   refresh_global_anchors() -> updates ANCHOR_IDX\n",
    "#   Plot helpers: slice + surface (mean colored by std) for any model\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# ----------------------------\n",
    "# Safety: require OSGPR core from Cell 3 + Acrobot data from Cell 2\n",
    "# ----------------------------\n",
    "required_syms = [\n",
    "    \"finite_mask\", \"sym_jitter\",\n",
    "    \"prior_summary\", \"train_osgpr\",\n",
    "    \"OSGPR_VFE\", \"greedy_dopt_anchors_from_K\",\n",
    "]\n",
    "missing = [k for k in required_syms if k not in globals()]\n",
    "if len(missing) > 0:\n",
    "    raise NameError(f\"Cell 4 missing required symbols from Cell 3: {missing}\")\n",
    "\n",
    "required_data = [\"X0\", \"Ydth1_0\", \"Ydth2_0\", \"Ydw1_0\", \"Ydw2_0\"]\n",
    "missing_data = [k for k in required_data if k not in globals()]\n",
    "if len(missing_data) > 0:\n",
    "    raise NameError(\n",
    "        \"Cell 4 expects Acrobot random-collection outputs from your Cell 2:\\n\"\n",
    "        f\"Missing: {missing_data}\\n\"\n",
    "        \"Please ensure Cell 2 returns X0, Ydth1_0, Ydth2_0, Ydw1_0, Ydw2_0.\"\n",
    "    )\n",
    "\n",
    "# Alias to clean internal names\n",
    "Ydth1 = Ydth1_0\n",
    "Ydth2 = Ydth2_0\n",
    "Ydw1  = Ydw1_0\n",
    "Ydw2  = Ydw2_0\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Clean / finite filter\n",
    "# ----------------------------\n",
    "mask = finite_mask(X0, Ydth1, Ydth2, Ydw1, Ydw2)\n",
    "X0f    = X0[mask]\n",
    "Yth1f  = Ydth1[mask]\n",
    "Yth2f  = Ydth2[mask]\n",
    "Yw1f   = Ydw1[mask]\n",
    "Yw2f   = Ydw2[mask]\n",
    "print(\"Data kept:\", X0f.shape[0], \"/\", X0.shape[0])\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Train/test split\n",
    "# ----------------------------\n",
    "N = X0f.shape[0]\n",
    "perm = rng.permutation(N)\n",
    "N_test = max(50, int(0.2 * N))\n",
    "test_idx  = perm[:N_test]\n",
    "train_idx = perm[N_test:]\n",
    "\n",
    "Xtr = X0f[train_idx]\n",
    "Xte = X0f[test_idx]\n",
    "\n",
    "Yth1_tr, Yth1_te = Yth1f[train_idx], Yth1f[test_idx]\n",
    "Yth2_tr, Yth2_te = Yth2f[train_idx], Yth2f[test_idx]\n",
    "Yw1_tr,  Yw1_te  = Yw1f[train_idx],  Yw1f[test_idx]\n",
    "Yw2_tr,  Yw2_te  = Yw2f[train_idx],  Yw2f[test_idx]\n",
    "\n",
    "print(\"Train:\", Xtr.shape, \" Test:\", Xte.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) GLOBAL inducing set (fixed capacity)\n",
    "# ----------------------------\n",
    "M_GLOBAL = int(globals().get(\"M_GLOBAL\", 512))\n",
    "N_avail  = Xtr.shape[0]\n",
    "\n",
    "if N_avail >= M_GLOBAL:\n",
    "    idxZ = rng.choice(N_avail, size=M_GLOBAL, replace=False)\n",
    "    Z_GLOBAL = Xtr[idxZ].copy().astype(np.float64)\n",
    "else:\n",
    "    print(f\"⚠️ Warning: Train data ({N_avail}) < M_GLOBAL ({M_GLOBAL}). Sampling with replacement.\")\n",
    "    idxZ = rng.choice(N_avail, size=M_GLOBAL, replace=True)\n",
    "    Z_GLOBAL = Xtr[idxZ].copy().astype(np.float64)\n",
    "    Z_GLOBAL += rng.standard_normal(Z_GLOBAL.shape) * 1e-6  # avoid exact duplicates\n",
    "\n",
    "print(\"Z_GLOBAL:\", Z_GLOBAL.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Kernels (ARD SE) with correct input dim\n",
    "# ----------------------------\n",
    "D_IN = int(Xtr.shape[1])\n",
    "\n",
    "def make_kernel():\n",
    "    return gpflow.kernels.SquaredExponential(\n",
    "        lengthscales=np.ones((D_IN,), dtype=np.float64),\n",
    "        variance=1.0\n",
    "    )\n",
    "\n",
    "k_th1 = make_kernel()\n",
    "k_th2 = make_kernel()\n",
    "k_w1  = make_kernel()\n",
    "k_w2  = make_kernel()\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Build + train helper (initial model uses prior summary at Z_GLOBAL)\n",
    "# ----------------------------\n",
    "def build_and_train_global_model(kernel, X, Y, Z_init, name,\n",
    "                                 iters=300, lr=0.02, noise=1e-4):\n",
    "    mu_old, Su_old, Kaa_old, Z_old = prior_summary(kernel, Z_init)\n",
    "\n",
    "    m = OSGPR_VFE(\n",
    "        data=(np.asarray(X, dtype=np.float64), np.asarray(Y, dtype=np.float64)),\n",
    "        kernel=kernel,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_init\n",
    "    )\n",
    "    m.likelihood.variance.assign(float(noise))\n",
    "\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    t, neg = train_osgpr(m, iters=iters, lr=lr, clip_norm=10.0)\n",
    "    print(f\"{name} done | train={t:.2f}s | neg_obj={neg:.4f} | noise={float(m.likelihood.variance.numpy()):.2e}\")\n",
    "\n",
    "    # for speed later in MPPI / eval\n",
    "    if hasattr(m, \"build_predict_cache\"):\n",
    "        m.build_predict_cache()\n",
    "    return m\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Train 4 global models\n",
    "# ----------------------------\n",
    "m_dth1 = build_and_train_global_model(k_th1, Xtr, Yth1_tr, Z_GLOBAL, \"dtheta1\",  iters=300, lr=0.02, noise=1e-4)\n",
    "m_dth2 = build_and_train_global_model(k_th2, Xtr, Yth2_tr, Z_GLOBAL, \"dtheta2\",  iters=300, lr=0.02, noise=1e-4)\n",
    "m_dw1  = build_and_train_global_model(k_w1,  Xtr, Yw1_tr,  Z_GLOBAL, \"domega1\",  iters=300, lr=0.02, noise=1e-4)\n",
    "m_dw2  = build_and_train_global_model(k_w2,  Xtr, Yw2_tr,  Z_GLOBAL, \"domega2\",  iters=300, lr=0.02, noise=1e-4)\n",
    "\n",
    "print(\"\\n✅ Global Acrobot OSGPR models trained + caches ready\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Numeric eval (RMSE on held-out)\n",
    "# ----------------------------\n",
    "def rmse_on_test(model, Xte, Yte):\n",
    "    Xte = np.asarray(Xte, dtype=np.float64)\n",
    "    y = np.asarray(Yte, dtype=np.float64).reshape(-1)\n",
    "    if hasattr(model, \"predict_f_cached\"):\n",
    "        mu, _ = model.predict_f_cached(Xte, full_cov=False)\n",
    "    else:\n",
    "        mu, _ = model.predict_f(Xte, full_cov=False)\n",
    "    yhat = mu.numpy().reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "print(\"\\nHeld-out RMSE:\")\n",
    "print(\"  dtheta1 :\", rmse_on_test(m_dth1, Xte, Yth1_te))\n",
    "print(\"  dtheta2 :\", rmse_on_test(m_dth2, Xte, Yth2_te))\n",
    "print(\"  domega1 :\", rmse_on_test(m_dw1,  Xte, Yw1_te))\n",
    "print(\"  domega2 :\", rmse_on_test(m_dw2,  Xte, Yw2_te))\n",
    "\n",
    "# ============================================================\n",
    "# 7) Anchor reselection utilities (CRITICAL for new pipeline)\n",
    "# ============================================================\n",
    "def reselect_anchors_from_model(model, m_anchors=24, lam=1e-6):\n",
    "    \"\"\"\n",
    "    Anchors chosen on K(Z_GLOBAL,Z_GLOBAL) using the model's CURRENT kernel hyperparams.\n",
    "    Re-run after each global update if kernel changes or you want anchors to adapt.\n",
    "    \"\"\"\n",
    "    Z = model.inducing_variable.Z.numpy().astype(np.float64)\n",
    "    Kzz = model.kernel.K(Z).numpy()\n",
    "    Kzz = sym_jitter(Kzz, lam)\n",
    "    m_anchors = int(min(m_anchors, Z.shape[0]))\n",
    "    idx = greedy_dopt_anchors_from_K(Kzz, m_anchors=m_anchors, lam=lam)\n",
    "    return idx\n",
    "\n",
    "ANCHOR_M = min(24, int(Z_GLOBAL.shape[0]))\n",
    "ANCHOR_IDX = reselect_anchors_from_model(m_dw2, m_anchors=ANCHOR_M, lam=1e-6)  # pick one head\n",
    "print(\"ANCHOR_IDX:\", ANCHOR_IDX.shape, f\"(anchors={len(ANCHOR_IDX)})\")\n",
    "\n",
    "def refresh_global_anchors(m_anchors=24):\n",
    "    \"\"\"\n",
    "    Call this after global update (especially if kernel hyperparams move).\n",
    "    Uses m_dw2 by default (you can switch to m_dth1 etc.).\n",
    "    \"\"\"\n",
    "    global ANCHOR_IDX\n",
    "    ANCHOR_IDX = reselect_anchors_from_model(m_dw2, m_anchors=m_anchors, lam=1e-6)\n",
    "    return ANCHOR_IDX\n",
    "\n",
    "# ============================================================\n",
    "# 8) Plot helpers (GLOBAL): mean + uncertainty\n",
    "# ============================================================\n",
    "def gp_predict_mu_std_fast(model, X):\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    if hasattr(model, \"predict_f_cached\"):\n",
    "        mu_tf, var_tf = model.predict_f_cached(X, full_cov=False)\n",
    "    else:\n",
    "        mu_tf, var_tf = model.predict_f(X, full_cov=False)\n",
    "    mu = mu_tf.numpy().reshape(-1)\n",
    "    var = var_tf.numpy().reshape(-1)\n",
    "    std = np.sqrt(np.maximum(var, 1e-12))\n",
    "    return mu, std\n",
    "\n",
    "def get_inducing_Z_np(model):\n",
    "    return model.inducing_variable.Z.numpy().astype(np.float64)\n",
    "\n",
    "# ---- 2D Slice: pick one feature dim to sweep (generic, since Acrobot features are not 1:1 physical x) ----\n",
    "def plot_slice_feature_dim_two_actions(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    feat_dim=0,\n",
    "    feat_min=-1.0, feat_max=1.0,\n",
    "    n_grid=260,\n",
    "    u_dim=-1,                 # action is last dim by default\n",
    "    u_list=(+1.0, -1.0),\n",
    "    title=\"Slice over feature dim\",\n",
    "    y_label=\"Δy\",\n",
    "    show_data=True,\n",
    "    show_inducing=True,\n",
    "):\n",
    "    Z = get_inducing_Z_np(model)\n",
    "\n",
    "    base = np.nanmedian(np.asarray(X_train, dtype=np.float64), axis=0)\n",
    "    curves = []\n",
    "    auto_ymin, auto_ymax = +np.inf, -np.inf\n",
    "\n",
    "    for u_fixed in u_list:\n",
    "        Xq = np.tile(base[None, :], (n_grid, 1))\n",
    "        Xq[:, feat_dim] = np.linspace(feat_min, feat_max, n_grid)\n",
    "        Xq[:, u_dim] = float(u_fixed)\n",
    "\n",
    "        mu, std = gp_predict_mu_std_fast(model, Xq)\n",
    "        lo, hi = mu - 2 * std, mu + 2 * std\n",
    "        curves.append((u_fixed, Xq[:, feat_dim].copy(), mu, std, lo, hi))\n",
    "        auto_ymin, auto_ymax = min(auto_ymin, float(lo.min())), max(auto_ymax, float(hi.max()))\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    for u_fixed, xgrid, mu, std, lo, hi in curves:\n",
    "        plt.plot(xgrid, mu, lw=2.5, label=f\"mean (u={u_fixed:+.1f})\")\n",
    "        plt.fill_between(xgrid, lo, hi, alpha=0.18, label=f\"±2σ (u={u_fixed:+.1f})\")\n",
    "\n",
    "    if show_data:\n",
    "        X_train = np.asarray(X_train, dtype=np.float64)\n",
    "        y_train = np.asarray(y_train, dtype=np.float64).reshape(-1)\n",
    "        for u_fixed in u_list:\n",
    "            mask = np.abs(X_train[:, u_dim] - float(u_fixed)) < 0.15\n",
    "            if np.sum(mask) > 0:\n",
    "                plt.scatter(X_train[mask, feat_dim], y_train[mask], s=18, alpha=0.35,\n",
    "                            label=f\"data (u≈{u_fixed:+.1f}, n={np.sum(mask)})\")\n",
    "\n",
    "    if show_inducing and (Z is not None):\n",
    "        for u_fixed in u_list:\n",
    "            maskZ = np.abs(Z[:, u_dim] - float(u_fixed)) < 0.15\n",
    "            if np.sum(maskZ) > 0:\n",
    "                Zsel = Z[maskZ]\n",
    "                muZ, _ = gp_predict_mu_std_fast(model, Zsel)\n",
    "                plt.scatter(Zsel[:, feat_dim], muZ, marker=\"x\", s=70, linewidths=2.0,\n",
    "                            label=f\"Z (u≈{u_fixed:+.1f}, M={np.sum(maskZ)})\")\n",
    "\n",
    "    plt.xlabel(f\"feature[{feat_dim}]\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title + f\"  (median other dims; action dim={u_dim})\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- 3D Surface: pick two feature dims to visualize, color by std ----\n",
    "def plot_surface_two_feature_dims_mean_colored_by_std(\n",
    "    model,\n",
    "    X_ref,\n",
    "    dim_x=0,\n",
    "    dim_y=1,\n",
    "    x_min=-1.0, x_max=1.0,\n",
    "    y_min=-1.0, y_max=1.0,\n",
    "    n_grid=70,\n",
    "    u_fixed=+1.0,\n",
    "    u_dim=-1,\n",
    "    title=\"3D surface over feature dims\",\n",
    "    z_label=\"Δy\",\n",
    "    show_inducing=True,\n",
    "):\n",
    "    X_ref = np.asarray(X_ref, dtype=np.float64)\n",
    "    base = np.nanmedian(X_ref, axis=0)\n",
    "\n",
    "    x_grid = np.linspace(x_min, x_max, n_grid)\n",
    "    y_grid = np.linspace(y_min, y_max, n_grid)\n",
    "    Xg, Yg = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    Xq = np.tile(base[None, :], (n_grid * n_grid, 1))\n",
    "    Xq[:, dim_x] = Xg.ravel()\n",
    "    Xq[:, dim_y] = Yg.ravel()\n",
    "    Xq[:, u_dim] = float(u_fixed)\n",
    "\n",
    "    mu, std = gp_predict_mu_std_fast(model, Xq)\n",
    "    Mean = mu.reshape(Xg.shape)\n",
    "    Std  = std.reshape(Xg.shape)\n",
    "\n",
    "    surface = go.Surface(\n",
    "        x=Xg, y=Yg, z=Mean,\n",
    "        surfacecolor=Std,\n",
    "        colorscale=\"Viridis\",\n",
    "        colorbar=dict(title=\"Std\"),\n",
    "        opacity=0.95,\n",
    "        showscale=True,\n",
    "        name=\"surface\"\n",
    "    )\n",
    "    traces = [surface]\n",
    "\n",
    "    if show_inducing:\n",
    "        Z = get_inducing_Z_np(model)\n",
    "        if Z is not None:\n",
    "            maskZ = np.abs(Z[:, u_dim] - float(u_fixed)) < 0.15\n",
    "            if np.sum(maskZ) > 0:\n",
    "                Zsel = Z[maskZ]\n",
    "                muZ, _ = gp_predict_mu_std_fast(model, Zsel)\n",
    "                traces.append(\n",
    "                    go.Scatter3d(\n",
    "                        x=Zsel[:, dim_x], y=Zsel[:, dim_y], z=muZ,\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(size=3, color=\"red\", opacity=0.9),\n",
    "                        name=f\"inducing Z (u≈{u_fixed:+.1f}) | M={np.sum(maskZ)}\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=f\"{title} | fixed u={u_fixed:+.1f}\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=f\"feature[{dim_x}]\", range=[x_min, x_max]),\n",
    "            yaxis=dict(title=f\"feature[{dim_y}]\", range=[y_min, y_max]),\n",
    "            zaxis=dict(title=z_label),\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=50),\n",
    "        height=650\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "print(\"\\n✅ Cell 4 complete (Acrobot global models + anchor refresh + plot helpers).\")\n",
    "\n",
    "# OPTIONAL quick demo plots (uncomment if you want):\n",
    "# plot_slice_feature_dim_two_actions(m_dw2, Xtr, Yw2_tr, feat_dim=0, title=\"domega2 slice\", y_label=\"Δw2\")\n",
    "# plot_surface_two_feature_dims_mean_colored_by_std(m_dw2, Xtr, dim_x=0, dim_y=1, title=\"domega2 surface\", z_label=\"Δw2\")\n"
   ],
   "id": "93b2207c4afbbe41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================\n",
    "# Cell 5 — Evaluate + Visualize GLOBAL GP (Reusable) ✅ ACROBOT\n",
    "#\n",
    "# Provides:\n",
    "#   ✅ RMSE for dtheta1, dtheta2, domega1, domega2 on Xte\n",
    "#   ✅ Slice plot (mean ±2σ) for chosen output model (generic feature dim)\n",
    "#   ✅ 3D Surface mean colored by std (over 2 chosen feature dims)\n",
    "#   ✅ NEW: 3D Surface of std alone (uncertainty surface)\n",
    "#\n",
    "# Assumes you ran:\n",
    "#   Cell 4 (trained global models + plot helpers already defined)\n",
    "#\n",
    "# Expected variables from your Cell 4:\n",
    "#   m_dth1, m_dth2, m_dw1, m_dw2\n",
    "#   Xtr, Xte\n",
    "#   Yth1_tr, Yth1_te, Yth2_tr, Yth2_te, Yw1_tr, Yw1_te, Yw2_tr, Yw2_te\n",
    "#   gp_predict_mu_std_fast()\n",
    "#   plot_slice_feature_dim_two_actions()\n",
    "#   plot_surface_two_feature_dims_mean_colored_by_std()\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Safety: require Cell 4 symbols\n",
    "# ----------------------------\n",
    "required = [\n",
    "    \"gp_predict_mu_std_fast\",\n",
    "    \"plot_slice_feature_dim_two_actions\",\n",
    "    \"plot_surface_two_feature_dims_mean_colored_by_std\",\n",
    "    \"m_dth1\", \"m_dth2\", \"m_dw1\", \"m_dw2\",\n",
    "    \"Xtr\", \"Xte\",\n",
    "    \"Yth1_tr\", \"Yth1_te\",\n",
    "    \"Yth2_tr\", \"Yth2_te\",\n",
    "    \"Yw1_tr\", \"Yw1_te\",\n",
    "    \"Yw2_tr\", \"Yw2_te\",\n",
    "]\n",
    "missing = [k for k in required if k not in globals()]\n",
    "if len(missing) > 0:\n",
    "    raise NameError(f\"Cell 5 missing required symbols (run Cell 4 first): {missing}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 1) RMSE helper\n",
    "# ----------------------------\n",
    "def rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def print_global_rmse_acrobot():\n",
    "    mu_th1, _ = gp_predict_mu_std_fast(m_dth1, Xte)\n",
    "    mu_th2, _ = gp_predict_mu_std_fast(m_dth2, Xte)\n",
    "    mu_w1,  _ = gp_predict_mu_std_fast(m_dw1,  Xte)\n",
    "    mu_w2,  _ = gp_predict_mu_std_fast(m_dw2,  Xte)\n",
    "\n",
    "    print(\"=== Test RMSE (global models, ACROBOT) ===\")\n",
    "    print(f\"dtheta1  RMSE: {rmse_np(mu_th1, Yth1_te):.6f}\")\n",
    "    print(f\"dtheta2  RMSE: {rmse_np(mu_th2, Yth2_te):.6f}\")\n",
    "    print(f\"domega1  RMSE: {rmse_np(mu_w1,  Yw1_te):.6f}\")\n",
    "    print(f\"domega2  RMSE: {rmse_np(mu_w2,  Yw2_te):.6f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Std-only surface over 2 chosen feature dims (ACROBOT)\n",
    "# ----------------------------\n",
    "def plot_surface_two_feature_dims_std_only(\n",
    "    model,\n",
    "    X_ref,\n",
    "    dim_x=0,\n",
    "    dim_y=1,\n",
    "    x_min=-1.0, x_max=1.0,\n",
    "    y_min=-1.0, y_max=1.0,\n",
    "    n_grid=70,\n",
    "    u_fixed=+1.0,\n",
    "    u_dim=-1,\n",
    "    title=\"3D Std surface (uncertainty only)\",\n",
    "):\n",
    "    X_ref = np.asarray(X_ref, dtype=np.float64)\n",
    "    base = np.nanmedian(X_ref, axis=0)\n",
    "\n",
    "    x_grid = np.linspace(x_min, x_max, n_grid)\n",
    "    y_grid = np.linspace(y_min, y_max, n_grid)\n",
    "    Xg, Yg = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    Xq = np.tile(base[None, :], (n_grid * n_grid, 1))\n",
    "    Xq[:, dim_x] = Xg.ravel()\n",
    "    Xq[:, dim_y] = Yg.ravel()\n",
    "    Xq[:, u_dim] = float(u_fixed)\n",
    "\n",
    "    _, std = gp_predict_mu_std_fast(model, Xq)\n",
    "    Std = std.reshape(Xg.shape)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(\n",
    "                x=Xg, y=Yg, z=Std,\n",
    "                colorscale=\"Viridis\",\n",
    "                colorbar=dict(title=\"Std\"),\n",
    "                opacity=0.98,\n",
    "                showscale=True,\n",
    "                name=\"std surface\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"{title} | fixed u={u_fixed:+.1f}\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=f\"feature[{dim_x}]\", range=[x_min, x_max]),\n",
    "            yaxis=dict(title=f\"feature[{dim_y}]\", range=[y_min, y_max]),\n",
    "            zaxis=dict(title=\"std\"),\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=50),\n",
    "        height=650\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) One-call global evaluation bundle (REUSABLE after updates)\n",
    "# ----------------------------\n",
    "def eval_and_plot_global_acrobot(\n",
    "    tag=\"GLOBAL (init)\",\n",
    "    model_for_plots=None,\n",
    "    y_train_for_plots=None,\n",
    "    # slice config\n",
    "    slice_feat_dim=0,\n",
    "    slice_feat_min=-1.0,\n",
    "    slice_feat_max=1.0,\n",
    "    # surface config\n",
    "    surf_dim_x=0,\n",
    "    surf_dim_y=1,\n",
    "    surf_x_min=-1.0, surf_x_max=1.0,\n",
    "    surf_y_min=-1.0, surf_y_max=1.0,\n",
    "    # action config\n",
    "    u_fixed=+1.0,\n",
    "    u_dim=-1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Notes on feature dims for Acrobot (your 7D features):\n",
    "      0: sin(th1)\n",
    "      1: cos(th1)\n",
    "      2: sin(th2)\n",
    "      3: cos(th2)\n",
    "      4: tanh(w1/s1)\n",
    "      5: tanh(w2/s2)\n",
    "      6: u\n",
    "    \"\"\"\n",
    "    if model_for_plots is None:\n",
    "        model_for_plots = m_dw2\n",
    "    if y_train_for_plots is None:\n",
    "        y_train_for_plots = Yw2_tr\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"GLOBAL EVAL (ACROBOT): {tag}\")\n",
    "    print(\"==============================\")\n",
    "    print_global_rmse_acrobot()\n",
    "\n",
    "    # Slice: mean ±2σ, compare u=+1/-1\n",
    "    plot_slice_feature_dim_two_actions(\n",
    "        model=model_for_plots,\n",
    "        X_train=Xtr,\n",
    "        y_train=y_train_for_plots,\n",
    "        feat_dim=int(slice_feat_dim),\n",
    "        feat_min=float(slice_feat_min),\n",
    "        feat_max=float(slice_feat_max),\n",
    "        n_grid=260,\n",
    "        u_dim=int(u_dim),\n",
    "        u_list=(+1.0, -1.0),\n",
    "        title=f\"{tag} slice: mean ±2σ (u=+1/-1) + inducing\",\n",
    "        y_label=\"Δy\",\n",
    "        show_data=True,\n",
    "        show_inducing=True,\n",
    "    )\n",
    "\n",
    "    # Surface: mean colored by std\n",
    "    plot_surface_two_feature_dims_mean_colored_by_std(\n",
    "        model=model_for_plots,\n",
    "        X_ref=Xtr,\n",
    "        dim_x=int(surf_dim_x),\n",
    "        dim_y=int(surf_dim_y),\n",
    "        x_min=float(surf_x_min), x_max=float(surf_x_max),\n",
    "        y_min=float(surf_y_min), y_max=float(surf_y_max),\n",
    "        n_grid=70,\n",
    "        u_fixed=float(u_fixed),\n",
    "        u_dim=int(u_dim),\n",
    "        title=f\"{tag} surface: mean colored by std (+ inducing)\",\n",
    "        z_label=\"Δy\",\n",
    "        show_inducing=True,\n",
    "    )\n",
    "\n",
    "    # NEW: std-only surface\n",
    "    plot_surface_two_feature_dims_std_only(\n",
    "        model=model_for_plots,\n",
    "        X_ref=Xtr,\n",
    "        dim_x=int(surf_dim_x),\n",
    "        dim_y=int(surf_dim_y),\n",
    "        x_min=float(surf_x_min), x_max=float(surf_x_max),\n",
    "        y_min=float(surf_y_min), y_max=float(surf_y_max),\n",
    "        n_grid=70,\n",
    "        u_fixed=float(u_fixed),\n",
    "        u_dim=int(u_dim),\n",
    "        title=f\"{tag} surface: std only (uncertainty)\",\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# RUN ONCE FOR INITIAL GLOBAL (ACROBOT)\n",
    "# ----------------------------\n",
    "# Default visualization:\n",
    "#   - slice over feature[0]=sin(th1)\n",
    "#   - surface over feature[0]=sin(th1) vs feature[4]=tanh(w1/s1)\n",
    "eval_and_plot_global_acrobot(\n",
    "    tag=\"GLOBAL (initial)\",\n",
    "    model_for_plots=m_dw2,\n",
    "    y_train_for_plots=Yw2_tr,\n",
    "    slice_feat_dim=0,\n",
    "    surf_dim_x=0,\n",
    "    surf_dim_y=4,\n",
    "    u_fixed=+1.0,\n",
    "    u_dim=-1\n",
    ")\n"
   ],
   "id": "e76267f1d5150253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Cell 6 — MPPI + Online OSGPR (fixed-size Z_GLOBAL) + Local subset (PALSGP-style) ✅ ACROBOT\n",
    "#   ✅ Keeps the \"NO RETRACING\" fix:\n",
    "#      - One compiled LocalSubsetPredictor per head\n",
    "#      - Only assign() new tensors when subset changes\n",
    "# ===========================\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "import plotly.graph_objects as go\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "from scipy.stats import chi2\n",
    "from gpflow.utilities import parameter_dict, multiple_assign\n",
    "\n",
    "# ----------------------------\n",
    "# Enforce float64 (per your pipeline going forward)\n",
    "# ----------------------------\n",
    "try:\n",
    "    gpflow.config.set_default_float(np.float64)\n",
    "except Exception:\n",
    "    pass\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "DTYPE_TF = gpflow.default_float()\n",
    "assert DTYPE_TF == tf.float64, f\"Expected float64 default, got {DTYPE_TF}. Set gpflow default float to float64.\"\n",
    "\n",
    "# ----------------------------\n",
    "# GPU sanity / enforcement\n",
    "# ----------------------------\n",
    "REQUIRE_GPU = True\n",
    "LOG_DEVICE_PLACEMENT = False\n",
    "\n",
    "print(\"TF built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs visible:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Logical GPUs:\", tf.config.list_logical_devices(\"GPU\"))\n",
    "\n",
    "if LOG_DEVICE_PLACEMENT:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "if REQUIRE_GPU:\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if len(gpus) == 0:\n",
    "        raise RuntimeError(\"REQUIRE_GPU=True but no GPU is visible to TensorFlow. Fix CUDA/TF install or set REQUIRE_GPU=False.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Config (Acrobot)\n",
    "# ----------------------------\n",
    "HORIZON    = 25\n",
    "K_SAMPLES  = 512\n",
    "SIGMA      = 0.6\n",
    "LAMBDA     = 1.0\n",
    "\n",
    "UPDATE_EVERY = 60\n",
    "ITERS_UPDATE = 200\n",
    "LR_UPDATE    = 0.02\n",
    "NOISE_UPDATE = 1e-4\n",
    "\n",
    "M_GLOBAL = 512\n",
    "\n",
    "M_SUB           = 72\n",
    "ANCHOR_M   = 32\n",
    "ANCHOR_LAM = 1e-6\n",
    "\n",
    "# Local subset rebuild logic\n",
    "LOCAL_REBUILD_EVERY   = 10\n",
    "LOCAL_OVERLAP_THRESH  = 0.70\n",
    "\n",
    "# Tube selection\n",
    "TUBE_ALPHA      = 0.99\n",
    "TUBE_COV_EPS    = 1e-6\n",
    "TUBE_TIME_BINS  = 8\n",
    "TUBE_FALLBACK_CANDIDATES = 400\n",
    "\n",
    "# Recording\n",
    "RECORD_RGB_DEFAULT = True\n",
    "RESIZE       = (720, 450)\n",
    "FPS          = 10\n",
    "FRAME_STRIDE = 2\n",
    "\n",
    "# Acrobot success + cost\n",
    "Y_TIP_GOAL = 1.0\n",
    "HOLD_STEPS = 60  # smaller than CartPole; tweak as you like\n",
    "\n",
    "# Exploration schedule (uncertainty bonus)\n",
    "EXPLORE_STEPS = 1000\n",
    "UNC_W_MAX     = 15.0\n",
    "UNC_W_MIN     = 0.0\n",
    "\n",
    "# Cost weights\n",
    "TIP_W      = 3.0     # encourage large y_tip\n",
    "VEL_W      = 0.05    # penalize angular velocities\n",
    "U_W        = 0.00    # penalize control\n",
    "TERM_BONUS = 5.0     # terminal bonus when y_tip high\n",
    "\n",
    "if \"U_MIN\" not in globals(): U_MIN = -1.0\n",
    "if \"U_MAX\" not in globals(): U_MAX = +1.0\n",
    "\n",
    "PLOT_EACH_UPDATE = False\n",
    "\n",
    "# Std scale unify (optional; used only for consistent plotting if you store surfaces)\n",
    "STD_CMIN_FIXED = 0.0\n",
    "STD_FIXED_Q    = 0.5\n",
    "STD_MODE       = \"fixed\"\n",
    "STD_CMAX_FIXED = None\n",
    "\n",
    "STORE_GLOBAL_SURFACES = False\n",
    "GLOBAL_SURF_HISTORY = []   # reset per RUN\n",
    "\n",
    "# ----------------------------\n",
    "# NEW: Cross-method registry for unified evaluation plots\n",
    "# ----------------------------\n",
    "if \"EVAL_REGISTRY\" not in globals():\n",
    "    EVAL_REGISTRY = {}\n",
    "\n",
    "def register_method_results(method_name, payload):\n",
    "    EVAL_REGISTRY[str(method_name)] = payload\n",
    "\n",
    "# ----------------------------\n",
    "# Safety: require dependencies from earlier cells\n",
    "# ----------------------------\n",
    "required = [\n",
    "    \"make_env\", \"obs_to_state\", \"wrap_pi\", \"state_to_features\",\n",
    "    \"batch_state_to_features\", \"OSGPR_VFE\", \"train_osgpr\",\n",
    "    \"extract_summary_from_model\", \"greedy_dopt_anchors_from_K\",\n",
    "    \"clone_kernel\",\n",
    "    \"m_dth1\", \"m_dth2\", \"m_dw1\", \"m_dw2\",\n",
    "    \"Z_GLOBAL\",\n",
    "]\n",
    "missing = [k for k in required if k not in globals()]\n",
    "if len(missing) > 0:\n",
    "    raise NameError(f\"Cell 6 missing required symbols from earlier cells: {missing}\")\n",
    "\n",
    "if \"render_acrobot_frame_from_state\" not in globals():\n",
    "    print(\"⚠️ render_acrobot_frame_from_state not found. RGB recording will be disabled.\")\n",
    "    RECORD_RGB_DEFAULT = False\n",
    "\n",
    "# ----------------------------\n",
    "# Acrobot tip height proxy\n",
    "# ----------------------------\n",
    "def acrobot_tip_height_proxy_np(th1, th2):\n",
    "    return float(-np.cos(th1) - np.cos(th1 + th2))\n",
    "\n",
    "@tf.function\n",
    "def acrobot_tip_height_proxy_tf(th1, th2):\n",
    "    return -(tf.cos(th1) + tf.cos(th1 + th2))\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: sym_jitter (numpy)\n",
    "# ----------------------------\n",
    "def sym_jitter(A, jitter=1e-6):\n",
    "    A = np.asarray(A, dtype=np.float64)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    return A + float(jitter) * np.eye(A.shape[0], dtype=np.float64)\n",
    "\n",
    "# ----------------------------\n",
    "# Global predict helpers (mean/std)\n",
    "# ----------------------------\n",
    "def gp_predict_mu_std_fast(model, X):\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    if hasattr(model, \"predict_f_cached\"):\n",
    "        mu_tf, var_tf = model.predict_f_cached(X, full_cov=False)\n",
    "    else:\n",
    "        mu_tf, var_tf = model.predict_f(X, full_cov=False)\n",
    "    mu = mu_tf.numpy().reshape(-1)\n",
    "    var = var_tf.numpy().reshape(-1)\n",
    "    std = np.sqrt(np.maximum(var, 1e-12))\n",
    "    return mu, std\n",
    "\n",
    "def update_unified_std_scale(std_list, q=0.99, mode=\"fixed\"):\n",
    "    global STD_CMAX_FIXED\n",
    "    all_std = np.concatenate([np.asarray(s, dtype=np.float64).reshape(-1) for s in std_list if s is not None], axis=0)\n",
    "    if all_std.size == 0:\n",
    "        if STD_CMAX_FIXED is None:\n",
    "            STD_CMAX_FIXED = 1.0\n",
    "        return (STD_CMIN_FIXED, STD_CMAX_FIXED)\n",
    "\n",
    "    cand = float(np.quantile(all_std, q))\n",
    "    cand = max(cand, 1e-8)\n",
    "\n",
    "    if STD_CMAX_FIXED is None:\n",
    "        STD_CMAX_FIXED = cand\n",
    "    elif mode == \"grow_only\":\n",
    "        STD_CMAX_FIXED = max(STD_CMAX_FIXED, cand)\n",
    "\n",
    "    return (STD_CMIN_FIXED, STD_CMAX_FIXED)\n",
    "\n",
    "# ============================================================\n",
    "# CLEAN multi-head Z_GLOBAL refit (ACROBOT): aggregate kernels across 4 heads\n",
    "# ============================================================\n",
    "def refit_Z_global_multihead(Z_global, Xnew, M_global, lam=1e-6, mode=\"mean\", normalize_traces=False):\n",
    "    Z_global = np.asarray(Z_global, dtype=np.float64)\n",
    "    Xnew = np.asarray(Xnew, dtype=np.float64)\n",
    "\n",
    "    Z_cand = np.vstack([Z_global, Xnew]).astype(np.float64, copy=False)\n",
    "    Zc_tf = tf.convert_to_tensor(Z_cand, dtype=tf.float64)\n",
    "\n",
    "    K1 = m_dth1.kernel.K(Zc_tf).numpy().astype(np.float64, copy=False)\n",
    "    K2 = m_dth2.kernel.K(Zc_tf).numpy().astype(np.float64, copy=False)\n",
    "    K3 = m_dw1.kernel.K(Zc_tf).numpy().astype(np.float64, copy=False)\n",
    "    K4 = m_dw2.kernel.K(Zc_tf).numpy().astype(np.float64, copy=False)\n",
    "\n",
    "    if normalize_traces:\n",
    "        def _norm(K):\n",
    "            tr = float(np.trace(K))\n",
    "            return K / max(tr, 1e-12)\n",
    "        K1, K2, K3, K4 = map(_norm, [K1, K2, K3, K4])\n",
    "\n",
    "    K_agg = (K1 + K2 + K3 + K4)\n",
    "    if mode != \"sum\":\n",
    "        K_agg = K_agg / 4.0\n",
    "\n",
    "    idxZ = greedy_dopt_anchors_from_K(K_agg, m_anchors=int(M_global), lam=float(lam))\n",
    "    Z_new = np.asarray(Z_cand[np.asarray(idxZ, dtype=np.int64)], dtype=np.float64)\n",
    "\n",
    "    if Z_new.shape[0] != int(M_global):\n",
    "        Z_new = Z_new[:int(M_global)].copy()\n",
    "    return Z_new\n",
    "\n",
    "# ============================================================\n",
    "# Online OSGPR update (unchanged)\n",
    "# ============================================================\n",
    "def osgpr_stream_update(model_old, X_new, Y_new, Z_new,\n",
    "                        iters=100, lr=0.02, noise=1e-4,\n",
    "                        freeze_kernel=False, clip_norm=10.0):\n",
    "    X_new = np.asarray(X_new, dtype=np.float64)\n",
    "    Y_new = np.asarray(Y_new, dtype=np.float64).reshape(-1, 1)\n",
    "\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(model_old)\n",
    "    Z_new = np.asarray(Z_new, dtype=np.float64)\n",
    "\n",
    "    k_new = clone_kernel(model_old.kernel)\n",
    "\n",
    "    m = OSGPR_VFE(\n",
    "        data=(X_new, Y_new),\n",
    "        kernel=k_new,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_new\n",
    "    )\n",
    "    m.likelihood.variance.assign(float(noise))\n",
    "\n",
    "    if freeze_kernel:\n",
    "        try:\n",
    "            m.kernel.variance.trainable = False\n",
    "            m.kernel.lengthscales.trainable = False\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    t_train, last_loss = train_osgpr(m, iters=iters, lr=lr, clip_norm=clip_norm)\n",
    "    m.build_predict_cache()\n",
    "\n",
    "    info = dict(\n",
    "        train_seconds=float(t_train),\n",
    "        last_neg_objective=float(last_loss),\n",
    "        M_new=int(m.inducing_variable.num_inducing),\n",
    "    )\n",
    "    return m, info\n",
    "\n",
    "# ============================================================\n",
    "# Anchors via aggregated kernel on Z_GLOBAL (ACROBOT)\n",
    "# ============================================================\n",
    "def compute_anchor_idx_dopt_from_Zglobal_multihead(Z_global, m_anchors=18, lam=1e-6, normalize_traces=True):\n",
    "    Z = np.asarray(Z_global, dtype=np.float64)\n",
    "    Ztf = tf.convert_to_tensor(Z, dtype=tf.float64)\n",
    "\n",
    "    K1 = m_dth1.kernel.K(Ztf).numpy().astype(np.float64, copy=False)\n",
    "    K2 = m_dth2.kernel.K(Ztf).numpy().astype(np.float64, copy=False)\n",
    "    K3 = m_dw1.kernel.K(Ztf).numpy().astype(np.float64, copy=False)\n",
    "    K4 = m_dw2.kernel.K(Ztf).numpy().astype(np.float64, copy=False)\n",
    "\n",
    "    if normalize_traces:\n",
    "        def _norm(K):\n",
    "            tr = float(np.trace(K))\n",
    "            return K / max(tr, 1e-12)\n",
    "        K1, K2, K3, K4 = map(_norm, [K1, K2, K3, K4])\n",
    "\n",
    "    K_agg = (K1 + K2 + K3 + K4) / 4.0\n",
    "    return greedy_dopt_anchors_from_K(K_agg, m_anchors=int(m_anchors), lam=float(lam))\n",
    "\n",
    "# ============================================================\n",
    "# Chi-square Mahalanobis tube selection (unchanged)\n",
    "# ============================================================\n",
    "def normalize_nonnegative_weights(w, eps=1e-12):\n",
    "    w = np.asarray(w, dtype=np.float64).reshape(-1)\n",
    "    w = np.maximum(w, 0.0)\n",
    "    s = float(np.sum(w))\n",
    "    if s < eps:\n",
    "        return np.ones_like(w) / max(len(w), 1)\n",
    "    return w / s\n",
    "\n",
    "def compute_weighted_moments(rollout_inputs, rollout_weights):\n",
    "    X = np.asarray(rollout_inputs, dtype=np.float64)  # (K,H,D)\n",
    "    K, H, D = X.shape\n",
    "    w = normalize_nonnegative_weights(rollout_weights).reshape(K, 1, 1)\n",
    "    tube_mean = np.sum(w * X, axis=0)  # (H,D)\n",
    "    Xc = X - tube_mean[None, :, :]\n",
    "    tube_cov = np.einsum(\"khd,khe->hde\", (w * Xc), Xc)  # (H,D,D)\n",
    "    return tube_mean, tube_cov\n",
    "\n",
    "def min_mahalanobis_and_argmin(points_Z, tube_mean, tube_cov, cov_eps=1e-6):\n",
    "    Z = np.asarray(points_Z, dtype=np.float64)\n",
    "    mu = np.asarray(tube_mean, dtype=np.float64)\n",
    "    Sig = np.asarray(tube_cov, dtype=np.float64)\n",
    "\n",
    "    M, D = Z.shape\n",
    "    H = mu.shape[0]\n",
    "    I = np.eye(D, dtype=np.float64)\n",
    "\n",
    "    dmin = np.full((M,), np.inf, dtype=np.float64)\n",
    "    tmin = np.zeros((M,), dtype=np.int64)\n",
    "\n",
    "    for t in range(H):\n",
    "        St = Sig[t] + float(cov_eps) * I\n",
    "        L = np.linalg.cholesky(St)\n",
    "\n",
    "        diff = (Z - mu[t:t+1, :]).T  # (D,M)\n",
    "        y = np.linalg.solve(L, diff)\n",
    "        y2 = np.linalg.solve(L.T, y)\n",
    "        quad = np.sum(diff * y2, axis=0)  # (M,)\n",
    "\n",
    "        mask = quad < dmin\n",
    "        dmin[mask] = quad[mask]\n",
    "        tmin[mask] = t\n",
    "\n",
    "    return dmin, tmin\n",
    "\n",
    "def split_even_quota(total, num_bins):\n",
    "    num_bins = int(max(1, num_bins))\n",
    "    base = total // num_bins\n",
    "    rem = total - base * num_bins\n",
    "    q = np.full((num_bins,), base, dtype=np.int64)\n",
    "    if rem > 0:\n",
    "        q[:rem] += 1\n",
    "    return q\n",
    "\n",
    "def chi2_radius_sq(alpha, D):\n",
    "    alpha = float(alpha)\n",
    "    D = int(D)\n",
    "    alpha = min(max(alpha, 1e-6), 1.0 - 1e-12)\n",
    "    return float(chi2.ppf(alpha, df=D))\n",
    "\n",
    "def greedy_dopt_select_from_kernel(K, k, jitter=1e-6, log_eps=1e-300):\n",
    "    K = np.asarray(K, dtype=np.float64)\n",
    "    n = K.shape[0]\n",
    "    k = int(min(k, n))\n",
    "    if k <= 0:\n",
    "        return np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "    diag = np.diag(K).copy() + float(jitter)\n",
    "    chosen = []\n",
    "    Lchol = None\n",
    "\n",
    "    for t in range(k):\n",
    "        if t == 0:\n",
    "            safe = np.maximum(diag, log_eps)\n",
    "            i = int(np.argmax(np.log(safe)))\n",
    "            chosen.append(i)\n",
    "            Lchol = np.sqrt(max(diag[i], log_eps)).reshape(1, 1)\n",
    "            continue\n",
    "\n",
    "        S = np.array(chosen, dtype=np.int64)\n",
    "        K_S = K[:, S]\n",
    "        v = np.linalg.solve(Lchol, K_S.T)\n",
    "        sq = np.sum(v * v, axis=0)\n",
    "        schur = diag - sq\n",
    "\n",
    "        schur[S] = -np.inf\n",
    "        schur_pos = np.maximum(schur, log_eps)\n",
    "        scores = np.log(schur_pos)\n",
    "        scores[S] = -np.inf\n",
    "\n",
    "        i = int(np.argmax(scores))\n",
    "        chosen.append(i)\n",
    "\n",
    "        k_iS = K[i, S].reshape(1, -1)\n",
    "        w = np.linalg.solve(Lchol, k_iS.T)\n",
    "        alpha2 = diag[i] - float(np.sum(w * w))\n",
    "        alpha2 = max(alpha2, log_eps)\n",
    "        alpha = np.sqrt(alpha2)\n",
    "\n",
    "        Lnew = np.zeros((t + 1, t + 1), dtype=np.float64)\n",
    "        Lnew[:t, :t] = Lchol\n",
    "        Lnew[t, :t] = w.reshape(-1)\n",
    "        Lnew[t, t] = alpha\n",
    "        Lchol = Lnew\n",
    "\n",
    "    return np.array(chosen, dtype=np.int64)\n",
    "\n",
    "def select_tube_subset(\n",
    "    Z_global,\n",
    "    kernel_for_dopt,\n",
    "    rollout_inputs,\n",
    "    rollout_weights,\n",
    "    total_subset_size=64,\n",
    "    anchor_idx=None,\n",
    "    time_bins=16,\n",
    "    cov_eps=1e-6,\n",
    "    dopt_jitter=1e-6,\n",
    "    fallback_candidates=400,\n",
    "    alpha=0.99,\n",
    "):\n",
    "    Zg = np.asarray(Z_global, dtype=np.float64)\n",
    "    M = Zg.shape[0]\n",
    "\n",
    "    if anchor_idx is None:\n",
    "        anchor_idx = np.zeros((0,), dtype=np.int64)\n",
    "    anchor_idx = np.unique(np.asarray(anchor_idx, dtype=np.int64))\n",
    "    anchor_idx = anchor_idx[(anchor_idx >= 0) & (anchor_idx < M)]\n",
    "\n",
    "    tube_mean, tube_cov = compute_weighted_moments(rollout_inputs, rollout_weights)\n",
    "    H, D = tube_mean.shape\n",
    "\n",
    "    chi2_thr = chi2_radius_sq(alpha, D)\n",
    "\n",
    "    dmin, tmin = min_mahalanobis_and_argmin(Zg, tube_mean, tube_cov, cov_eps=cov_eps)\n",
    "    tube_candidates_idx = np.where(dmin <= chi2_thr)[0].astype(np.int64)\n",
    "\n",
    "    remaining_budget = int(total_subset_size - anchor_idx.size)\n",
    "    remaining_budget = max(0, remaining_budget)\n",
    "\n",
    "    if tube_candidates_idx.size < remaining_budget:\n",
    "        L = int(min(max(fallback_candidates, remaining_budget), M))\n",
    "        tube_candidates_idx = np.argsort(dmin)[:L].astype(np.int64)\n",
    "\n",
    "    tube_pool = tube_candidates_idx[~np.isin(tube_candidates_idx, anchor_idx)]\n",
    "    tmin_pool = tmin[tube_pool]\n",
    "\n",
    "    selected = set(int(i) for i in anchor_idx)\n",
    "\n",
    "    if remaining_budget > 0 and tube_pool.size > 0:\n",
    "        B = int(max(1, min(time_bins, H)))\n",
    "        edges = np.linspace(0, H, B + 1, dtype=np.int64)\n",
    "        quotas = split_even_quota(remaining_budget, B)\n",
    "\n",
    "        for b in range(B):\n",
    "            if len(selected) >= total_subset_size:\n",
    "                break\n",
    "\n",
    "            a, c = int(edges[b]), int(edges[b + 1])\n",
    "            if c <= a:\n",
    "                continue\n",
    "\n",
    "            in_bin = (tmin_pool >= a) & (tmin_pool < c)\n",
    "            bin_pool = tube_pool[in_bin]\n",
    "            if bin_pool.size == 0:\n",
    "                continue\n",
    "\n",
    "            k_b = int(min(quotas[b], bin_pool.size, total_subset_size - len(selected)))\n",
    "            if k_b <= 0:\n",
    "                continue\n",
    "\n",
    "            Zb = Zg[bin_pool]\n",
    "            Kb = kernel_for_dopt.K(tf.convert_to_tensor(Zb, dtype=tf.float64)).numpy().astype(np.float64)\n",
    "            pick = greedy_dopt_select_from_kernel(Kb, k=k_b, jitter=dopt_jitter)\n",
    "\n",
    "            for gidx in bin_pool[pick]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    if len(selected) < total_subset_size:\n",
    "        need = int(total_subset_size - len(selected))\n",
    "        leftover = tube_pool[~np.isin(tube_pool, np.array(list(selected), dtype=np.int64))]\n",
    "        if leftover.size > 0 and need > 0:\n",
    "            Zl = Zg[leftover]\n",
    "            Kl = kernel_for_dopt.K(tf.convert_to_tensor(Zl, dtype=tf.float64)).numpy().astype(np.float64)\n",
    "            pick = greedy_dopt_select_from_kernel(Kl, k=min(need, leftover.size), jitter=dopt_jitter)\n",
    "            for gidx in leftover[pick]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    if len(selected) < total_subset_size:\n",
    "        need = int(total_subset_size - len(selected))\n",
    "        remaining = np.setdiff1d(np.arange(M, dtype=np.int64), np.array(list(selected), dtype=np.int64), assume_unique=False)\n",
    "        if remaining.size > 0:\n",
    "            order = remaining[np.argsort(dmin[remaining])]\n",
    "            for gidx in order[:need]:\n",
    "                selected.add(int(gidx))\n",
    "\n",
    "    subset_idx = np.array(sorted(selected), dtype=np.int64)[:total_subset_size]\n",
    "    return subset_idx, tube_mean, tube_cov, tube_candidates_idx, chi2_thr\n",
    "\n",
    "# ============================================================\n",
    "# TF local predictor pack (NO RETRACING) ✅ ACROBOT\n",
    "# ============================================================\n",
    "@tf.function\n",
    "def wrap_pi_tf(theta):\n",
    "    two_pi = tf.constant(2.0 * np.pi, dtype=DTYPE_TF)\n",
    "    pi = tf.constant(np.pi, dtype=DTYPE_TF)\n",
    "    return tf.math.floormod(theta + pi, two_pi) - pi\n",
    "\n",
    "@tf.function\n",
    "def batch_state_to_features_tf(S, U):\n",
    "    \"\"\"\n",
    "    S: (B,4) = [th1, th2, w1, w2]\n",
    "    U: (B,)\n",
    "    -> (B,7) = [sin(th1), cos(th1), sin(th2), cos(th2), tanh(w1/8), tanh(w2/10), u]\n",
    "    \"\"\"\n",
    "    th1 = S[:, 0]\n",
    "    th2 = S[:, 1]\n",
    "    w1  = S[:, 2]\n",
    "    w2  = S[:, 3]\n",
    "    f0 = tf.sin(th1)\n",
    "    f1 = tf.cos(th1)\n",
    "    f2 = tf.sin(th2)\n",
    "    f3 = tf.cos(th2)\n",
    "    f4 = tf.tanh(w1 / tf.constant(8.0, dtype=DTYPE_TF))\n",
    "    f5 = tf.tanh(w2 / tf.constant(10.0, dtype=DTYPE_TF))\n",
    "    f6 = U\n",
    "    return tf.stack([f0, f1, f2, f3, f4, f5, f6], axis=1)\n",
    "\n",
    "@tf.function\n",
    "def se_ard_kernel_Kzx_tf(Z, X, lengthscales, variance):\n",
    "    ls = tf.reshape(lengthscales, (1, -1))\n",
    "    var = tf.cast(variance, DTYPE_TF)\n",
    "    Zs = Z / ls\n",
    "    Xs = X / ls\n",
    "    z2 = tf.reduce_sum(Zs * Zs, axis=1, keepdims=True)\n",
    "    x2 = tf.reduce_sum(Xs * Xs, axis=1, keepdims=True)\n",
    "    zx = tf.matmul(Zs, Xs, transpose_b=True)\n",
    "    r2 = tf.maximum(z2 + tf.transpose(x2) - 2.0 * zx, 0.0)\n",
    "    return var * tf.exp(-0.5 * r2)\n",
    "\n",
    "class LocalSubsetPredictor(tf.Module):\n",
    "    def __init__(self, Dfeat, Msub, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.Dfeat = int(Dfeat)\n",
    "        self.Msub  = int(Msub)\n",
    "\n",
    "        self.Z     = tf.Variable(tf.zeros([self.Msub, self.Dfeat], dtype=tf.float64), trainable=False)\n",
    "        self.L     = tf.Variable(tf.eye(self.Msub, dtype=tf.float64), trainable=False)\n",
    "        self.alpha = tf.Variable(tf.zeros([self.Msub, 1], dtype=tf.float64), trainable=False)\n",
    "        self.S     = tf.Variable(tf.eye(self.Msub, dtype=tf.float64), trainable=False)\n",
    "\n",
    "        self.ls    = tf.Variable(tf.ones([self.Dfeat], dtype=tf.float64), trainable=False)\n",
    "        self.var   = tf.Variable(1.0, dtype=tf.float64, trainable=False)\n",
    "\n",
    "    def assign_pack(self, Z, L, alpha, S, ls, var):\n",
    "        self.Z.assign(tf.cast(Z, tf.float64))\n",
    "        self.L.assign(tf.cast(L, tf.float64))\n",
    "        self.alpha.assign(tf.cast(alpha, tf.float64))\n",
    "        self.S.assign(tf.cast(S, tf.float64))\n",
    "        self.ls.assign(tf.cast(ls, tf.float64))\n",
    "        self.var.assign(tf.cast(var, tf.float64))\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def predict_mu_var(self, Xfeat):\n",
    "        Xfeat = tf.cast(Xfeat, tf.float64)\n",
    "        Kzx = se_ard_kernel_Kzx_tf(self.Z, Xfeat, self.ls, self.var)  # (M,N)\n",
    "\n",
    "        w1 = tf.linalg.triangular_solve(self.L, Kzx, lower=True)\n",
    "        W  = tf.linalg.triangular_solve(tf.transpose(self.L), w1, lower=False)\n",
    "\n",
    "        mu = tf.reshape(tf.matmul(Kzx, self.alpha, transpose_a=True), (-1,))\n",
    "\n",
    "        kxx = tf.fill((tf.shape(Xfeat)[0],), tf.cast(self.var, tf.float64))\n",
    "        Qdiag = tf.reduce_sum(Kzx * W, axis=0)\n",
    "        SW = tf.matmul(self.S, W)\n",
    "        Sdiag = tf.reduce_sum(W * SW, axis=0)\n",
    "\n",
    "        v = tf.maximum(kxx - Qdiag + Sdiag, tf.cast(1e-12, tf.float64))\n",
    "        return mu, v\n",
    "\n",
    "def build_local_pack_from_global_tf(model_global, Z_global, idx_sub):\n",
    "    idx_sub = np.asarray(idx_sub, dtype=np.int64)\n",
    "    Zg = np.asarray(Z_global, dtype=np.float64)\n",
    "    Z  = Zg[idx_sub].copy()\n",
    "\n",
    "    Ztf = tf.convert_to_tensor(Z, dtype=tf.float64)\n",
    "    muZ, SigZ = model_global.predict_f(Ztf, full_cov=True)\n",
    "    m = muZ\n",
    "    S = SigZ\n",
    "    if len(S.shape) == 3:\n",
    "        S = S[0]\n",
    "\n",
    "    ls  = tf.cast(model_global.kernel.lengthscales, tf.float64)\n",
    "    var = tf.cast(model_global.kernel.variance, tf.float64)\n",
    "\n",
    "    Kzz = se_ard_kernel_Kzx_tf(Ztf, Ztf, ls, var)\n",
    "    jitter = tf.cast(1e-6, tf.float64)\n",
    "    Kzz = 0.5 * (Kzz + tf.transpose(Kzz)) + jitter * tf.eye(tf.shape(Kzz)[0], dtype=tf.float64)\n",
    "    L = tf.linalg.cholesky(Kzz)\n",
    "\n",
    "    y = tf.linalg.triangular_solve(L, m, lower=True)\n",
    "    alpha = tf.linalg.triangular_solve(tf.transpose(L), y, lower=False)\n",
    "\n",
    "    return (Ztf, L, alpha, S, tf.reshape(ls, (-1,)), var)\n",
    "\n",
    "# ============================================================\n",
    "# MPPI cost (Acrobot)\n",
    "# ============================================================\n",
    "@tf.function\n",
    "def exploration_weight_tf(t):\n",
    "    explore_steps_f = tf.cast(EXPLORE_STEPS, DTYPE_TF)\n",
    "    t_f = tf.cast(t, DTYPE_TF)\n",
    "    a = tf.clip_by_value(1.0 - t_f / tf.maximum(explore_steps_f, 1.0), 0.0, 1.0)\n",
    "    return tf.cast(UNC_W_MIN, DTYPE_TF) + (tf.cast(UNC_W_MAX, DTYPE_TF) - tf.cast(UNC_W_MIN, DTYPE_TF)) * a\n",
    "\n",
    "@tf.function\n",
    "def stage_cost_acrobot_tf(S, U, unc_bonus=None, unc_w=0.0):\n",
    "    th1 = S[:, 0]\n",
    "    th2 = S[:, 1]\n",
    "    w1  = S[:, 2]\n",
    "    w2  = S[:, 3]\n",
    "    y_tip = acrobot_tip_height_proxy_tf(th1, th2)\n",
    "\n",
    "    c = (\n",
    "        - tf.cast(TIP_W, DTYPE_TF) * y_tip\n",
    "        + tf.cast(VEL_W, DTYPE_TF) * (tf.square(w1) + tf.square(w2))\n",
    "        + tf.cast(U_W, DTYPE_TF) * tf.square(U)\n",
    "    )\n",
    "    if (unc_bonus is not None) and (unc_w > 0.0):\n",
    "        c = c - tf.cast(unc_w, DTYPE_TF) * tf.cast(unc_bonus, DTYPE_TF)\n",
    "    return c\n",
    "\n",
    "@tf.function\n",
    "def terminal_cost_acrobot_tf(S):\n",
    "    th1 = S[:, 0]\n",
    "    th2 = S[:, 1]\n",
    "    y_tip = acrobot_tip_height_proxy_tf(th1, th2)\n",
    "    good = y_tip >= tf.cast(Y_TIP_GOAL, DTYPE_TF)\n",
    "    cT = tf.where(good, -tf.cast(TERM_BONUS, DTYPE_TF) * tf.ones_like(y_tip), tf.zeros_like(y_tip))\n",
    "    return cT\n",
    "\n",
    "# ============================================================\n",
    "# Global-local dynamics: uses persistent predictors (NO RETRACING)\n",
    "# ============================================================\n",
    "@tf.function(reduce_retracing=True)\n",
    "def gp_dynamics_step_batch_local_tf(S, U, local_dth1, local_dth2, local_dw1, local_dw2):\n",
    "    Xfeat = batch_state_to_features_tf(S, U)\n",
    "\n",
    "    dth1, _ = local_dth1.predict_mu_var(Xfeat)\n",
    "    dth2, _ = local_dth2.predict_mu_var(Xfeat)\n",
    "    dw1,  _ = local_dw1.predict_mu_var(Xfeat)\n",
    "    dw2,  _ = local_dw2.predict_mu_var(Xfeat)\n",
    "\n",
    "    S2 = tf.stack([\n",
    "        wrap_pi_tf(S[:, 0] + dth1),\n",
    "        wrap_pi_tf(S[:, 1] + dth2),\n",
    "        S[:, 2] + dw1,\n",
    "        S[:, 3] + dw2\n",
    "    ], axis=1)\n",
    "    return S2, Xfeat\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def rollout_tube_features_local_tf(state0, u_seq, local_dth1, local_dth2, local_dw1, local_dw2):\n",
    "    H = tf.shape(u_seq)[0]\n",
    "    s = tf.identity(state0)\n",
    "    tube = tf.TensorArray(dtype=DTYPE_TF, size=H)\n",
    "\n",
    "    t = tf.constant(0)\n",
    "    def cond(t, s, tube): return t < H\n",
    "    def body(t, s, tube):\n",
    "        u = u_seq[t]\n",
    "        xfeat = batch_state_to_features_tf(tf.expand_dims(s, axis=0), tf.expand_dims(u, axis=0))[0]\n",
    "        tube = tube.write(t, xfeat)\n",
    "        s2, _ = gp_dynamics_step_batch_local_tf(\n",
    "            tf.expand_dims(s, axis=0), tf.expand_dims(u, axis=0),\n",
    "            local_dth1, local_dth2, local_dw1, local_dw2\n",
    "        )\n",
    "        s = s2[0]\n",
    "        return t+1, s, tube\n",
    "\n",
    "    _, _, tube = tf.while_loop(cond, body, [t, s, tube], parallel_iterations=1)\n",
    "    return tube.stack()\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def mppi_plan_gpu_local_tf(state0, u_mean0, t_global,\n",
    "                           local_dth1, local_dth2, local_dw1, local_dw2,\n",
    "                           horizon=HORIZON, K=K_SAMPLES, sigma=SIGMA, lam=LAMBDA,\n",
    "                           base_seed=0):\n",
    "    H = tf.cast(horizon, tf.int32)\n",
    "    Kt = tf.cast(K, tf.int32)\n",
    "\n",
    "    seed = tf.stack([tf.cast(base_seed, tf.int32), tf.cast(t_global, tf.int32)], axis=0)\n",
    "    eps = tf.random.stateless_normal((Kt, H), seed=seed, mean=0.0, stddev=tf.cast(sigma, DTYPE_TF), dtype=DTYPE_TF)\n",
    "    U = tf.clip_by_value(u_mean0[None, :] + eps, tf.cast(U_MIN, DTYPE_TF), tf.cast(U_MAX, DTYPE_TF))\n",
    "\n",
    "    S = tf.tile(state0[None, :], [Kt, 1])\n",
    "    total_cost = tf.zeros((Kt,), dtype=DTYPE_TF)\n",
    "\n",
    "    Xta = tf.TensorArray(dtype=DTYPE_TF, size=H)\n",
    "    unc_w = exploration_weight_tf(t_global)\n",
    "\n",
    "    t = tf.constant(0, dtype=tf.int32)\n",
    "    def cond(t, S, total_cost, Xta): return t < H\n",
    "    def body(t, S, total_cost, Xta):\n",
    "        Ut = U[:, t]\n",
    "        S2, Xfeat = gp_dynamics_step_batch_local_tf(S, Ut, local_dth1, local_dth2, local_dw1, local_dw2)\n",
    "        Xta = Xta.write(t, Xfeat)\n",
    "\n",
    "        # uncertainty bonus: use dw2 variance (can swap to dw1 if you like)\n",
    "        _, unc_v = local_dw2.predict_mu_var(Xfeat)\n",
    "        total_cost = total_cost + stage_cost_acrobot_tf(S, Ut, unc_bonus=unc_v, unc_w=unc_w)\n",
    "        return t+1, S2, total_cost, Xta\n",
    "\n",
    "    _, S, total_cost, Xta = tf.while_loop(cond, body, [t, S, total_cost, Xta], parallel_iterations=1)\n",
    "    total_cost = total_cost + terminal_cost_acrobot_tf(S)\n",
    "\n",
    "    cmin = tf.reduce_min(total_cost)\n",
    "    w = tf.exp(-(total_cost - cmin) / tf.cast(lam, DTYPE_TF))\n",
    "    wsum = tf.reduce_sum(w) + tf.cast(1e-12, DTYPE_TF)\n",
    "\n",
    "    u_mean = u_mean0 + tf.reduce_sum(w[:, None] * eps, axis=0) / wsum\n",
    "    u_mean = tf.clip_by_value(u_mean, tf.cast(U_MIN, DTYPE_TF), tf.cast(U_MAX, DTYPE_TF))\n",
    "\n",
    "    tubeX = rollout_tube_features_local_tf(state0, u_mean, local_dth1, local_dth2, local_dw1, local_dw2)\n",
    "    XHKD = Xta.stack()\n",
    "    Xroll = tf.transpose(XHKD, perm=[1, 0, 2])  # (K,H,Dfeat)\n",
    "    return u_mean[0], u_mean, tubeX, unc_w, Xroll, w\n",
    "\n",
    "def mppi_plan_gpu_local(state, u_init, t_global,\n",
    "                        local_dth1, local_dth2, local_dw1, local_dw2,\n",
    "                        base_seed=0):\n",
    "    state0 = tf.convert_to_tensor(np.asarray(state, dtype=np.float64).reshape(4,), dtype=DTYPE_TF)\n",
    "    u0     = tf.convert_to_tensor(np.asarray(u_init, dtype=np.float64).reshape(-1,), dtype=DTYPE_TF)\n",
    "\n",
    "    dev = \"/GPU:0\" if len(tf.config.list_logical_devices(\"GPU\")) > 0 else \"/CPU:0\"\n",
    "    if REQUIRE_GPU: dev = \"/GPU:0\"\n",
    "\n",
    "    with tf.device(dev):\n",
    "        u_first, u_mean, tubeX, unc_w, Xroll, w = mppi_plan_gpu_local_tf(\n",
    "            state0, u0, tf.convert_to_tensor(int(t_global), dtype=tf.int32),\n",
    "            local_dth1, local_dth2, local_dw1, local_dw2,\n",
    "            horizon=HORIZON, K=K_SAMPLES, sigma=SIGMA, lam=LAMBDA,\n",
    "            base_seed=int(base_seed)\n",
    "        )\n",
    "\n",
    "    return float(u_first.numpy()), u_mean.numpy(), tubeX.numpy(), float(unc_w.numpy()), Xroll.numpy(), w.numpy()\n",
    "\n",
    "# ----------------------------\n",
    "# Visualization helpers\n",
    "# ----------------------------\n",
    "def display_run_animation_from_frames(frames, fps=FPS, resize=RESIZE):\n",
    "    if frames is None or len(frames) == 0:\n",
    "        print(\"⚠️ No frames captured for this run.\")\n",
    "        return None\n",
    "\n",
    "    fig = plt.figure(figsize=(resize[0]/100, resize[1]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    def animate_fn(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate_fn,\n",
    "        frames=len(frames),\n",
    "        interval=1000 / float(fps),\n",
    "        blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    html = HTML(ani.to_jshtml())\n",
    "    display(html)\n",
    "    return html\n",
    "\n",
    "def success_hold_update_acrobot(state, hold_count):\n",
    "    th1, th2, w1, w2 = state\n",
    "    y_tip = acrobot_tip_height_proxy_np(th1, th2)\n",
    "    good = (y_tip >= float(Y_TIP_GOAL))\n",
    "    hold_count = (hold_count + 1) if good else 0\n",
    "    success = (hold_count >= int(HOLD_STEPS))\n",
    "    return hold_count, success, y_tip, good\n",
    "\n",
    "# ============================================================\n",
    "# Single EPISODE runner ✅ ACROBOT\n",
    "# ============================================================\n",
    "def run_one_episode_mppi_retrain_rgb_with_eval(\n",
    "    max_steps=600, seed=0, verbose=True,\n",
    "    use_gpu_mppi=True,\n",
    "    warmup_mppi=True,\n",
    "    record_rgb=True,\n",
    "    t_offset_in_run=0,\n",
    "    return_frames=False,\n",
    "):\n",
    "    global m_dth1, m_dth2, m_dw1, m_dw2\n",
    "    global Z_GLOBAL\n",
    "    global STD_CMAX_FIXED\n",
    "\n",
    "    env = make_env(render_mode=None, seed=seed, max_episode_steps=max_steps)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    s = np.array(obs_to_state(obs), dtype=np.float64)  # (th1, th2, w1, w2)\n",
    "\n",
    "    # Ensure Z_GLOBAL fixed size\n",
    "    Z_GLOBAL = np.asarray(Z_GLOBAL, dtype=np.float64)\n",
    "    if Z_GLOBAL.shape[0] != int(M_GLOBAL):\n",
    "        if Z_GLOBAL.shape[0] > int(M_GLOBAL):\n",
    "            Z_GLOBAL = Z_GLOBAL[:int(M_GLOBAL)].copy()\n",
    "        else:\n",
    "            raise ValueError(f\"Z_GLOBAL has {Z_GLOBAL.shape[0]} points but M_GLOBAL={M_GLOBAL}.\")\n",
    "\n",
    "    # anchors\n",
    "    ANCHOR_IDX = compute_anchor_idx_dopt_from_Zglobal_multihead(\n",
    "        Z_GLOBAL, m_anchors=ANCHOR_M, lam=ANCHOR_LAM, normalize_traces=True\n",
    "    )\n",
    "\n",
    "    # init local subset + mean action sequence\n",
    "    u_mean = np.zeros((HORIZON,), dtype=np.float64)\n",
    "    idx_sub = np.arange(min(M_SUB, M_GLOBAL), dtype=np.int64)\n",
    "\n",
    "    # Persistent TF predictors per head (no retracing on rebuild)\n",
    "    Dfeat = int(Z_GLOBAL.shape[1])  # feature dim = 7\n",
    "    local_dth1 = LocalSubsetPredictor(Dfeat, M_SUB, name=\"local_dth1\")\n",
    "    local_dth2 = LocalSubsetPredictor(Dfeat, M_SUB, name=\"local_dth2\")\n",
    "    local_dw1  = LocalSubsetPredictor(Dfeat, M_SUB, name=\"local_dw1\")\n",
    "    local_dw2  = LocalSubsetPredictor(Dfeat, M_SUB, name=\"local_dw2\")\n",
    "\n",
    "    def refresh_locals(idx_sub_np):\n",
    "        Z,L,a,S,ls,var = build_local_pack_from_global_tf(m_dth1, Z_GLOBAL, idx_sub_np); local_dth1.assign_pack(Z,L,a,S,ls,var)\n",
    "        Z,L,a,S,ls,var = build_local_pack_from_global_tf(m_dth2, Z_GLOBAL, idx_sub_np); local_dth2.assign_pack(Z,L,a,S,ls,var)\n",
    "        Z,L,a,S,ls,var = build_local_pack_from_global_tf(m_dw1,  Z_GLOBAL, idx_sub_np); local_dw1.assign_pack(Z,L,a,S,ls,var)\n",
    "        Z,L,a,S,ls,var = build_local_pack_from_global_tf(m_dw2,  Z_GLOBAL, idx_sub_np); local_dw2.assign_pack(Z,L,a,S,ls,var)\n",
    "\n",
    "    refresh_locals(idx_sub)\n",
    "\n",
    "    last_idx_sub = np.array(idx_sub, dtype=np.int64)\n",
    "    last_local_rebuild_t = 0\n",
    "\n",
    "    pred_time_step = np.zeros((max_steps,), dtype=np.float64)\n",
    "    train_time_step = np.zeros((max_steps,), dtype=np.float64)\n",
    "    wall_excl_vis_cum = np.zeros((max_steps,), dtype=np.float64)\n",
    "\n",
    "    t_wall_start = time.perf_counter()\n",
    "    vis_time_s = 0.0\n",
    "\n",
    "    # warmup: compile once\n",
    "    if use_gpu_mppi and warmup_mppi:\n",
    "        _ = mppi_plan_gpu_local(\n",
    "            state=s, u_init=u_mean, t_global=int(t_offset_in_run),\n",
    "            local_dth1=local_dth1, local_dth2=local_dth2, local_dw1=local_dw1, local_dw2=local_dw2,\n",
    "            base_seed=seed\n",
    "        )\n",
    "\n",
    "    frames = []\n",
    "    total_reward = 0.0\n",
    "    hold_count = 0\n",
    "    updates = 0\n",
    "\n",
    "    Xbuf, ydth1_buf, ydth2_buf, ydw1_buf, ydw2_buf = [], [], [], [], []\n",
    "    last_rollout_inputs = None\n",
    "    last_rollout_weights = None\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        t_global = int(t_offset_in_run + t)\n",
    "\n",
    "        # ---------- MPPI plan ----------\n",
    "        t0 = time.perf_counter()\n",
    "        if use_gpu_mppi:\n",
    "            u0, u_mean, tubeX, unc_w, Xroll, wroll = mppi_plan_gpu_local(\n",
    "                state=s, u_init=u_mean, t_global=t_global,\n",
    "                local_dth1=local_dth1, local_dth2=local_dth2, local_dw1=local_dw1, local_dw2=local_dw2,\n",
    "                base_seed=seed\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(\"use_gpu_mppi=False path not wired in this cell (set use_gpu_mppi=True).\")\n",
    "        t1 = time.perf_counter()\n",
    "        pred_time_step[t] = (t1 - t0)\n",
    "\n",
    "        last_rollout_inputs = Xroll\n",
    "        last_rollout_weights = wroll\n",
    "\n",
    "        # ---------- tube subset selection ----------\n",
    "        idx_sub_cand, _, _, _, _ = select_tube_subset(\n",
    "            Z_global=Z_GLOBAL,\n",
    "            kernel_for_dopt=m_dw2.kernel,   # choose one head for D-opt inside bins (consistent)\n",
    "            rollout_inputs=last_rollout_inputs,\n",
    "            rollout_weights=last_rollout_weights,\n",
    "            total_subset_size=M_SUB,\n",
    "            anchor_idx=ANCHOR_IDX,\n",
    "            time_bins=TUBE_TIME_BINS,\n",
    "            cov_eps=TUBE_COV_EPS,\n",
    "            dopt_jitter=1e-6,\n",
    "            fallback_candidates=TUBE_FALLBACK_CANDIDATES,\n",
    "            alpha=TUBE_ALPHA,\n",
    "        )\n",
    "\n",
    "        inter = np.intersect1d(last_idx_sub, idx_sub_cand)\n",
    "        overlap = float(len(inter)) / float(len(idx_sub_cand)) if len(idx_sub_cand) > 0 else 1.0\n",
    "\n",
    "        need_rebuild = ((t - last_local_rebuild_t) >= int(LOCAL_REBUILD_EVERY)) or (overlap < float(LOCAL_OVERLAP_THRESH))\n",
    "        if need_rebuild:\n",
    "            idx_sub = np.array(idx_sub_cand, dtype=np.int64)\n",
    "            refresh_locals(idx_sub)  # no retracing; tensor assigns only\n",
    "            last_idx_sub = np.array(idx_sub, dtype=np.int64)\n",
    "            last_local_rebuild_t = int(t)\n",
    "        else:\n",
    "            idx_sub = last_idx_sub\n",
    "\n",
    "        # ---------- env step ----------\n",
    "        obs2, r, terminated, truncated, info = env.step(np.array([u0], dtype=np.float32))\n",
    "        s2 = np.array(obs_to_state(obs2), dtype=np.float64)\n",
    "        total_reward += float(r)\n",
    "\n",
    "        # collect executed transition (delta targets)\n",
    "        Xbuf.append(state_to_features(s[0], s[1], s[2], s[3], float(u0)))\n",
    "        ydth1_buf.append([wrap_pi(s2[0] - s[0])])\n",
    "        ydth2_buf.append([wrap_pi(s2[1] - s[1])])\n",
    "        ydw1_buf.append([s2[2] - s[2]])\n",
    "        ydw2_buf.append([s2[3] - s[3]])\n",
    "\n",
    "        # ---------- render (excluded from wall) ----------\n",
    "        if record_rgb and RECORD_RGB_DEFAULT and (t % FRAME_STRIDE == 0):\n",
    "            tv0 = time.perf_counter()\n",
    "            W, Hh = int(RESIZE[0]), int(RESIZE[1])\n",
    "            frame = render_acrobot_frame_from_state(s2[0], s2[1], W=W, H=Hh)\n",
    "            frames.append(frame)\n",
    "            vis_time_s += (time.perf_counter() - tv0)\n",
    "\n",
    "        # ---------- success tracking ----------\n",
    "        hold_count, success, y_tip, good = success_hold_update_acrobot(s2, hold_count)\n",
    "\n",
    "        if verbose and (t % 50 == 0):\n",
    "            print(f\"[t_global={t_global:04d}] u0={u0:+.2f} unc_w={unc_w:.2f}  y_tip={y_tip:+.3f}  hold={hold_count}/{HOLD_STEPS}\")\n",
    "\n",
    "        # ---------- UPDATE (global only) ----------\n",
    "        if ((t + 1) % UPDATE_EVERY == 0) and (len(Xbuf) >= 10):\n",
    "            updates += 1\n",
    "\n",
    "            Xnew  = np.asarray(Xbuf, dtype=np.float64)\n",
    "            y1    = np.asarray(ydth1_buf, dtype=np.float64)\n",
    "            y2    = np.asarray(ydth2_buf, dtype=np.float64)\n",
    "            y3    = np.asarray(ydw1_buf,  dtype=np.float64)\n",
    "            y4    = np.asarray(ydw2_buf,  dtype=np.float64)\n",
    "\n",
    "            # refit Z_GLOBAL (still fixed size)\n",
    "            Z_GLOBAL = refit_Z_global_multihead(\n",
    "                Z_global=Z_GLOBAL,\n",
    "                Xnew=Xnew,\n",
    "                M_global=M_GLOBAL,\n",
    "                lam=ANCHOR_LAM,\n",
    "                mode=\"mean\",\n",
    "                normalize_traces=False,\n",
    "            )\n",
    "\n",
    "            # train 4 heads (OSGPR)\n",
    "            ttrain0 = time.perf_counter()\n",
    "            m_dth1, _ = osgpr_stream_update(m_dth1, Xnew, y1, Z_GLOBAL, iters=ITERS_UPDATE, lr=LR_UPDATE, noise=NOISE_UPDATE, freeze_kernel=False)\n",
    "            m_dth2, _ = osgpr_stream_update(m_dth2, Xnew, y2, Z_GLOBAL, iters=ITERS_UPDATE, lr=LR_UPDATE, noise=NOISE_UPDATE, freeze_kernel=False)\n",
    "            m_dw1,  _ = osgpr_stream_update(m_dw1,  Xnew, y3, Z_GLOBAL, iters=ITERS_UPDATE, lr=LR_UPDATE, noise=NOISE_UPDATE, freeze_kernel=False)\n",
    "            m_dw2,  _ = osgpr_stream_update(m_dw2,  Xnew, y4, Z_GLOBAL, iters=ITERS_UPDATE, lr=LR_UPDATE, noise=NOISE_UPDATE, freeze_kernel=False)\n",
    "            ttrain1 = time.perf_counter()\n",
    "            train_time_step[t] += float(ttrain1 - ttrain0)\n",
    "\n",
    "            # clear buffers\n",
    "            Xbuf, ydth1_buf, ydth2_buf, ydw1_buf, ydw2_buf = [], [], [], [], []\n",
    "\n",
    "            # reselect anchors\n",
    "            ANCHOR_IDX = compute_anchor_idx_dopt_from_Zglobal_multihead(\n",
    "                Z_GLOBAL, m_anchors=ANCHOR_M, lam=ANCHOR_LAM, normalize_traces=True\n",
    "            )\n",
    "\n",
    "            # force rebuild subset after update\n",
    "            idx_sub, _, _, _, _ = select_tube_subset(\n",
    "                Z_global=Z_GLOBAL,\n",
    "                kernel_for_dopt=m_dw2.kernel,\n",
    "                rollout_inputs=last_rollout_inputs,\n",
    "                rollout_weights=last_rollout_weights,\n",
    "                total_subset_size=M_SUB,\n",
    "                anchor_idx=ANCHOR_IDX,\n",
    "                time_bins=TUBE_TIME_BINS,\n",
    "                cov_eps=TUBE_COV_EPS,\n",
    "                dopt_jitter=1e-6,\n",
    "                fallback_candidates=TUBE_FALLBACK_CANDIDATES,\n",
    "                alpha=TUBE_ALPHA,\n",
    "            )\n",
    "            refresh_locals(idx_sub)\n",
    "            last_idx_sub = np.array(idx_sub, dtype=np.int64)\n",
    "            last_local_rebuild_t = int(t)\n",
    "\n",
    "        # ---------- wall time cumulative excl vis ----------\n",
    "        wall_excl_vis_cum[t] = max((time.perf_counter() - t_wall_start) - vis_time_s, 0.0)\n",
    "\n",
    "        s = s2\n",
    "        if success or terminated or truncated:\n",
    "            y_tip = -np.cos(s2[0]) - np.cos(s2[0] + s2[1])\n",
    "            print(f\"[EP END] t_global={t_global:04d} t_ep={t:04d} \"\n",
    "                  f\"success={success} terminated={terminated} truncated={truncated} \"\n",
    "                  f\"y_tip={y_tip:.3f} hold={hold_count}/{HOLD_STEPS}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    steps = int(t + 1)\n",
    "\n",
    "    stats = dict(\n",
    "        total_reward=float(total_reward),\n",
    "        steps=steps,\n",
    "        updates=int(updates),\n",
    "        frames=int(len(frames)),\n",
    "        hold_steps=int(hold_count),\n",
    "        Z_global_size=int(len(Z_GLOBAL)),\n",
    "        std_cmax_fixed=float(STD_CMAX_FIXED) if STD_CMAX_FIXED is not None else None,\n",
    "        vis_time_s=float(vis_time_s),\n",
    "    )\n",
    "\n",
    "    frames_out = frames if (return_frames and record_rgb and RECORD_RGB_DEFAULT) else None\n",
    "    return stats, frames_out, last_idx_sub, pred_time_step[:steps], train_time_step[:steps], wall_excl_vis_cum[:steps]\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-RUN driver ✅ ACROBOT\n",
    "# ============================================================\n",
    "N_RUNS = 1\n",
    "N_EPISODES_PER_RUN = 4\n",
    "\n",
    "MAX_STEPS_PER_EP = 2000\n",
    "USE_GPU_MPPI = True\n",
    "VERBOSE = True\n",
    "\n",
    "Z_GLOBAL_INIT = np.asarray(Z_GLOBAL, dtype=np.float64).copy()\n",
    "\n",
    "params_th1_init = parameter_dict(m_dth1)\n",
    "params_th2_init = parameter_dict(m_dth2)\n",
    "params_w1_init  = parameter_dict(m_dw1)\n",
    "params_w2_init  = parameter_dict(m_dw2)\n",
    "\n",
    "def reset_models_and_globals_for_fresh_run():\n",
    "    global m_dth1, m_dth2, m_dw1, m_dw2\n",
    "    global Z_GLOBAL\n",
    "    global GLOBAL_SURF_HISTORY\n",
    "    global STD_CMAX_FIXED\n",
    "\n",
    "    Z_GLOBAL = Z_GLOBAL_INIT.copy()\n",
    "    if Z_GLOBAL.shape[0] != int(M_GLOBAL):\n",
    "        if Z_GLOBAL.shape[0] > int(M_GLOBAL):\n",
    "            Z_GLOBAL = Z_GLOBAL[:int(M_GLOBAL)].copy()\n",
    "        else:\n",
    "            raise ValueError(f\"Z_GLOBAL_INIT has {Z_GLOBAL.shape[0]} < M_GLOBAL={M_GLOBAL}.\")\n",
    "\n",
    "    multiple_assign(m_dth1, params_th1_init)\n",
    "    multiple_assign(m_dth2, params_th2_init)\n",
    "    multiple_assign(m_dw1,  params_w1_init)\n",
    "    multiple_assign(m_dw2,  params_w2_init)\n",
    "\n",
    "    for mm in [m_dth1, m_dth2, m_dw1, m_dw2]:\n",
    "        try: mm.build_predict_cache()\n",
    "        except Exception: pass\n",
    "\n",
    "    GLOBAL_SURF_HISTORY = []\n",
    "    STD_CMAX_FIXED = None\n",
    "\n",
    "run_pred_time = []\n",
    "run_train_time = []\n",
    "run_wall_cum = []\n",
    "run_rewards = []\n",
    "run_steps_total = []\n",
    "run_updates_total = []\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"\\n==================== RUN {run+1}/{N_RUNS} (fresh reset) ====================\")\n",
    "    reset_models_and_globals_for_fresh_run()\n",
    "\n",
    "    pred_concat = []\n",
    "    train_concat = []\n",
    "    wall_concat = []\n",
    "    t_offset = 0\n",
    "\n",
    "    frames_run = []\n",
    "    run_reward_sum = 0.0\n",
    "    run_updates_sum = 0\n",
    "    run_steps_sum = 0\n",
    "\n",
    "    for ep in range(N_EPISODES_PER_RUN):\n",
    "        record_rgb = (ep == 0)\n",
    "        warmup_mppi = (ep == 0)\n",
    "\n",
    "        print(f\"\\n--- RUN {run+1} EP {ep+1}/{N_EPISODES_PER_RUN} (t_offset={t_offset}) ---\")\n",
    "\n",
    "        stats_ep, frames_ep, _, pred_t, train_t, wall_cum_t = run_one_episode_mppi_retrain_rgb_with_eval(\n",
    "            max_steps=MAX_STEPS_PER_EP,\n",
    "            seed=1000*run + ep,\n",
    "            verbose=VERBOSE,\n",
    "            use_gpu_mppi=USE_GPU_MPPI,\n",
    "            warmup_mppi=warmup_mppi,\n",
    "            record_rgb=record_rgb,\n",
    "            t_offset_in_run=t_offset,\n",
    "            return_frames=True,\n",
    "        )\n",
    "\n",
    "        if record_rgb and (frames_ep is not None) and (len(frames_ep) > 0):\n",
    "            frames_run.extend(frames_ep)\n",
    "\n",
    "        pred_concat.append(pred_t)\n",
    "        train_concat.append(train_t)\n",
    "        wall_concat.append(wall_cum_t)\n",
    "\n",
    "        run_reward_sum += stats_ep[\"total_reward\"]\n",
    "        run_updates_sum += stats_ep[\"updates\"]\n",
    "        run_steps_sum += stats_ep[\"steps\"]\n",
    "        t_offset += stats_ep[\"steps\"]\n",
    "\n",
    "    pred_run = np.concatenate(pred_concat, axis=0)\n",
    "    train_run = np.concatenate(train_concat, axis=0)\n",
    "    wall_run = np.concatenate(wall_concat, axis=0)\n",
    "\n",
    "    # recompute wall cumulative cleanly\n",
    "    wall_incr = np.zeros_like(wall_run)\n",
    "    i0 = 0\n",
    "    for ep_arr in wall_concat:\n",
    "        ep_arr = np.asarray(ep_arr, dtype=np.float64)\n",
    "        if ep_arr.size > 0:\n",
    "            d = np.diff(np.concatenate([[0.0], ep_arr]))\n",
    "            wall_incr[i0:i0+len(d)] = d\n",
    "        i0 += len(ep_arr)\n",
    "    wall_cum_run = np.cumsum(np.maximum(wall_incr, 0.0))\n",
    "\n",
    "    run_pred_time.append(pred_run)\n",
    "    run_train_time.append(train_run)\n",
    "    run_wall_cum.append(wall_cum_run)\n",
    "    run_rewards.append(run_reward_sum)\n",
    "    run_steps_total.append(len(pred_run))\n",
    "    run_updates_total.append(run_updates_sum)\n",
    "\n",
    "    print(f\"\\n=== RUN {run+1}: single animation (episode 0 only) ===\")\n",
    "    _ = display_run_animation_from_frames(frames_run, fps=FPS, resize=RESIZE)\n",
    "\n",
    "# ============================================================\n",
    "# Aggregate across runs: mean + band (std)  (pad with NaN)\n",
    "# ============================================================\n",
    "maxT = int(max(run_steps_total))\n",
    "def pad_to(arr, T):\n",
    "    out = np.full((T,), np.nan, dtype=np.float64)\n",
    "    out[:len(arr)] = arr\n",
    "    return out\n",
    "\n",
    "pred_mat  = np.vstack([pad_to(a, maxT) for a in run_pred_time])\n",
    "train_mat = np.vstack([pad_to(a, maxT) for a in run_train_time])\n",
    "wall_mat  = np.vstack([pad_to(a, maxT) for a in run_wall_cum])\n",
    "\n",
    "t_axis = np.arange(maxT, dtype=np.int64)\n",
    "\n",
    "pred_mean  = np.nanmean(pred_mat, axis=0)\n",
    "pred_std   = np.nanstd(pred_mat, axis=0)\n",
    "\n",
    "wall_cum_mean = np.nanmean(wall_mat, axis=0)\n",
    "wall_cum_std  = np.nanstd(wall_mat, axis=0)\n",
    "\n",
    "# training: ignore zeros -> update-only\n",
    "train_mat_upd = train_mat.copy()\n",
    "train_mat_upd[~np.isfinite(train_mat_upd)] = np.nan\n",
    "train_mat_upd[train_mat_upd <= 0.0] = np.nan\n",
    "\n",
    "train_update_mean = np.nanmean(train_mat_upd, axis=0)\n",
    "train_update_std  = np.nanstd(train_mat_upd, axis=0)\n",
    "\n",
    "# cumulative update-only training\n",
    "train_cum_upd_mat = np.full_like(train_mat_upd, np.nan)\n",
    "for r in range(N_RUNS):\n",
    "    y = train_mat_upd[r].copy()\n",
    "    valid = np.isfinite(y)\n",
    "    cum = np.zeros((maxT,), dtype=np.float64)\n",
    "    running = 0.0\n",
    "    for i in range(maxT):\n",
    "        if valid[i]:\n",
    "            running += float(y[i])\n",
    "            cum[i] = running\n",
    "        else:\n",
    "            cum[i] = np.nan\n",
    "    train_cum_upd_mat[r] = cum\n",
    "\n",
    "train_update_cum_mean = np.nanmean(train_cum_upd_mat, axis=0)\n",
    "train_update_cum_std  = np.nanstd(train_cum_upd_mat, axis=0)\n",
    "\n",
    "def moving_average_1d(y, window=7):\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    w = int(max(1, window))\n",
    "    if y.size == 0 or w == 1:\n",
    "        return y.copy()\n",
    "    kernel = np.ones((w,), dtype=np.float64) / float(w)\n",
    "    return np.convolve(y, kernel, mode=\"same\")\n",
    "\n",
    "SMOOTH_UPD_WIN = 7\n",
    "\n",
    "mask_upd = np.isfinite(train_update_mean)\n",
    "t_upd = t_axis[mask_upd]\n",
    "y_upd_mean = train_update_mean[mask_upd]\n",
    "y_upd_std  = train_update_std[mask_upd]\n",
    "y_upd_mean_s = moving_average_1d(y_upd_mean, window=SMOOTH_UPD_WIN)\n",
    "\n",
    "mask_upd_cum = np.isfinite(train_update_cum_mean)\n",
    "t_upd_cum = t_axis[mask_upd_cum]\n",
    "y_upd_cum_mean = train_update_cum_mean[mask_upd_cum]\n",
    "y_upd_cum_std  = train_update_cum_std[mask_upd_cum]\n",
    "y_upd_cum_mean_s = moving_average_1d(y_upd_cum_mean, window=SMOOTH_UPD_WIN)\n",
    "\n",
    "# ============================================================\n",
    "# Plots with variability band (mean ± 1 std)\n",
    "# ============================================================\n",
    "plt.figure(figsize=(10, 3.2))\n",
    "plt.plot(t_upd, y_upd_mean_s, linewidth=2.0, label=f\"mean (smoothed over updates, win={SMOOTH_UPD_WIN})\")\n",
    "plt.fill_between(t_upd, y_upd_mean - y_upd_std, y_upd_mean + y_upd_std, alpha=0.2, label=\"±1 std (across runs)\")\n",
    "plt.xlabel(\"timestep (only update steps)\")\n",
    "plt.ylabel(\"training time per update (s)\")\n",
    "plt.title(\"Training time per UPDATE (zeros ignored) — mean ± std across runs\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 3.2))\n",
    "plt.plot(t_upd_cum, y_upd_cum_mean_s, linewidth=2.0, label=f\"mean cum (smoothed, win={SMOOTH_UPD_WIN})\")\n",
    "plt.fill_between(t_upd_cum, y_upd_cum_mean - y_upd_cum_std, y_upd_cum_mean + y_upd_cum_std, alpha=0.2, label=\"±1 std (across runs)\")\n",
    "plt.xlabel(\"timestep (only update steps)\")\n",
    "plt.ylabel(\"cumulative training time (s)\")\n",
    "plt.title(\"Cumulative training time over UPDATEs (zeros ignored) — mean ± std across runs\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 3.2))\n",
    "plt.plot(t_axis, pred_mean, linewidth=2.0, label=\"mean\")\n",
    "plt.fill_between(t_axis, pred_mean - pred_std, pred_mean + pred_std, alpha=0.2, label=\"±1 std (across runs)\")\n",
    "plt.xlabel(\"timestep (within run, concatenated episodes)\")\n",
    "plt.ylabel(\"prediction time (s) per step (MPPI planning)\")\n",
    "plt.title(\"Prediction (MPPI) time per timestep — mean ± std across runs\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 3.2))\n",
    "plt.plot(t_axis, wall_cum_mean, linewidth=2.0, label=\"mean\")\n",
    "plt.fill_between(t_axis, wall_cum_mean - wall_cum_std, wall_cum_mean + wall_cum_std, alpha=0.2, label=\"±1 std (across runs)\")\n",
    "plt.xlabel(\"timestep (within run, concatenated episodes)\")\n",
    "plt.ylabel(\"wall time cumulative (s) (EXCLUDING visualization)\")\n",
    "plt.title(\"Wall time cumulative (no visualization) — mean ± std across runs\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# Register this method (for cross-method overlay)\n",
    "# ============================================================\n",
    "METHOD_NAME = \"PALSGP_OSGPR_fixedZglobal_localSubset_ACROBOT\"\n",
    "\n",
    "register_method_results(METHOD_NAME, dict(\n",
    "    t_axis=t_axis,\n",
    "    pred_mean=pred_mean,\n",
    "    wall_cum_mean=wall_cum_mean,\n",
    "\n",
    "    train_update_t=t_upd,\n",
    "    train_update_mean=y_upd_mean_s,\n",
    "    train_update_std=y_upd_std,\n",
    "    train_update_cum_t=t_upd_cum,\n",
    "    train_update_cum_mean=y_upd_cum_mean_s,\n",
    "    train_update_cum_std=y_upd_cum_std,\n",
    "\n",
    "    meta=dict(\n",
    "        N_RUNS=N_RUNS,\n",
    "        N_EPISODES_PER_RUN=N_EPISODES_PER_RUN,\n",
    "        UPDATE_EVERY=UPDATE_EVERY,\n",
    "        HORIZON=HORIZON,\n",
    "        K_SAMPLES=K_SAMPLES,\n",
    "        M_GLOBAL=M_GLOBAL,\n",
    "        M_SUB=M_SUB,\n",
    "    )\n",
    "))\n",
    "\n",
    "print(f\"✅ Registered results into EVAL_REGISTRY under key: {METHOD_NAME}\")\n",
    "print(\"Current methods in registry:\", list(EVAL_REGISTRY.keys()))\n",
    "\n",
    "print(\"\\n==================== SUMMARY ====================\")\n",
    "for r in range(N_RUNS):\n",
    "    print(f\"RUN {r+1}: total_steps={run_steps_total[r]}, total_reward_sum={run_rewards[r]:.3f}, updates_sum={run_updates_total[r]}\")\n",
    "print(\"================================================\\n\")\n"
   ],
   "id": "13fec251cc6ac4d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "be1d8bcd725fccd8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
