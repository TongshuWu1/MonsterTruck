{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3a4760e7552a24",
   "metadata": {},
   "source": [
    "Envrionment Setup for MountainCarContinuous-v0"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd00b4b3fa16b522",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs visible to TF:\", tf.config.list_physical_devices(\"CPU\"))\n",
    "\n",
    "# Optional: show detailed GPU info\n",
    "for g in tf.config.list_physical_devices(\"CPU\"):\n",
    "    print(\" -\", g)\n",
    "\n",
    "# If this prints [] => you're on CPU only\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys, platform\n",
    "print(sys.executable)\n",
    "print(platform.platform())\n"
   ],
   "id": "d6d25fbe84cc8d47",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e430adcade89f47",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# ============================\n",
    "# Cell 1 — Imports + Config\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d790741e343106ca",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 2 — Env Factory + Basics\n",
    "# ============================\n",
    "\n",
    "ENV_ID = \"MountainCarContinuous-v0\"\n",
    "\n",
    "def make_env(render_mode=None, seed=0):\n",
    "    \"\"\"\n",
    "    render_mode:\n",
    "      - None: fastest (training)\n",
    "      - \"rgb_array\": frames for notebook animation\n",
    "      - \"human\": pops up window (not great for notebook)\n",
    "    \"\"\"\n",
    "    env = gym.make(ENV_ID, render_mode=render_mode)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    return env\n",
    "\n",
    "# Quick sanity check\n",
    "env = make_env(render_mode=None, seed=SEED)\n",
    "obs, info = env.reset()\n",
    "print(\"obs:\", obs, \"shape:\", obs.shape)\n",
    "print(\"action_space:\", env.action_space)\n",
    "print(\"observation_space:\", env.observation_space)\n",
    "\n",
    "# Useful constants\n",
    "OBS_DIM = env.observation_space.shape[0]   # 2: [position, velocity]\n",
    "ACT_DIM = env.action_space.shape[0]        # 1: [force]\n",
    "ACTION_LOW  = env.action_space.low.copy()\n",
    "ACTION_HIGH = env.action_space.high.copy()\n",
    "\n",
    "# Gym's goal is typically around position ~ 0.45 (varies by implementation)\n",
    "GOAL_POS_DEFAULT = 0.45\n",
    "env.close()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87f2b1b277bad586",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 3 — Notebook Render Utilities\n",
    "# ============================\n",
    "\n",
    "def resize_frame(frame, size=(640, 400)):\n",
    "    \"\"\"frame: HxWx3 uint8\"\"\"\n",
    "    if size is None:\n",
    "        return frame\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize(size, resample=Image.BILINEAR)\n",
    "    return np.asarray(img)\n",
    "\n",
    "def rollout_and_render(env, policy_fn, steps=600, seed=0,\n",
    "                       frame_stride=1, resize=(640, 400), fps=30):\n",
    "    \"\"\"\n",
    "    env must be created with render_mode=\"rgb_array\"\n",
    "    policy_fn(obs) -> action in [-1,1] shape (1,)\n",
    "    \"\"\"\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    frames = []\n",
    "    traj = []\n",
    "\n",
    "    for t in range(steps):\n",
    "        action = np.asarray(policy_fn(obs), dtype=np.float32).reshape(ACT_DIM,)\n",
    "        action = np.clip(action, ACTION_LOW, ACTION_HIGH)\n",
    "\n",
    "        obs2, reward, terminated, truncated, info = env.step(action)\n",
    "        traj.append((obs.copy(), action.copy(), reward, terminated, truncated))\n",
    "\n",
    "        if t % frame_stride == 0:\n",
    "            frame = env.render()\n",
    "            frame = resize_frame(frame, size=resize)\n",
    "            frames.append(frame)\n",
    "\n",
    "        obs = obs2\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    # ---- animate ----\n",
    "    fig = plt.figure(figsize=(resize[0]/100, resize[1]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames),\n",
    "        interval=1000 / fps, blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "    return traj\n",
    "\n",
    "def random_policy(obs):\n",
    "    # MountainCarContinuous expects 1D action in [-1,1]\n",
    "    return rng.uniform(low=-1.0, high=1.0, size=(1,))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "795adeef7d84a562",
   "metadata": {},
   "source": [
    "Initial Random data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41ccb8f9d26af7aa",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Render the RANDOM collection path (and collect X,Y)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_random_transitions_rendered(n_steps=500, seed=0,\n",
    "                                       frame_stride=1, resize=(720, 450), fps=30):\n",
    "    \"\"\"\n",
    "    Runs random actions, collects (X,Y), AND renders the rollout.\n",
    "    X = [p,v,u], Y = [dp,dv]\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    env_vis = make_env(render_mode=\"rgb_array\", seed=seed)\n",
    "    obs, info = env_vis.reset(seed=seed)\n",
    "\n",
    "    X_list, Y_list = [], []\n",
    "    traj_p, traj_v, traj_u = [], [], []\n",
    "    frames = []\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        u = rng.uniform(-1.0, 1.0, size=(1,)).astype(np.float64)\n",
    "        obs2, reward, terminated, truncated, info = env_vis.step(u)\n",
    "\n",
    "        p, v = obs\n",
    "        p2, v2 = obs2\n",
    "        dp = p2 - p\n",
    "        dv = v2 - v\n",
    "\n",
    "        X_list.append([p, v, float(u[0])])\n",
    "        Y_list.append([dp, dv])\n",
    "\n",
    "        traj_p.append(p)\n",
    "        traj_v.append(v)\n",
    "        traj_u.append(float(u[0]))\n",
    "\n",
    "        # render frame\n",
    "        if (t % frame_stride) == 0:\n",
    "            frame = env_vis.render()\n",
    "            frame = resize_frame(frame, size=resize)\n",
    "            frames.append(frame)\n",
    "\n",
    "        obs = obs2\n",
    "        if terminated or truncated:\n",
    "            obs, info = env_vis.reset(seed=seed + 123 + t)\n",
    "\n",
    "    env_vis.close()\n",
    "\n",
    "    X = np.asarray(X_list, dtype=np.float64)\n",
    "    Y = np.asarray(Y_list, dtype=np.float64)\n",
    "\n",
    "    # ---- show animation ----\n",
    "    fig = plt.figure(figsize=(resize[0]/100, resize[1]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    from matplotlib import animation\n",
    "    from IPython.display import HTML, display\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames),\n",
    "        interval=1000 / fps, blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "    # ---- show trajectory plots ----\n",
    "    traj_p = np.array(traj_p)\n",
    "    traj_v = np.array(traj_v)\n",
    "    traj_u = np.array(traj_u)\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.plot(traj_p, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"position p\")\n",
    "    plt.title(\"Random collection: position vs time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.plot(traj_v, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"velocity v\")\n",
    "    plt.title(\"Random collection: velocity vs time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.scatter(traj_p, traj_v, s=8, alpha=0.6)\n",
    "    plt.xlabel(\"position p\")\n",
    "    plt.ylabel(\"velocity v\")\n",
    "    plt.title(\"Random collection path in state space (p vs v)\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 3.5))\n",
    "    plt.plot(traj_u, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"action u\")\n",
    "    plt.title(\"Random actions over time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Collected X shape:\", X.shape, \" (p,v,u)\")\n",
    "    print(\"Collected Y shape:\", Y.shape, \" (dp,dv)\")\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# ---- run it ----\n",
    "X0, Y0 = collect_random_transitions_rendered(\n",
    "    n_steps=10,\n",
    "    seed=SEED,\n",
    "    frame_stride=4,\n",
    "    resize=(720, 450),\n",
    "    fps=12\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "922fcd49f885b6c3",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 7 — GPflow Setup (float64)\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPflow:\", gpflow.__version__)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afa4cb7cf3a5b0d7",
   "metadata": {},
   "source": [
    "OSGPR-VFE\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "56d818f37c15baa4",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 8 — Streaming OSGPR (VFE) — paper-style regression update (D-dim input)\n",
    "#   Works for MountainCar input x=[p,v,u] (D=3)\n",
    "#   Single-output GP (we train two models: dp and dv)\n",
    "#   ✅ Includes caching for VERY fast predict (needed for MPPI)\n",
    "# ===========================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "from gpflow.models import GPModel, InternalDataTrainingLossMixin\n",
    "from gpflow import covariances\n",
    "\n",
    "# --- stable numerics ---\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# helpers\n",
    "# ---------------------------\n",
    "def sym_jitter(A, jitter=1e-6):\n",
    "    A = np.asarray(A, dtype=np.float64)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    A = A + jitter * np.eye(A.shape[0], dtype=np.float64)\n",
    "    return A\n",
    "\n",
    "def finite_mask(*arrs):\n",
    "    m = None\n",
    "    for a in arrs:\n",
    "        a = np.asarray(a)\n",
    "        mm = np.isfinite(a).all(axis=1) if a.ndim == 2 else np.isfinite(a)\n",
    "        m = mm if m is None else (m & mm)\n",
    "    return m\n",
    "\n",
    "def choose_inducing_keep_old(Z_old, X_new, M, keep_frac=0.8, rng=None):\n",
    "    \"\"\"\n",
    "    D-dimensional inducing management:\n",
    "      keep_frac of old inducing points + rest from current batch.\n",
    "    Z_old: (M_old, D)\n",
    "    X_new: (N_new, D)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    Z_old = np.asarray(Z_old, dtype=np.float64)\n",
    "    X_new = np.asarray(X_new, dtype=np.float64)\n",
    "\n",
    "    assert Z_old.ndim == 2 and X_new.ndim == 2\n",
    "    D = Z_old.shape[1]\n",
    "    assert X_new.shape[1] == D, f\"Dim mismatch: Z_old D={D}, X_new D={X_new.shape[1]}\"\n",
    "\n",
    "    M_keep = int(np.round(M * keep_frac))\n",
    "    M_new  = M - M_keep\n",
    "    M_keep = min(M_keep, Z_old.shape[0])\n",
    "    M_new  = min(M_new,  X_new.shape[0])\n",
    "\n",
    "    old_idx = rng.choice(Z_old.shape[0], size=M_keep, replace=False) if M_keep > 0 else np.array([], dtype=int)\n",
    "    new_idx = rng.choice(X_new.shape[0], size=M_new,  replace=False) if M_new  > 0 else np.array([], dtype=int)\n",
    "\n",
    "    Z = np.vstack([Z_old[old_idx], X_new[new_idx]]).astype(np.float64)\n",
    "\n",
    "    if Z.shape[0] < M:\n",
    "        need = M - Z.shape[0]\n",
    "        extra = rng.choice(X_new.shape[0], size=need, replace=True)\n",
    "        Z = np.vstack([Z, X_new[extra]])\n",
    "    return Z\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# OSGPR-VFE model (Bui et al., NIPS 2017) — VFE case\n",
    "# ============================================================\n",
    "class OSGPR_VFE(GPModel, InternalDataTrainingLossMixin):\n",
    "    \"\"\"\n",
    "    Online Sparse Variational GP Regression (VFE), regression-only.\n",
    "    SINGLE-OUTPUT. Train two models for dp and dv.\n",
    "\n",
    "    ✅ Includes prediction cache for fast MPPI:\n",
    "      - build_predict_cache()\n",
    "      - predict_f_cached()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, kernel, mu_old, Su_old, Kaa_old, Z_old, Z, mean_function=None):\n",
    "        X, Y = gpflow.models.util.data_input_to_tensor(data)\n",
    "        self.X, self.Y = X, Y\n",
    "        likelihood = gpflow.likelihoods.Gaussian()\n",
    "        num_latent_gps = GPModel.calc_num_latent_gps_from_data(data, kernel, likelihood)\n",
    "        super().__init__(kernel, likelihood, mean_function, num_latent_gps)\n",
    "\n",
    "        Z = np.asarray(Z, dtype=np.float64)\n",
    "        assert Z.ndim == 2, \"Z must be (M, D)\"\n",
    "        self.inducing_variable = InducingPoints(Z)\n",
    "        self.num_data = tf.shape(self.X)[0]\n",
    "\n",
    "        # old summary (fixed)\n",
    "        mu_old  = np.asarray(mu_old, dtype=np.float64).reshape(-1, 1)\n",
    "        Su_old  = sym_jitter(Su_old, 1e-6)\n",
    "        Kaa_old = sym_jitter(Kaa_old, 1e-6)\n",
    "        Z_old   = np.asarray(Z_old, dtype=np.float64)\n",
    "        assert Z_old.ndim == 2, \"Z_old must be (M_old, D)\"\n",
    "\n",
    "        self.mu_old  = tf.Variable(mu_old,  trainable=False, dtype=gpflow.default_float())\n",
    "        self.Su_old  = tf.Variable(Su_old,  trainable=False, dtype=gpflow.default_float())\n",
    "        self.Kaa_old = tf.Variable(Kaa_old, trainable=False, dtype=gpflow.default_float())\n",
    "        self.Z_old   = tf.Variable(Z_old,   trainable=False, dtype=gpflow.default_float())\n",
    "\n",
    "        if self.mean_function is None:\n",
    "            self.mean_function = gpflow.mean_functions.Zero()\n",
    "\n",
    "        # cache state\n",
    "        self._cache_ready = False\n",
    "        self._cache_Lb = None\n",
    "        self._cache_LD = None\n",
    "        self._cache_rhs = None\n",
    "\n",
    "    def _common_terms(self):\n",
    "        Mb = self.inducing_variable.num_inducing\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        sigma2 = self.likelihood.variance\n",
    "\n",
    "        Saa = self.Su_old\n",
    "        ma  = self.mu_old\n",
    "\n",
    "        # Kbf, Kbb, Kba, Kaa (old)\n",
    "        Kbf = covariances.Kuf(self.inducing_variable, self.kernel, self.X)                # [Mb, N]\n",
    "        Kbb = covariances.Kuu(self.inducing_variable, self.kernel, jitter=jitter)         # [Mb, Mb]\n",
    "        Kba = covariances.Kuf(self.inducing_variable, self.kernel, self.Z_old)            # [Mb, Ma]\n",
    "\n",
    "        # current kernel at Z_old (optional mismatch correction term)\n",
    "        Kaa_cur = gpflow.utilities.add_noise_cov(self.kernel(self.Z_old), jitter)         # current kernel(Z_old,Z_old)\n",
    "        Kaa = gpflow.utilities.add_noise_cov(self.Kaa_old, jitter)                        # stored old kernel(Z_old,Z_old)\n",
    "\n",
    "        err = self.Y - self.mean_function(self.X)\n",
    "\n",
    "        # c = Kbf * (Y/sigma2) + Kba * (Saa^{-1} ma)\n",
    "        Sainv_ma = tf.linalg.solve(Saa, ma)\n",
    "        c1 = tf.matmul(Kbf, self.Y / sigma2)                                              # [Mb,1]\n",
    "        c2 = tf.matmul(Kba, Sainv_ma)                                                     # [Mb,1]\n",
    "        c  = c1 + c2                                                                      # [Mb,1]\n",
    "\n",
    "        # Cholesky(Kbb)\n",
    "        Lb = tf.linalg.cholesky(Kbb)\n",
    "        Lbinv_c   = tf.linalg.triangular_solve(Lb, c, lower=True)\n",
    "        Lbinv_Kba = tf.linalg.triangular_solve(Lb, Kba, lower=True)\n",
    "        Lbinv_Kbf = tf.linalg.triangular_solve(Lb, Kbf, lower=True) / tf.sqrt(sigma2)\n",
    "\n",
    "        d1 = tf.matmul(Lbinv_Kbf, Lbinv_Kbf, transpose_b=True)                            # [Mb,Mb]\n",
    "\n",
    "        # d2 = (LSa^{-1} Kab Lb^{-1})^T (LSa^{-1} Kab Lb^{-1})\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        Kab_Lbinv = tf.linalg.matrix_transpose(Lbinv_Kba)                                 # [Ma,Mb]\n",
    "        LSainv_Kab_Lbinv = tf.linalg.triangular_solve(LSa, Kab_Lbinv, lower=True)\n",
    "        d2 = tf.matmul(LSainv_Kab_Lbinv, LSainv_Kab_Lbinv, transpose_a=True)\n",
    "\n",
    "        # d3 = (La^{-1} Kab Lb^{-1})^T (La^{-1} Kab Lb^{-1})\n",
    "        La = tf.linalg.cholesky(Kaa)\n",
    "        Lainv_Kab_Lbinv = tf.linalg.triangular_solve(La, Kab_Lbinv, lower=True)\n",
    "        d3 = tf.matmul(Lainv_Kab_Lbinv, Lainv_Kab_Lbinv, transpose_a=True)\n",
    "\n",
    "        # D = I + d1 + d2 - d3\n",
    "        D = tf.eye(Mb, dtype=gpflow.default_float()) + d1 + d2 - d3\n",
    "        D = gpflow.utilities.add_noise_cov(D, jitter)\n",
    "        LD = tf.linalg.cholesky(D)\n",
    "\n",
    "        LDinv_Lbinv_c = tf.linalg.triangular_solve(LD, Lbinv_c, lower=True)\n",
    "\n",
    "        # Qff_diag term for trace: diag(Kfb Kbb^{-1} Kbf) / sigma2\n",
    "        Qff_diag = tf.reduce_sum(tf.square(Lbinv_Kbf), axis=0)                             # [N]\n",
    "\n",
    "        return (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "                Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag)\n",
    "\n",
    "    def maximum_log_likelihood_objective(self):\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        sigma2 = self.likelihood.variance\n",
    "        N = tf.cast(self.num_data, gpflow.default_float())\n",
    "\n",
    "        Saa = self.Su_old\n",
    "        ma  = self.mu_old\n",
    "\n",
    "        Kfdiag = self.kernel(self.X, full_cov=False)\n",
    "\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        # ma term\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        Lainv_ma = tf.linalg.triangular_solve(LSa, ma, lower=True)\n",
    "\n",
    "        bound = -0.5 * N * np.log(2.0 * np.pi)\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(err)) / sigma2\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(Lainv_ma))\n",
    "        bound +=  0.5 * tf.reduce_sum(tf.square(LDinv_Lbinv_c))\n",
    "\n",
    "        bound += -0.5 * N * tf.math.log(sigma2)\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LD)))\n",
    "\n",
    "        bound += -0.5 * tf.reduce_sum(Kfdiag) / sigma2\n",
    "        bound +=  0.5 * tf.reduce_sum(Qff_diag)\n",
    "\n",
    "        bound += tf.reduce_sum(tf.math.log(tf.linalg.diag_part(La)))\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LSa)))\n",
    "\n",
    "        Kaadiff = Kaa_cur - tf.matmul(Lbinv_Kba, Lbinv_Kba, transpose_a=True)\n",
    "        Sainv_Kaadiff = tf.linalg.solve(Saa, Kaadiff)\n",
    "        Kainv_Kaadiff = tf.linalg.solve(Kaa, Kaadiff)\n",
    "\n",
    "        bound += -0.5 * tf.reduce_sum(\n",
    "            tf.linalg.diag_part(Sainv_Kaadiff) - tf.linalg.diag_part(Kainv_Kaadiff)\n",
    "        )\n",
    "        return bound\n",
    "\n",
    "    def predict_f(self, Xnew, full_cov=False):\n",
    "        # slow but correct; cached version below is used in MPPI\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "\n",
    "        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)\n",
    "\n",
    "        if full_cov:\n",
    "            Kss = self.kernel(Xnew) + jitter * tf.eye(tf.shape(Xnew)[0], dtype=gpflow.default_float())\n",
    "            var = (\n",
    "                Kss\n",
    "                - tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n",
    "                + tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_Kbs, transpose_a=True)\n",
    "            )\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "        else:\n",
    "            var = (\n",
    "                self.kernel(Xnew, full_cov=False)\n",
    "                - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "                + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "            )\n",
    "            var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "\n",
    "    # ============================================================\n",
    "    # ✅ Prediction cache (HUGE speed-up for MPPI)\n",
    "    # ============================================================\n",
    "    def build_predict_cache(self):\n",
    "        \"\"\"\n",
    "        Build cached Cholesky factors + vector needed for fast prediction.\n",
    "        Call AFTER training, and AFTER every streaming update.\n",
    "        \"\"\"\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        self._cache_Lb = Lb\n",
    "        self._cache_LD = LD\n",
    "        self._cache_rhs = LDinv_Lbinv_c\n",
    "        self._cache_ready = True\n",
    "\n",
    "    def predict_f_cached(self, Xnew, full_cov=False):\n",
    "        \"\"\"\n",
    "        Fast prediction using cached matrices.\n",
    "        If cache not ready -> fallback to normal predict_f.\n",
    "        \"\"\"\n",
    "        if (not hasattr(self, \"_cache_ready\")) or (self._cache_ready is not True):\n",
    "            return self.predict_f(Xnew, full_cov=full_cov)\n",
    "\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "\n",
    "        Lb  = self._cache_Lb\n",
    "        LD  = self._cache_LD\n",
    "        rhs = self._cache_rhs\n",
    "\n",
    "        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)  # [M, Nnew]\n",
    "\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, rhs, transpose_a=True)\n",
    "\n",
    "        if full_cov:\n",
    "            Kss = self.kernel(Xnew) + jitter * tf.eye(tf.shape(Xnew)[0], dtype=gpflow.default_float())\n",
    "            var = (\n",
    "                Kss\n",
    "                - tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n",
    "                + tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_Kbs, transpose_a=True)\n",
    "            )\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "        else:\n",
    "            var = (\n",
    "                self.kernel(Xnew, full_cov=False)\n",
    "                - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "                + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "            )\n",
    "            var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "\n",
    "\n",
    "def train_osgpr(model, iters=250, lr=0.01):\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.maximum_log_likelihood_objective()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients([(g, v) for g, v in zip(grads, model.trainable_variables) if g is not None])\n",
    "        return loss\n",
    "\n",
    "    t0 = time.time()\n",
    "    last = None\n",
    "    for _ in range(iters):\n",
    "        last = step()\n",
    "    dt = time.time() - t0\n",
    "    return dt, float(last.numpy())\n",
    "\n",
    "\n",
    "def prior_summary(kernel, Z):\n",
    "    Z = np.asarray(Z, dtype=np.float64)\n",
    "    Kzz = kernel.K(Z).numpy()\n",
    "    Kzz = sym_jitter(Kzz, 1e-6)\n",
    "    mu0 = np.zeros((Z.shape[0], 1), dtype=np.float64)\n",
    "    return mu0, Kzz, Kzz, Z\n",
    "\n",
    "\n",
    "def extract_summary_from_model(model):\n",
    "    Z = model.inducing_variable.Z.numpy()\n",
    "\n",
    "    mu_tf, Sigma_tf = model.predict_f(Z, full_cov=True)  # u = f(Z)\n",
    "    mu = mu_tf.numpy()\n",
    "\n",
    "    Sigma = Sigma_tf.numpy()\n",
    "    if Sigma.ndim == 3:\n",
    "        Sigma = Sigma[0]\n",
    "    Sigma = sym_jitter(Sigma, 1e-6)\n",
    "\n",
    "    Kaa = model.kernel.K(Z).numpy()\n",
    "    Kaa = sym_jitter(Kaa, 1e-6)\n",
    "\n",
    "    return mu, Sigma, Kaa, Z\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d67176c12e7c7fe",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 9 — Train initial streaming OSGPR-VFE GPs for dp and dv\n",
    "#   Requires:\n",
    "#     X0: (N,3)  [p,v,u]\n",
    "#     Y0: (N,2)  [dp,dv]\n",
    "# ===========================\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# targets\n",
    "y_dp = Y0[:, 0:1].astype(np.float64)\n",
    "y_dv = Y0[:, 1:2].astype(np.float64)\n",
    "\n",
    "# inducing size\n",
    "M = 64\n",
    "idxZ = rng.choice(X0.shape[0], size=min(M, X0.shape[0]), replace=False)\n",
    "Z0 = X0[idxZ].copy()\n",
    "\n",
    "# kernels (3D input: p,v,u)\n",
    "kernel_dp = gpflow.kernels.SquaredExponential(lengthscales=[0.5, 0.2, 0.5], variance=1.0)\n",
    "kernel_dv = gpflow.kernels.SquaredExponential(lengthscales=[0.5, 0.2, 0.5], variance=1.0)\n",
    "\n",
    "# ===== dp model =====\n",
    "mu_old, Su_old, Kaa_old, Z_old = prior_summary(kernel_dp, Z0)\n",
    "m_dp = OSGPR_VFE(\n",
    "    data=(X0, y_dp),\n",
    "    kernel=kernel_dp,\n",
    "    mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "    Z=Z0\n",
    ")\n",
    "m_dp.likelihood.variance.assign(1e-4)\n",
    "\n",
    "print(\"Training dp model...\")\n",
    "t_dp, neg_dp = train_osgpr(m_dp, iters=300, lr=0.02)\n",
    "print(f\"dp done | train={t_dp:.3f}s | neg_obj={neg_dp:.4f}\")\n",
    "\n",
    "# ===== dv model =====\n",
    "mu_old, Su_old, Kaa_old, Z_old = prior_summary(kernel_dv, Z0)\n",
    "m_dv = OSGPR_VFE(\n",
    "    data=(X0, y_dv),\n",
    "    kernel=kernel_dv,\n",
    "    mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "    Z=Z0\n",
    ")\n",
    "m_dv.likelihood.variance.assign(1e-4)\n",
    "\n",
    "print(\"\\nTraining dv model...\")\n",
    "t_dv, neg_dv = train_osgpr(m_dv, iters=300, lr=0.02)\n",
    "print(f\"dv done | train={t_dv:.3f}s | neg_obj={neg_dv:.4f}\")\n",
    "\n",
    "# ✅ build caches (critical for MPPI speed)\n",
    "m_dp.build_predict_cache()\n",
    "m_dv.build_predict_cache()\n",
    "print(\"\\n✅ Prediction caches ready for MPPI\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c23dab0388182a94",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 10 — GP Visualization (+ Inducing points overlay)\n",
    "#   - Slice (Matplotlib)\n",
    "#   - 3D Surface INTERACTIVE (Plotly) ✅ spin/zoom\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "MC_P_MIN, MC_P_MAX = -1.2, 0.6\n",
    "MC_V_MIN, MC_V_MAX = -0.07, 0.07\n",
    "\n",
    "\n",
    "def gp_predict_mu_std_fast(model, X):\n",
    "    \"\"\"\n",
    "    Uses cached predict if available\n",
    "    X: (N,3) -> mu (N,), std (N,)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    if hasattr(model, \"predict_f_cached\"):\n",
    "        mu_tf, var_tf = model.predict_f_cached(X, full_cov=False)\n",
    "    else:\n",
    "        mu_tf, var_tf = model.predict_f(X, full_cov=False)\n",
    "\n",
    "    mu = mu_tf.numpy().reshape(-1)\n",
    "    var = var_tf.numpy().reshape(-1)\n",
    "    std = np.sqrt(np.maximum(var, 1e-12))\n",
    "    return mu, std\n",
    "\n",
    "\n",
    "def get_inducing_Z_np(model):\n",
    "    \"\"\"Safely fetch inducing locations Z as numpy array (M,3).\"\"\"\n",
    "    if hasattr(model, \"inducing_variable\") and hasattr(model.inducing_variable, \"Z\"):\n",
    "        return model.inducing_variable.Z.numpy()\n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Slice plot with axis control + Inducing points overlay\n",
    "# ============================================================\n",
    "def plot_slice_two_actions(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    title=\"Slice\",\n",
    "    y_label=\"Δy\",\n",
    "    v_fixed=0.0,\n",
    "    a_list=(+1.0, -1.0),\n",
    "    n_grid=280,\n",
    "    x_min=MC_P_MIN, x_max=MC_P_MAX,\n",
    "    y_min=None, y_max=None,\n",
    "    x_tick_step=None,\n",
    "    y_tick_step=None,\n",
    "    data_tol_v=0.01,\n",
    "    data_tol_a=0.2,\n",
    "    show_data=True,\n",
    "    show_minmax=True,\n",
    "    # --- inducing points ---\n",
    "    show_inducing=True,\n",
    "    inducing_tol_v=0.01,\n",
    "    inducing_tol_a=0.2,\n",
    "):\n",
    "    p_grid = np.linspace(x_min, x_max, n_grid)\n",
    "\n",
    "    curves = []\n",
    "    auto_ymin = +np.inf\n",
    "    auto_ymax = -np.inf\n",
    "\n",
    "    Z = get_inducing_Z_np(model)\n",
    "\n",
    "    for a_fixed in a_list:\n",
    "        X_query = np.column_stack([\n",
    "            p_grid,\n",
    "            np.full_like(p_grid, v_fixed),\n",
    "            np.full_like(p_grid, a_fixed),\n",
    "        ]).astype(np.float64)\n",
    "\n",
    "        mu, std = gp_predict_mu_std_fast(model, X_query)\n",
    "        lo = mu - 2 * std\n",
    "        hi = mu + 2 * std\n",
    "\n",
    "        curves.append((a_fixed, mu, std, lo, hi))\n",
    "        auto_ymin = min(auto_ymin, float(np.min(lo)))\n",
    "        auto_ymax = max(auto_ymax, float(np.max(hi)))\n",
    "\n",
    "    if y_min is None:\n",
    "        y_min = auto_ymin\n",
    "    if y_max is None:\n",
    "        y_max = auto_ymax\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    for a_fixed, mu, std, lo, hi in curves:\n",
    "        plt.plot(p_grid, mu, lw=2.5, label=f\"mean (u={a_fixed:+.1f})\")\n",
    "        plt.fill_between(p_grid, lo, hi, alpha=0.18, label=f\"±2σ (u={a_fixed:+.1f})\")\n",
    "\n",
    "        # ----- training data -----\n",
    "        if show_data:\n",
    "            X_train = np.asarray(X_train)\n",
    "            y_train = np.asarray(y_train).reshape(-1)\n",
    "            mask = (np.abs(X_train[:, 1] - v_fixed) < data_tol_v) & (np.abs(X_train[:, 2] - a_fixed) < data_tol_a)\n",
    "            if np.sum(mask) > 0:\n",
    "                plt.scatter(\n",
    "                    X_train[mask, 0], y_train[mask],\n",
    "                    s=22, alpha=0.65,\n",
    "                    label=f\"data (v≈{v_fixed:.2f}, u≈{a_fixed:+.1f}, n={np.sum(mask)})\"\n",
    "                )\n",
    "\n",
    "        # ----- inducing points -----\n",
    "        if show_inducing and (Z is not None):\n",
    "            maskZ = (np.abs(Z[:, 1] - v_fixed) < inducing_tol_v) & (np.abs(Z[:, 2] - a_fixed) < inducing_tol_a)\n",
    "            if np.sum(maskZ) > 0:\n",
    "                Zsel = Z[maskZ]\n",
    "                muZ, _ = gp_predict_mu_std_fast(model, Zsel)\n",
    "                plt.scatter(\n",
    "                    Zsel[:, 0], muZ,\n",
    "                    marker=\"x\", s=70, linewidths=2.0,\n",
    "                    label=f\"inducing Z (v≈{v_fixed:.2f}, u≈{a_fixed:+.1f}, M={np.sum(maskZ)})\"\n",
    "                )\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel(\"Position p\")\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    if x_tick_step is not None:\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(float(x_tick_step)))\n",
    "    if y_tick_step is not None:\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(float(y_tick_step)))\n",
    "\n",
    "    plt.grid(True, alpha=0.25)\n",
    "\n",
    "    if show_minmax:\n",
    "        mu_all = np.concatenate([c[1] for c in curves])\n",
    "        std_all = np.concatenate([c[2] for c in curves])\n",
    "        lo_all = np.concatenate([c[3] for c in curves])\n",
    "        hi_all = np.concatenate([c[4] for c in curves])\n",
    "\n",
    "        extra = (f\"\\nmean[min,max]=({mu_all.min():+.3e},{mu_all.max():+.3e})\"\n",
    "                 f\"  std[min,max]=({std_all.min():+.3e},{std_all.max():+.3e})\"\n",
    "                 f\"  band[min,max]=({lo_all.min():+.3e},{hi_all.max():+.3e})\")\n",
    "        plt.title(title + extra)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Plotly interactive 3D surface:\n",
    "#     z = mean, color = std + Inducing points overlay\n",
    "# ============================================================\n",
    "def plot_surface_mean_colored_by_std_interactive(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    title=\"3D Surface (interactive)\",\n",
    "    z_label=\"Δy\",\n",
    "    a_fixed=+1.0,\n",
    "    n_grid=80,\n",
    "    p_min=MC_P_MIN, p_max=MC_P_MAX,\n",
    "    v_min=MC_V_MIN, v_max=MC_V_MAX,\n",
    "    z_min=None, z_max=None,\n",
    "    std_min=None, std_max=None,\n",
    "    show_data=True,\n",
    "    data_tol_a=0.2,\n",
    "    # --- inducing points ---\n",
    "    show_inducing=True,\n",
    "    inducing_tol_a=0.2,\n",
    "):\n",
    "    p_grid = np.linspace(p_min, p_max, n_grid)\n",
    "    v_grid = np.linspace(v_min, v_max, n_grid)\n",
    "    P, V = np.meshgrid(p_grid, v_grid)\n",
    "\n",
    "    X_grid = np.column_stack([\n",
    "        P.ravel(),\n",
    "        V.ravel(),\n",
    "        np.full_like(P.ravel(), a_fixed)\n",
    "    ]).astype(np.float64)\n",
    "\n",
    "    mu, std = gp_predict_mu_std_fast(model, X_grid)\n",
    "    Mean = mu.reshape(P.shape)\n",
    "    Std  = std.reshape(P.shape)\n",
    "\n",
    "    if z_min is None:\n",
    "        z_min = float(np.min(Mean))\n",
    "    if z_max is None:\n",
    "        z_max = float(np.max(Mean))\n",
    "    if std_min is None:\n",
    "        std_min = float(np.min(Std))\n",
    "    if std_max is None:\n",
    "        std_max = float(np.max(Std))\n",
    "\n",
    "    surface = go.Surface(\n",
    "        x=P, y=V, z=Mean,\n",
    "        surfacecolor=Std,\n",
    "        colorscale=\"Viridis\",\n",
    "        cmin=std_min, cmax=std_max,\n",
    "        colorbar=dict(title=\"Std (uncertainty)\"),\n",
    "        opacity=0.95,\n",
    "        showscale=True,\n",
    "        name=\"surface\"\n",
    "    )\n",
    "\n",
    "    traces = [surface]\n",
    "\n",
    "    # --- overlay training points near action ---\n",
    "    if show_data:\n",
    "        X_train = np.asarray(X_train)\n",
    "        y_train = np.asarray(y_train).reshape(-1)\n",
    "        act = X_train[:, 2]\n",
    "        mask = np.abs(act - a_fixed) < data_tol_a\n",
    "        if np.sum(mask) > 0:\n",
    "            traces.append(\n",
    "                go.Scatter3d(\n",
    "                    x=X_train[mask, 0],\n",
    "                    y=X_train[mask, 1],\n",
    "                    z=y_train[mask],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=3, color=\"black\", opacity=0.6),\n",
    "                    name=f\"train (u≈{a_fixed:+.1f})\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # --- overlay inducing points (Z) ---\n",
    "    Z = get_inducing_Z_np(model)\n",
    "    if show_inducing and (Z is not None):\n",
    "        maskZ = np.abs(Z[:, 2] - a_fixed) < inducing_tol_a\n",
    "        if np.sum(maskZ) > 0:\n",
    "            Zsel = Z[maskZ]\n",
    "            muZ, _ = gp_predict_mu_std_fast(model, Zsel)  # put them on predicted mean surface\n",
    "            traces.append(\n",
    "                go.Scatter3d(\n",
    "                    x=Zsel[:, 0],\n",
    "                    y=Zsel[:, 1],\n",
    "                    z=muZ,\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=5, color=\"red\", opacity=0.95),\n",
    "                    name=f\"inducing Z (u≈{a_fixed:+.1f}, M={np.sum(maskZ)})\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "    fig.update_layout(\n",
    "        title=f\"{title} | u={a_fixed:+.1f}\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"Position p\", range=[p_min, p_max]),\n",
    "            yaxis=dict(title=\"Velocity v\", range=[v_min, v_max]),\n",
    "            zaxis=dict(title=z_label, range=[z_min, z_max]),\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "        height=650\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# ---- Example usage ----\n",
    "plot_slice_two_actions(\n",
    "    m_dp, X0, Y0[:, 0],\n",
    "    title=\"OSGPR-VFE slice: Δp (with inducing points)\",\n",
    "    y_label=\"Δp\",\n",
    "    v_fixed=0.0,\n",
    "    a_list=(+1.0, -1.0),\n",
    "    n_grid=280,\n",
    "    x_min=-1.2, x_max=0.6,\n",
    "    y_min=-0.012, y_max=0.012,\n",
    "    x_tick_step=0.1,\n",
    "    y_tick_step=0.005,\n",
    "    show_inducing=True,\n",
    "    inducing_tol_v=0.01,\n",
    "    inducing_tol_a=0.2\n",
    ")\n",
    "\n",
    "plot_surface_mean_colored_by_std_interactive(\n",
    "    m_dv, X0, Y0[:, 1],\n",
    "    title=\"OSGPR-VFE surface: Δv (with inducing points)\",\n",
    "    z_label=\"Δv\",\n",
    "    a_fixed=+1.0,\n",
    "    n_grid=80,\n",
    "    p_min=-1.2, p_max=0.6,\n",
    "    v_min=-0.07, v_max=0.07,\n",
    "    z_min=-0.0035, z_max=0.0035,\n",
    "    std_min=0.0, std_max=None,\n",
    "    show_inducing=True,\n",
    "    inducing_tol_a=0.2\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "745feae25e8c7846",
   "metadata": {},
   "source": "|MPPI\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Offline",
   "id": "7bccd869ac291f78"
  },
  {
   "cell_type": "code",
   "id": "647dc81f21f89222",
   "metadata": {},
   "source": [
    "# # ===========================\n",
    "# # Cell 11 — MPPI planner (CACHED) + uncertainty bonus + time penalty\n",
    "# #   - Exploration objective = maximize GP predictive uncertainty along rollout\n",
    "# #   - Exploitation objective = reach goal fast (time penalty) + SMALL distance-to-goal penalty\n",
    "# #   - NO action penalty (per your request)\n",
    "# #   - Uses cached predictor for speed; rebuild after each streaming update\n",
    "# # ===========================\n",
    "#\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import gpflow\n",
    "# from gpflow import covariances\n",
    "#\n",
    "# # MountainCar bounds/constants\n",
    "# P_MIN, P_MAX = -1.2, 0.6\n",
    "# V_MIN, V_MAX = -0.07, 0.07\n",
    "# U_MIN, U_MAX = -1.0, 1.0\n",
    "# GOAL_POS = 0.45\n",
    "#\n",
    "#\n",
    "# # -------------------------------------------------\n",
    "# # Cached predictor builder for OSGPR_VFE (fast diag predict)\n",
    "# # -------------------------------------------------\n",
    "# def build_cached_predictor_osgpr(model):\n",
    "#     \"\"\"\n",
    "#     Returns fast callable:\n",
    "#         mu, std = pred(Xnew_np)\n",
    "#     Rebuild after streaming update (model changed).\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # Pull the expensive cached factors ONCE (graph capture will inline them)\n",
    "#     (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "#      Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = model._common_terms()\n",
    "#\n",
    "#     inducing = model.inducing_variable\n",
    "#     kernel = model.kernel\n",
    "#     mean_function = model.mean_function\n",
    "#\n",
    "#     @tf.function\n",
    "#     def _predict_tf(Xnew):\n",
    "#         Kbs = covariances.Kuf(inducing, kernel, Xnew)  # (Mb,N)\n",
    "#\n",
    "#         # mean\n",
    "#         Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "#         LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "#         mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)  # (N,1)\n",
    "#         mean = mean + mean_function(Xnew)\n",
    "#\n",
    "#         # diag var\n",
    "#         var = (\n",
    "#             kernel(Xnew, full_cov=False)\n",
    "#             - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "#             + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "#         )\n",
    "#         var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "#         return mean, var\n",
    "#\n",
    "#     def predict_np(Xnew_np):\n",
    "#         Xnew_tf = tf.convert_to_tensor(Xnew_np, dtype=gpflow.default_float())\n",
    "#         mu_tf, var_tf = _predict_tf(Xnew_tf)\n",
    "#         mu = mu_tf.numpy().reshape(-1)\n",
    "#         var = var_tf.numpy().reshape(-1)\n",
    "#         std = np.sqrt(np.maximum(var, 1e-12))\n",
    "#         return mu, std\n",
    "#\n",
    "#     return predict_np\n",
    "#\n",
    "#\n",
    "# # -------------------------------------------------\n",
    "# # Dynamics using cached predictors\n",
    "# # -------------------------------------------------\n",
    "# def gp_step_batch_cached(pred_dp, pred_dv, states, actions, return_unc=False):\n",
    "#     \"\"\"\n",
    "#     states:  (K,2) [p,v]\n",
    "#     actions: (K,)  u\n",
    "#     \"\"\"\n",
    "#     states = np.asarray(states, dtype=np.float64)\n",
    "#     actions = np.asarray(actions, dtype=np.float64).reshape(-1)\n",
    "#\n",
    "#     X = np.column_stack([states[:, 0], states[:, 1], actions]).astype(np.float64)\n",
    "#\n",
    "#     mu_dp, std_dp = pred_dp(X)\n",
    "#     mu_dv, std_dv = pred_dv(X)\n",
    "#\n",
    "#     p2 = np.clip(states[:, 0] + mu_dp, P_MIN, P_MAX)\n",
    "#     v2 = np.clip(states[:, 1] + mu_dv, V_MIN, V_MAX)\n",
    "#     next_states = np.stack([p2, v2], axis=1).astype(np.float64)\n",
    "#\n",
    "#     if return_unc:\n",
    "#         # simple scalar uncertainty proxy\n",
    "#         unc = np.sqrt(std_dp**2 + std_dv**2).astype(np.float64)\n",
    "#         return next_states, unc\n",
    "#     return next_states\n",
    "#\n",
    "#\n",
    "# # -------------------------------------------------\n",
    "# # Exploit costs (time + small distance penalty)\n",
    "# #   - NO action penalty (per request)\n",
    "# # -------------------------------------------------\n",
    "# def exploit_running_cost(states, w_time=1.0, w_goal=1.0):\n",
    "#     \"\"\"\n",
    "#     Cost per step:\n",
    "#       + w_time (encourage shorter time-to-goal)\n",
    "#       + small penalty for being far from goal (only when p < GOAL_POS)\n",
    "#     \"\"\"\n",
    "#     p = states[:, 0]\n",
    "#     goal_err = np.maximum(0.0, GOAL_POS - p)\n",
    "#     return (w_time * np.ones_like(p) + w_goal * (goal_err**2)).astype(np.float64)\n",
    "#\n",
    "#\n",
    "# def exploit_terminal_cost(states, w_terminal=250.0):\n",
    "#     \"\"\"\n",
    "#     Penalize ONLY if we haven't reached the goal at end of horizon.\n",
    "#     \"\"\"\n",
    "#     p = states[:, 0]\n",
    "#     miss = np.maximum(0.0, GOAL_POS - p)\n",
    "#     return (w_terminal * (miss**2)).astype(np.float64)\n",
    "#\n",
    "#\n",
    "# # -------------------------------------------------\n",
    "# # MPPI planner: minimize (exploit_cost - uncertainty_bonus)\n",
    "# # -------------------------------------------------\n",
    "# def mppi_plan_action_uncertainty(\n",
    "#     pred_dp, pred_dv,\n",
    "#     state0,\n",
    "#     u_nominal,\n",
    "#     rng,\n",
    "#     horizon=60,\n",
    "#     num_samples=256,\n",
    "#     noise_sigma=0.35,\n",
    "#     lam=1.0,\n",
    "#     u_smooth=0.65,\n",
    "#     # exploit weights\n",
    "#     w_time=1.0,\n",
    "#     w_goal=1.0,\n",
    "#     w_terminal=250.0,\n",
    "#     # explore weights\n",
    "#     w_unc=0.0,          # >0 => maximize uncertainty\n",
    "#     unc_scale=0.002,\n",
    "#     unc_every=5,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Total cost along rollout:\n",
    "#       J = sum_t [ w_time + w_goal * (max(0, goal-p))^2 ]  + terminal\n",
    "#           - w_unc * sum_{t in unc_every} (unc / unc_scale)\n",
    "#\n",
    "#     IMPORTANT:\n",
    "#       - This does NOT punish backward directly.\n",
    "#       - Time penalty + terminal miss cost allows \"back then forward\" if needed.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     state0 = np.asarray(state0, dtype=np.float64).reshape(2,)\n",
    "#     H = int(horizon)\n",
    "#     K = int(num_samples)\n",
    "#\n",
    "#     if u_nominal is None:\n",
    "#         u_nominal = np.zeros(H, dtype=np.float64)\n",
    "#     else:\n",
    "#         u_nominal = np.asarray(u_nominal, dtype=np.float64).reshape(H,)\n",
    "#\n",
    "#     noise = rng.normal(0.0, noise_sigma, size=(K, H)).astype(np.float64)\n",
    "#     U = np.clip(u_nominal[None, :] + noise, U_MIN, U_MAX)\n",
    "#\n",
    "#     states = np.repeat(state0[None, :], K, axis=0)\n",
    "#     total_cost = np.zeros(K, dtype=np.float64)\n",
    "#\n",
    "#     for t in range(H):\n",
    "#         a_t = U[:, t]\n",
    "#\n",
    "#         # propagate + optionally compute uncertainty bonus\n",
    "#         if (w_unc > 0.0) and (unc_every > 0) and ((t % unc_every) == 0):\n",
    "#             states, unc = gp_step_batch_cached(pred_dp, pred_dv, states, a_t, return_unc=True)\n",
    "#             total_cost += -w_unc * (unc / max(1e-12, unc_scale))\n",
    "#         else:\n",
    "#             states = gp_step_batch_cached(pred_dp, pred_dv, states, a_t, return_unc=False)\n",
    "#\n",
    "#         # exploit: time + small distance penalty\n",
    "#         total_cost += exploit_running_cost(states, w_time=w_time, w_goal=w_goal)\n",
    "#\n",
    "#     total_cost += exploit_terminal_cost(states, w_terminal=w_terminal)\n",
    "#\n",
    "#     beta = np.min(total_cost)\n",
    "#     w = np.exp(-(total_cost - beta) / max(1e-12, lam))\n",
    "#     w = w / (np.sum(w) + 1e-12)\n",
    "#\n",
    "#     du = np.sum(w[:, None] * noise, axis=0)\n",
    "#     u_new = np.clip(u_nominal + du, U_MIN, U_MAX)\n",
    "#\n",
    "#     u_nominal = u_smooth * u_nominal + (1.0 - u_smooth) * u_new\n",
    "#     u0 = float(u_nominal[0])\n",
    "#\n",
    "#     u_nominal = np.roll(u_nominal, -1)\n",
    "#     u_nominal[-1] = u_nominal[-2]\n",
    "#\n",
    "#     return u0, u_nominal, float(np.mean(total_cost)), float(np.min(total_cost))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d34b9d2eba090a66",
   "metadata": {},
   "source": [
    "# # ===========================\n",
    "# # Cell 12 — Train episodes (explore->exploit across episodes) + Streaming OSGPR-VFE\n",
    "# #   + Evaluation AFTER EVERY update (no explore)\n",
    "# #\n",
    "# # Strategy A Exploit:\n",
    "# #   ✅ running cost = time only   (W_GOAL = 0)\n",
    "# #   ✅ terminal cost = goal miss penalty (W_TERMINAL big)\n",
    "# #\n",
    "# # Added:\n",
    "# #   ✅ Replay buffer batch mixing\n",
    "# #   ✅ k-center inducing points\n",
    "# #   ✅ Freeze kernel (stable streaming)\n",
    "# #   ✅ GP slice + 3D surface plots after each update (your Cell 10 functions)\n",
    "# # ===========================\n",
    "#\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import gymnasium as gym\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import animation\n",
    "# from IPython.display import HTML, display\n",
    "# from PIL import Image\n",
    "#\n",
    "# import gpflow\n",
    "# import tensorflow as tf\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  EASY TUNING KNOBS  ====================\n",
    "# # ============================================================\n",
    "#\n",
    "# # ----------------------------\n",
    "# # Episodes / steps\n",
    "# # ----------------------------\n",
    "# NUM_TRAIN_EPISODES = 15\n",
    "# MAX_STEPS          = 600\n",
    "#\n",
    "# # ----------------------------\n",
    "# # Rendering / printing\n",
    "# # ----------------------------\n",
    "# RENDER_TRAIN    = True\n",
    "# RENDER_EVAL     = False\n",
    "# PRINT_EVERY_EP  = True\n",
    "#\n",
    "# FRAME_STRIDE = 2\n",
    "# RESIZE       = (720, 450)\n",
    "# FPS          = 15\n",
    "#\n",
    "# # ----------------------------\n",
    "# # MPPI knobs (DEFINE HERE so Cell 12 is self-contained)\n",
    "# # Must match your Cell 11 signature.\n",
    "# # ----------------------------\n",
    "# HORIZON     = 55\n",
    "# NUM_SAMPLES = 128\n",
    "# NOISE_SIGMA = 0.35\n",
    "# LAM         = 1.0\n",
    "# U_SMOOTH    = 0.65\n",
    "#\n",
    "# # ----------------------------\n",
    "# # EXPLOIT Strategy A weights\n",
    "# # ----------------------------\n",
    "# W_TIME     = 1.0\n",
    "# W_GOAL     = 0.0\n",
    "# W_TERMINAL = 350.0   # stronger terminal miss penalty helps consistency\n",
    "#\n",
    "# # ----------------------------\n",
    "# # Exploration schedule (uncertainty chasing)\n",
    "# # Your Cell 11 already has correct sign: total_cost += -w_unc * (unc/unc_scale)\n",
    "# # ----------------------------\n",
    "# UNC_W_START     = 15.0\n",
    "# UNC_ZERO_BY_EP  = 8\n",
    "# UNC_EVERY       = 5\n",
    "# UNC_SCALE       = 0.002\n",
    "#\n",
    "# # Explore-mode exploit weights (keep small so it can roam)\n",
    "# EXPLORE_W_TIME  = 0.10\n",
    "# EXPLORE_W_GOAL  = 0.00\n",
    "# EXPLORE_W_TERM  = 100.0\n",
    "#\n",
    "# # ----------------------------\n",
    "# # Streaming update (OSGPR-VFE)\n",
    "# # ----------------------------\n",
    "# M_INDUCING    = 48\n",
    "# TRAIN_ITERS   = 150\n",
    "# LR            = 0.005\n",
    "#\n",
    "# REPLAY_CAP    = 5000\n",
    "# BATCH_SIZE    = 1000\n",
    "# RECENT_FRAC   = 0.70\n",
    "#\n",
    "# MIN_NOISE_VAR = 1e-4\n",
    "#\n",
    "# # ----------------------------\n",
    "# # GP evaluation plots after each update\n",
    "# # ----------------------------\n",
    "# PLOT_GP_EVERY_UPDATE   = True\n",
    "# PLOT_GP_EVERY_N_UPDATE = 1\n",
    "# PLOT_USE_REPLAY_DATA   = True\n",
    "# PLOT_MAX_POINTS        = 3500\n",
    "# PLOT_SEED              = 0\n",
    "#\n",
    "# # Slice plot settings (Δp model)\n",
    "# SLICE_V_FIXED   = 0.0\n",
    "# SLICE_ACTIONS   = (+1.0, -1.0)\n",
    "# SLICE_N_GRID    = 280\n",
    "# SLICE_P_MIN     = -1.2\n",
    "# SLICE_P_MAX     = 0.6\n",
    "# SLICE_Y_MIN_DP  = -0.012\n",
    "# SLICE_Y_MAX_DP  = +0.012\n",
    "# SLICE_X_TICK    = 0.1\n",
    "# SLICE_Y_TICK_DP = 0.005\n",
    "#\n",
    "# # Surface plot settings (Δv model)\n",
    "# SURF_ACTION     = +1.0\n",
    "# SURF_N_GRID     = 80\n",
    "# SURF_P_MIN      = -1.2\n",
    "# SURF_P_MAX      = 0.6\n",
    "# SURF_V_MIN      = -0.07\n",
    "# SURF_V_MAX      = 0.07\n",
    "# SURF_Z_MIN_DV   = -0.0035\n",
    "# SURF_Z_MAX_DV   = +0.0035\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  SMALL UTILITIES  ======================\n",
    "# # ============================================================\n",
    "#\n",
    "# def resize_frame(frame, size=(720, 450)):\n",
    "#     if frame is None:\n",
    "#         return None\n",
    "#     img = Image.fromarray(frame)\n",
    "#     img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "#     return np.array(img)\n",
    "#\n",
    "# def show_frames(frames, fps=15):\n",
    "#     if len(frames) == 0:\n",
    "#         return\n",
    "#     fig = plt.figure(figsize=(RESIZE[0]/120, RESIZE[1]/120))\n",
    "#     ax = plt.gca()\n",
    "#     ax.axis(\"off\")\n",
    "#     im = ax.imshow(frames[0])\n",
    "#\n",
    "#     def animate(i):\n",
    "#         im.set_data(frames[i])\n",
    "#         return (im,)\n",
    "#\n",
    "#     ani = animation.FuncAnimation(\n",
    "#         fig, animate, frames=len(frames),\n",
    "#         interval=1000/fps, blit=True\n",
    "#     )\n",
    "#     plt.close(fig)\n",
    "#     display(HTML(ani.to_jshtml()))\n",
    "#\n",
    "# def episode_unc_weight(ep_index0):\n",
    "#     \"\"\"Quadratic decay from UNC_W_START to ~0 by UNC_ZERO_BY_EP.\"\"\"\n",
    "#     t = ep_index0 / max(1, (UNC_ZERO_BY_EP - 1))\n",
    "#     t = np.clip(t, 0.0, 1.0)\n",
    "#     return float(UNC_W_START * (1.0 - t)**2)\n",
    "#\n",
    "# def safe_set_min_noise(model, min_var=1e-4):\n",
    "#     try:\n",
    "#         cur = float(model.likelihood.variance.numpy())\n",
    "#         model.likelihood.variance.assign(np.maximum(min_var, cur))\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  REPLAY BUFFER  ========================\n",
    "# # ============================================================\n",
    "#\n",
    "# class ReplayBuffer:\n",
    "#     def __init__(self, cap, dim_x=3):\n",
    "#         self.cap = int(cap)\n",
    "#         self.dim_x = dim_x\n",
    "#         self.X   = np.zeros((0, dim_x), dtype=np.float64)\n",
    "#         self.ydp = np.zeros((0, 1),     dtype=np.float64)\n",
    "#         self.ydv = np.zeros((0, 1),     dtype=np.float64)\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return self.X.shape[0]\n",
    "#\n",
    "#     def add(self, X_new, ydp_new, ydv_new):\n",
    "#         X_new   = np.asarray(X_new,   dtype=np.float64).reshape(-1, self.dim_x)\n",
    "#         ydp_new = np.asarray(ydp_new, dtype=np.float64).reshape(-1, 1)\n",
    "#         ydv_new = np.asarray(ydv_new, dtype=np.float64).reshape(-1, 1)\n",
    "#\n",
    "#         self.X   = np.vstack([self.X,   X_new])\n",
    "#         self.ydp = np.vstack([self.ydp, ydp_new])\n",
    "#         self.ydv = np.vstack([self.ydv, ydv_new])\n",
    "#\n",
    "#         if len(self) > self.cap:\n",
    "#             extra = len(self) - self.cap\n",
    "#             self.X   = self.X[extra:]\n",
    "#             self.ydp = self.ydp[extra:]\n",
    "#             self.ydv = self.ydv[extra:]\n",
    "#\n",
    "#     def sample_mixed(self, n, recent_frac=0.7, rng=None):\n",
    "#         if rng is None:\n",
    "#             rng = np.random.default_rng(0)\n",
    "#\n",
    "#         N = len(self)\n",
    "#         if N == 0:\n",
    "#             raise ValueError(\"Replay buffer empty.\")\n",
    "#         n = int(min(n, N))\n",
    "#\n",
    "#         n_recent = int(np.round(n * recent_frac))\n",
    "#         n_old    = n - n_recent\n",
    "#\n",
    "#         recent_window = max(500, int(0.25 * N))\n",
    "#         recent_start = max(0, N - recent_window)\n",
    "#\n",
    "#         idx_recent_pool = np.arange(recent_start, N)\n",
    "#         idx_old_pool    = np.arange(0, N)\n",
    "#\n",
    "#         idx_recent = rng.choice(idx_recent_pool, size=min(n_recent, idx_recent_pool.size), replace=False) \\\n",
    "#             if n_recent > 0 else np.array([], dtype=int)\n",
    "#\n",
    "#         idx_old = rng.choice(idx_old_pool, size=min(n_old, idx_old_pool.size), replace=False) \\\n",
    "#             if n_old > 0 else np.array([], dtype=int)\n",
    "#\n",
    "#         idx = np.unique(np.concatenate([idx_recent, idx_old]))\n",
    "#         if idx.size < n:\n",
    "#             idx_more = rng.choice(np.arange(0, N), size=(n - idx.size), replace=True)\n",
    "#             idx = np.concatenate([idx, idx_more])\n",
    "#\n",
    "#         return self.X[idx], self.ydp[idx], self.ydv[idx]\n",
    "#\n",
    "# def sample_plot_data_from_replay(replay, max_points=3500, seed=0):\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     N = len(replay)\n",
    "#     if N == 0:\n",
    "#         return None, None, None\n",
    "#     if N <= max_points:\n",
    "#         idx = np.arange(N)\n",
    "#     else:\n",
    "#         idx = rng.choice(np.arange(N), size=max_points, replace=False)\n",
    "#     return replay.X[idx], replay.ydp[idx].reshape(-1), replay.ydv[idx].reshape(-1)\n",
    "#\n",
    "# # ============================================================\n",
    "# # ============  k-CENTER INDUCING POINT SELECTION  ============\n",
    "# # ============================================================\n",
    "#\n",
    "# def kcenter_greedy(Xcand, M, rng=None):\n",
    "#     if rng is None:\n",
    "#         rng = np.random.default_rng(0)\n",
    "#\n",
    "#     Xcand = np.asarray(Xcand, dtype=np.float64)\n",
    "#     N, D = Xcand.shape\n",
    "#     M = int(min(M, N))\n",
    "#\n",
    "#     start = int(rng.integers(0, N))\n",
    "#     chosen = [start]\n",
    "#     d2 = np.sum((Xcand - Xcand[start])**2, axis=1)\n",
    "#\n",
    "#     for _ in range(1, M):\n",
    "#         j = int(np.argmax(d2))\n",
    "#         chosen.append(j)\n",
    "#         d2 = np.minimum(d2, np.sum((Xcand - Xcand[j])**2, axis=1))\n",
    "#\n",
    "#     return Xcand[np.array(chosen)]\n",
    "#\n",
    "# def choose_inducing_kcenter(Z_old, X_new, M=48, rng=None):\n",
    "#     if rng is None:\n",
    "#         rng = np.random.default_rng(0)\n",
    "#     Z_old = np.asarray(Z_old, dtype=np.float64)\n",
    "#     X_new = np.asarray(X_new, dtype=np.float64)\n",
    "#     Xcand = np.vstack([Z_old, X_new])\n",
    "#     return kcenter_greedy(Xcand, M=M, rng=rng)\n",
    "#\n",
    "# # ============================================================\n",
    "# # =================  STREAMING UPDATE WRAPPER  =================\n",
    "# # ============================================================\n",
    "#\n",
    "# def streaming_update_once(m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "#                           X_batch, ydp_batch, ydv_batch,\n",
    "#                           M=48, train_iters=150, lr=0.005,\n",
    "#                           rng=None):\n",
    "#     if rng is None:\n",
    "#         rng = np.random.default_rng(0)\n",
    "#\n",
    "#     # --- dp ---\n",
    "#     mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dp)\n",
    "#     Z_new = choose_inducing_kcenter(Z_old, X_batch, M=M, rng=rng)\n",
    "#\n",
    "#     m_dp_new = OSGPR_VFE(\n",
    "#         data=(X_batch, ydp_batch),\n",
    "#         kernel=kernel_dp,\n",
    "#         mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "#         Z=Z_new\n",
    "#     )\n",
    "#     m_dp_new.likelihood.variance.assign(np.maximum(MIN_NOISE_VAR, float(m_dp.likelihood.variance.numpy())))\n",
    "#     gpflow.set_trainable(m_dp_new.kernel, False)\n",
    "#     gpflow.set_trainable(m_dp_new.likelihood, True)\n",
    "#     t_dp, neg_dp = train_osgpr(m_dp_new, iters=train_iters, lr=lr)\n",
    "#\n",
    "#     # --- dv ---\n",
    "#     mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dv)\n",
    "#     Z_new = choose_inducing_kcenter(Z_old, X_batch, M=M, rng=rng)\n",
    "#\n",
    "#     m_dv_new = OSGPR_VFE(\n",
    "#         data=(X_batch, ydv_batch),\n",
    "#         kernel=kernel_dv,\n",
    "#         mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "#         Z=Z_new\n",
    "#     )\n",
    "#     m_dv_new.likelihood.variance.assign(np.maximum(MIN_NOISE_VAR, float(m_dv.likelihood.variance.numpy())))\n",
    "#     gpflow.set_trainable(m_dv_new.kernel, False)\n",
    "#     gpflow.set_trainable(m_dv_new.likelihood, True)\n",
    "#     t_dv, neg_dv = train_osgpr(m_dv_new, iters=train_iters, lr=lr)\n",
    "#\n",
    "#     return m_dp_new, m_dv_new, (t_dp, neg_dp, t_dv, neg_dv)\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  ROLLOUT EPISODE  ======================\n",
    "# # ============================================================\n",
    "#\n",
    "# def run_episode(env, rng, pred_dp, pred_dv,\n",
    "#                 do_explore, w_unc,\n",
    "#                 w_time_use, w_goal_use, w_term_use,\n",
    "#                 render=False):\n",
    "#\n",
    "#     obs, info = env.reset(seed=int(rng.integers(0, 2**31-1)))\n",
    "#     u_nom = np.zeros(HORIZON, dtype=np.float64)\n",
    "#\n",
    "#     X_ep, Ydp_ep, Ydv_ep = [], [], []\n",
    "#     frames = []\n",
    "#\n",
    "#     std_dp_list = []\n",
    "#     std_dv_list = []\n",
    "#\n",
    "#     t_start = time.perf_counter()\n",
    "#     success = False\n",
    "#\n",
    "#     for t in range(MAX_STEPS):\n",
    "#         p, v = float(obs[0]), float(obs[1])\n",
    "#\n",
    "#         u, u_nom, avg_cost, min_cost = mppi_plan_action_uncertainty(\n",
    "#             pred_dp, pred_dv,\n",
    "#             state0=np.array([p, v], dtype=np.float64),\n",
    "#             u_nominal=u_nom,\n",
    "#             rng=rng,\n",
    "#             horizon=HORIZON,\n",
    "#             num_samples=NUM_SAMPLES,\n",
    "#             noise_sigma=NOISE_SIGMA,\n",
    "#             lam=LAM,\n",
    "#             u_smooth=U_SMOOTH,\n",
    "#             w_time=w_time_use,\n",
    "#             w_goal=w_goal_use,        # ✅ zero in Strategy A\n",
    "#             w_terminal=w_term_use,\n",
    "#             w_unc=(w_unc if do_explore else 0.0),\n",
    "#             unc_scale=UNC_SCALE,\n",
    "#             unc_every=UNC_EVERY\n",
    "#         )\n",
    "#\n",
    "#         obs2, reward, terminated, truncated, info = env.step(np.array([u], dtype=np.float64))\n",
    "#         p2, v2 = float(obs2[0]), float(obs2[1])\n",
    "#\n",
    "#         X_ep.append([p, v, float(u)])\n",
    "#         Ydp_ep.append([p2 - p])\n",
    "#         Ydv_ep.append([v2 - v])\n",
    "#\n",
    "#         if do_explore:\n",
    "#             _, sdp = pred_dp(np.array([[p, v, float(u)]], dtype=np.float64))\n",
    "#             _, sdv = pred_dv(np.array([[p, v, float(u)]], dtype=np.float64))\n",
    "#             std_dp_list.append(float(sdp[0]))\n",
    "#             std_dv_list.append(float(sdv[0]))\n",
    "#\n",
    "#         obs = obs2\n",
    "#\n",
    "#         if render and ((t % FRAME_STRIDE) == 0):\n",
    "#             frames.append(resize_frame(env.render(), RESIZE))\n",
    "#\n",
    "#         if p2 >= GOAL_POS:\n",
    "#             success = True\n",
    "#             break\n",
    "#         if terminated or truncated:\n",
    "#             break\n",
    "#\n",
    "#     wall_time = time.perf_counter() - t_start\n",
    "#\n",
    "#     X_ep   = np.asarray(X_ep, dtype=np.float64)\n",
    "#     ydp_ep = np.asarray(Ydp_ep, dtype=np.float64).reshape(-1, 1)\n",
    "#     ydv_ep = np.asarray(Ydv_ep, dtype=np.float64).reshape(-1, 1)\n",
    "#\n",
    "#     steps_taken = X_ep.shape[0]\n",
    "#     mean_sdp = float(np.mean(std_dp_list)) if len(std_dp_list) > 0 else None\n",
    "#     mean_sdv = float(np.mean(std_dv_list)) if len(std_dv_list) > 0 else None\n",
    "#\n",
    "#     return success, steps_taken, wall_time, X_ep, ydp_ep, ydv_ep, frames, mean_sdp, mean_sdv\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  MAIN TRAIN LOOP  ======================\n",
    "# # ============================================================\n",
    "#\n",
    "# needed = [\"X0\", \"Y0\", \"m_dp\", \"m_dv\", \"kernel_dp\", \"kernel_dv\"]\n",
    "# missing = [k for k in needed if k not in globals()]\n",
    "# if len(missing) > 0:\n",
    "#     raise NameError(f\"Missing required variables before Cell 12: {missing}. Run earlier cells first.\")\n",
    "#\n",
    "# # Build replay buffer and seed with initial random dataset\n",
    "# replay = ReplayBuffer(REPLAY_CAP, dim_x=3)\n",
    "# replay.add(\n",
    "#     X0,\n",
    "#     Y0[:, 0:1].astype(np.float64),\n",
    "#     Y0[:, 1:2].astype(np.float64)\n",
    "# )\n",
    "#\n",
    "# # Freeze kernels for stability\n",
    "# gpflow.set_trainable(m_dp.kernel, False)\n",
    "# gpflow.set_trainable(m_dv.kernel, False)\n",
    "# gpflow.set_trainable(m_dp.likelihood, True)\n",
    "# gpflow.set_trainable(m_dv.likelihood, True)\n",
    "# safe_set_min_noise(m_dp, MIN_NOISE_VAR)\n",
    "# safe_set_min_noise(m_dv, MIN_NOISE_VAR)\n",
    "#\n",
    "# train_logs = []\n",
    "# eval_logs  = []\n",
    "# eval_wall_hist = []\n",
    "# eval_steps_hist = []\n",
    "#\n",
    "# for ep in range(NUM_TRAIN_EPISODES):\n",
    "#     ep_seed = SEED + 1000 * ep if \"SEED\" in globals() else 1000 * ep\n",
    "#     rng = np.random.default_rng(ep_seed)\n",
    "#\n",
    "#     # rebuild cached predictors\n",
    "#     pred_dp = build_cached_predictor_osgpr(m_dp)\n",
    "#     pred_dv = build_cached_predictor_osgpr(m_dv)\n",
    "#\n",
    "#     # exploration schedule\n",
    "#     w_unc_ep = episode_unc_weight(ep)\n",
    "#     do_explore = (w_unc_ep > 1e-9)\n",
    "#\n",
    "#     # explore weights vs exploit weights\n",
    "#     if do_explore:\n",
    "#         w_time_use = EXPLORE_W_TIME\n",
    "#         w_goal_use = EXPLORE_W_GOAL\n",
    "#         w_term_use = EXPLORE_W_TERM\n",
    "#     else:\n",
    "#         w_time_use = W_TIME\n",
    "#         w_goal_use = W_GOAL\n",
    "#         w_term_use = W_TERMINAL\n",
    "#\n",
    "#     if PRINT_EVERY_EP:\n",
    "#         print(\"\\n\" + \"-\"*95)\n",
    "#         print(f\"[Train Episode {ep+1}/{NUM_TRAIN_EPISODES}] explore={do_explore} w_unc={w_unc_ep:.3f} \"\n",
    "#               f\"| (w_time={w_time_use:.2f}, w_goal={w_goal_use:.2f}, w_term={w_term_use:.1f})\")\n",
    "#\n",
    "#     # ----------------------------\n",
    "#     # TRAIN\n",
    "#     # ----------------------------\n",
    "#     env = make_env(render_mode=(\"rgb_array\" if RENDER_TRAIN else None), seed=ep_seed)\n",
    "#     success, steps_taken, wall_time, X_ep, ydp_ep, ydv_ep, frames, mean_sdp, mean_sdv = run_episode(\n",
    "#         env, rng, pred_dp, pred_dv,\n",
    "#         do_explore=do_explore, w_unc=w_unc_ep,\n",
    "#         w_time_use=w_time_use, w_goal_use=w_goal_use, w_term_use=w_term_use,\n",
    "#         render=RENDER_TRAIN\n",
    "#     )\n",
    "#     env.close()\n",
    "#\n",
    "#     msg = f\"  Train: {'SUCCESS ✅' if success else 'FAIL ❌'} | steps={steps_taken:4d}/{MAX_STEPS} | wall={wall_time:6.2f}s\"\n",
    "#     if do_explore and (mean_sdp is not None):\n",
    "#         msg += f\" | mean std(dp)={mean_sdp:.3e} std(dv)={mean_sdv:.3e}\"\n",
    "#     if PRINT_EVERY_EP:\n",
    "#         print(msg)\n",
    "#\n",
    "#     train_logs.append((ep+1, bool(success), int(steps_taken), float(wall_time)))\n",
    "#\n",
    "#     if RENDER_TRAIN:\n",
    "#         show_frames(frames, fps=FPS)\n",
    "#\n",
    "#     # Add episode to replay\n",
    "#     replay.add(X_ep, ydp_ep, ydv_ep)\n",
    "#\n",
    "#     # ----------------------------\n",
    "#     # UPDATE\n",
    "#     # ----------------------------\n",
    "#     Xb, ydpb, ydvb = replay.sample_mixed(BATCH_SIZE, recent_frac=RECENT_FRAC, rng=rng)\n",
    "#\n",
    "#     t0 = time.perf_counter()\n",
    "#     m_dp, m_dv, (t_dp, neg_dp, t_dv, neg_dv) = streaming_update_once(\n",
    "#         m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "#         Xb, ydpb, ydvb,\n",
    "#         M=M_INDUCING, train_iters=TRAIN_ITERS, lr=LR,\n",
    "#         rng=rng\n",
    "#     )\n",
    "#     upd_wall = time.perf_counter() - t0\n",
    "#\n",
    "#     safe_set_min_noise(m_dp, MIN_NOISE_VAR)\n",
    "#     safe_set_min_noise(m_dv, MIN_NOISE_VAR)\n",
    "#\n",
    "#     if PRINT_EVERY_EP:\n",
    "#         print(f\"  Update: dp_time={t_dp:6.2f}s negELBO={neg_dp:.3e} | dv_time={t_dv:6.2f}s negELBO={neg_dv:.3e} | total={upd_wall:6.2f}s\")\n",
    "#         print(f\"          replay={len(replay):6d}  batch={Xb.shape[0]:4d}  inducing={M_INDUCING:3d}\")\n",
    "#\n",
    "#     # ----------------------------\n",
    "#     # GP plots after update\n",
    "#     # ----------------------------\n",
    "#     do_plot = (PLOT_GP_EVERY_UPDATE and ((ep + 1) % max(1, PLOT_GP_EVERY_N_UPDATE) == 0))\n",
    "#     if do_plot:\n",
    "#         if PLOT_USE_REPLAY_DATA and len(replay) > 0:\n",
    "#             X_plot, ydp_plot, ydv_plot = sample_plot_data_from_replay(\n",
    "#                 replay, max_points=PLOT_MAX_POINTS, seed=PLOT_SEED + ep\n",
    "#             )\n",
    "#         else:\n",
    "#             X_plot = X0\n",
    "#             ydp_plot = Y0[:, 0]\n",
    "#             ydv_plot = Y0[:, 1]\n",
    "#\n",
    "#         print(f\"  Plot: GP eval after update @ ep {ep+1} (overlay n={len(X_plot)})\")\n",
    "#\n",
    "#         if (\"plot_slice_two_actions\" in globals()) and (\"plot_surface_mean_colored_by_std_interactive\" in globals()):\n",
    "#             plot_slice_two_actions(\n",
    "#                 m_dp, X_plot, ydp_plot,\n",
    "#                 title=f\"OSGPR-VFE slice after update {ep+1}: Δp (with inducing points)\",\n",
    "#                 y_label=\"Δp\",\n",
    "#                 v_fixed=SLICE_V_FIXED,\n",
    "#                 a_list=SLICE_ACTIONS,\n",
    "#                 n_grid=SLICE_N_GRID,\n",
    "#                 x_min=SLICE_P_MIN, x_max=SLICE_P_MAX,\n",
    "#                 y_min=SLICE_Y_MIN_DP, y_max=SLICE_Y_MAX_DP,\n",
    "#                 x_tick_step=SLICE_X_TICK,\n",
    "#                 y_tick_step=SLICE_Y_TICK_DP,\n",
    "#                 show_inducing=True,\n",
    "#                 inducing_tol_v=0.01,\n",
    "#                 inducing_tol_a=0.2\n",
    "#             )\n",
    "#\n",
    "#             plot_surface_mean_colored_by_std_interactive(\n",
    "#                 m_dv, X_plot, ydv_plot,\n",
    "#                 title=f\"OSGPR-VFE surface after update {ep+1}: Δv (with inducing points)\",\n",
    "#                 z_label=\"Δv\",\n",
    "#                 a_fixed=SURF_ACTION,\n",
    "#                 n_grid=SURF_N_GRID,\n",
    "#                 p_min=SURF_P_MIN, p_max=SURF_P_MAX,\n",
    "#                 v_min=SURF_V_MIN, v_max=SURF_V_MAX,\n",
    "#                 z_min=SURF_Z_MIN_DV, z_max=SURF_Z_MAX_DV,\n",
    "#                 std_min=0.0, std_max=None,\n",
    "#                 show_inducing=True,\n",
    "#                 inducing_tol_a=0.2\n",
    "#             )\n",
    "#         else:\n",
    "#             print(\"  [WARN] plot functions missing. Run Cell 10 first.\")\n",
    "#\n",
    "#     # ----------------------------\n",
    "#     # EVAL AFTER UPDATE\n",
    "#     # ----------------------------\n",
    "#     pred_dp_eval = build_cached_predictor_osgpr(m_dp)\n",
    "#     pred_dv_eval = build_cached_predictor_osgpr(m_dv)\n",
    "#\n",
    "#     env_eval = make_env(render_mode=(\"rgb_array\" if RENDER_EVAL else None), seed=ep_seed + 777)\n",
    "#     t_eval0 = time.perf_counter()\n",
    "#\n",
    "#     eval_success, eval_steps, eval_wall, X_ev, ydp_ev, ydv_ev, eval_frames, _, _ = run_episode(\n",
    "#         env_eval, rng, pred_dp_eval, pred_dv_eval,\n",
    "#         do_explore=False, w_unc=0.0,\n",
    "#         w_time_use=W_TIME, w_goal_use=W_GOAL, w_term_use=W_TERMINAL,\n",
    "#         render=RENDER_EVAL\n",
    "#     )\n",
    "#     eval_wall = time.perf_counter() - t_eval0\n",
    "#     env_eval.close()\n",
    "#\n",
    "#     eval_logs.append((ep+1, bool(eval_success), int(eval_steps), float(eval_wall)))\n",
    "#     eval_wall_hist.append(float(eval_wall))\n",
    "#     eval_steps_hist.append(int(eval_steps))\n",
    "#\n",
    "#     if PRINT_EVERY_EP:\n",
    "#         print(f\"  Eval : {'SUCCESS ✅' if eval_success else 'FAIL ❌'} | steps={eval_steps:4d}/{MAX_STEPS} | wall={eval_wall:6.2f}s\")\n",
    "#\n",
    "#     if RENDER_EVAL:\n",
    "#         show_frames(eval_frames, fps=FPS)\n",
    "#\n",
    "# # ============================================================\n",
    "# # =====================  SUMMARY + PLOTS  ======================\n",
    "# # ============================================================\n",
    "#\n",
    "# print(\"\\n\" + \"#\"*95)\n",
    "# print(\"TRAIN SUMMARY\")\n",
    "# print(\"#\"*95)\n",
    "#\n",
    "# for (ep_i, ok, steps, wt) in train_logs:\n",
    "#     print(f\"After Train Ep {ep_i:02d} | {'SUCCESS' if ok else 'FAIL':7s} | steps={steps:4d} | wall={wt:7.2f}s\")\n",
    "#\n",
    "# print(\"\\nEVAL-AFTER-UPDATE SUMMARY (no exploration)\")\n",
    "# for (ep_i, ok, steps, wt) in eval_logs:\n",
    "#     print(f\"Eval after update @ Train Ep {ep_i:02d} | {'SUCCESS' if ok else 'FAIL':7s} | steps={steps:4d} | wall={wt:7.2f}s\")\n",
    "#\n",
    "# xs = [x[0] for x in eval_logs]\n",
    "#\n",
    "# plt.figure(figsize=(9, 4))\n",
    "# plt.plot(xs, eval_wall_hist, marker=\"o\")\n",
    "# plt.xlabel(\"Training episode index\")\n",
    "# plt.ylabel(\"Eval wall time (sec)\")\n",
    "# plt.title(\"Eval runtime after each model update (no exploration)\")\n",
    "# plt.grid(True, alpha=0.25)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#\n",
    "# plt.figure(figsize=(9, 4))\n",
    "# plt.plot(xs, eval_steps_hist, marker=\"o\")\n",
    "# plt.xlabel(\"Training episode index\")\n",
    "# plt.ylabel(\"Eval timesteps taken\")\n",
    "# plt.title(\"Eval timesteps after each model update (no exploration)\")\n",
    "# plt.grid(True, alpha=0.25)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Online",
   "id": "6d21b50cbbfd2aa7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Cell 11 — MPPI planner (CACHED) + uncertainty bonus + time penalty\n",
    "#   + NEW: return first-step sampled action candidates U[:,0]\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow import covariances\n",
    "\n",
    "# MountainCar bounds/constants\n",
    "P_MIN, P_MAX = -1.2, 0.6\n",
    "V_MIN, V_MAX = -0.07, 0.07\n",
    "U_MIN, U_MAX = -1.0, 1.0\n",
    "GOAL_POS = 0.45\n",
    "\n",
    "\n",
    "def build_cached_predictor_osgpr(model):\n",
    "    \"\"\"\n",
    "    Returns fast callable:\n",
    "        mu, std = pred(Xnew_np)\n",
    "    Rebuild after streaming update (model changed).\n",
    "    \"\"\"\n",
    "    (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "     Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = model._common_terms()\n",
    "\n",
    "    inducing = model.inducing_variable\n",
    "    kernel = model.kernel\n",
    "    mean_function = model.mean_function\n",
    "\n",
    "    @tf.function\n",
    "    def _predict_tf(Xnew):\n",
    "        Kbs = covariances.Kuf(inducing, kernel, Xnew)  # (Mb,N)\n",
    "\n",
    "        # mean\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)  # (N,1)\n",
    "        mean = mean + mean_function(Xnew)\n",
    "\n",
    "        # diag var\n",
    "        var = (\n",
    "            kernel(Xnew, full_cov=False)\n",
    "            - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "            + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "        )\n",
    "        var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "        return mean, var\n",
    "\n",
    "    def predict_np(Xnew_np):\n",
    "        Xnew_tf = tf.convert_to_tensor(Xnew_np, dtype=gpflow.default_float())\n",
    "        mu_tf, var_tf = _predict_tf(Xnew_tf)\n",
    "        mu = mu_tf.numpy().reshape(-1)\n",
    "        var = var_tf.numpy().reshape(-1)\n",
    "        std = np.sqrt(np.maximum(var, 1e-12))\n",
    "        return mu, std\n",
    "\n",
    "    return predict_np\n",
    "\n",
    "\n",
    "def gp_step_batch_cached(pred_dp, pred_dv, states, actions, return_unc=False):\n",
    "    \"\"\"\n",
    "    states:  (K,2) [p,v]\n",
    "    actions: (K,)  u\n",
    "    \"\"\"\n",
    "    states = np.asarray(states, dtype=np.float64)\n",
    "    actions = np.asarray(actions, dtype=np.float64).reshape(-1)\n",
    "\n",
    "    X = np.column_stack([states[:, 0], states[:, 1], actions]).astype(np.float64)\n",
    "\n",
    "    mu_dp, std_dp = pred_dp(X)\n",
    "    mu_dv, std_dv = pred_dv(X)\n",
    "\n",
    "    p2 = np.clip(states[:, 0] + mu_dp, P_MIN, P_MAX)\n",
    "    v2 = np.clip(states[:, 1] + mu_dv, V_MIN, V_MAX)\n",
    "    next_states = np.stack([p2, v2], axis=1).astype(np.float64)\n",
    "\n",
    "    if return_unc:\n",
    "        unc = np.sqrt(std_dp**2 + std_dv**2).astype(np.float64)\n",
    "        return next_states, unc\n",
    "    return next_states\n",
    "\n",
    "\n",
    "# ✅ Strategy A friendly:\n",
    "# running cost can be time-only if w_goal=0\n",
    "def exploit_running_cost(states, w_time=1.0, w_goal=0.0):\n",
    "    p = states[:, 0]\n",
    "    goal_err = np.maximum(0.0, GOAL_POS - p)\n",
    "    return (w_time * np.ones_like(p) + w_goal * (goal_err**2)).astype(np.float64)\n",
    "\n",
    "def exploit_terminal_cost(states, w_terminal=250.0):\n",
    "    p = states[:, 0]\n",
    "    miss = np.maximum(0.0, GOAL_POS - p)\n",
    "    return (w_terminal * (miss**2)).astype(np.float64)\n",
    "\n",
    "\n",
    "def mppi_plan_action_uncertainty(\n",
    "    pred_dp, pred_dv,\n",
    "    state0,\n",
    "    u_nominal,\n",
    "    rng,\n",
    "    horizon=60,\n",
    "    num_samples=256,\n",
    "    noise_sigma=0.35,\n",
    "    lam=1.0,\n",
    "    u_smooth=0.65,\n",
    "    # exploit weights\n",
    "    w_time=1.0,\n",
    "    w_goal=0.0,\n",
    "    w_terminal=250.0,\n",
    "    # explore weights\n",
    "    w_unc=0.0,\n",
    "    unc_scale=0.002,\n",
    "    unc_every=5,\n",
    "    # NEW\n",
    "    return_u_candidates=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Total cost:\n",
    "      J = sum_t exploit_running_cost + terminal_cost  - w_unc * (unc / unc_scale)\n",
    "\n",
    "    return_u_candidates=True => also return u_candidates = U[:,0]\n",
    "    \"\"\"\n",
    "    state0 = np.asarray(state0, dtype=np.float64).reshape(2,)\n",
    "    H = int(horizon)\n",
    "    K = int(num_samples)\n",
    "\n",
    "    if u_nominal is None:\n",
    "        u_nominal = np.zeros(H, dtype=np.float64)\n",
    "    else:\n",
    "        u_nominal = np.asarray(u_nominal, dtype=np.float64).reshape(H,)\n",
    "\n",
    "    noise = rng.normal(0.0, noise_sigma, size=(K, H)).astype(np.float64)\n",
    "    U = np.clip(u_nominal[None, :] + noise, U_MIN, U_MAX)\n",
    "\n",
    "    states = np.repeat(state0[None, :], K, axis=0)\n",
    "    total_cost = np.zeros(K, dtype=np.float64)\n",
    "\n",
    "    for t in range(H):\n",
    "        a_t = U[:, t]\n",
    "\n",
    "        if (w_unc > 0.0) and (unc_every > 0) and ((t % unc_every) == 0):\n",
    "            states, unc = gp_step_batch_cached(pred_dp, pred_dv, states, a_t, return_unc=True)\n",
    "            total_cost += -w_unc * (unc / max(1e-12, unc_scale))\n",
    "        else:\n",
    "            states = gp_step_batch_cached(pred_dp, pred_dv, states, a_t, return_unc=False)\n",
    "\n",
    "        total_cost += exploit_running_cost(states, w_time=w_time, w_goal=w_goal)\n",
    "\n",
    "    total_cost += exploit_terminal_cost(states, w_terminal=w_terminal)\n",
    "\n",
    "    beta = np.min(total_cost)\n",
    "    w = np.exp(-(total_cost - beta) / max(1e-12, lam))\n",
    "    w = w / (np.sum(w) + 1e-12)\n",
    "\n",
    "    du = np.sum(w[:, None] * noise, axis=0)\n",
    "    u_new = np.clip(u_nominal + du, U_MIN, U_MAX)\n",
    "\n",
    "    u_nominal = u_smooth * u_nominal + (1.0 - u_smooth) * u_new\n",
    "    u0 = float(u_nominal[0])\n",
    "\n",
    "    u_nominal = np.roll(u_nominal, -1)\n",
    "    u_nominal[-1] = u_nominal[-2]\n",
    "\n",
    "    if return_u_candidates:\n",
    "        u_candidates = U[:, 0].copy()\n",
    "        return u0, u_nominal, float(np.mean(total_cost)), float(np.min(total_cost)), u_candidates\n",
    "\n",
    "    return u0, u_nominal, float(np.mean(total_cost)), float(np.min(total_cost))\n"
   ],
   "id": "691bcbab7916e78c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# Cell 12 — ONLINE-IN-EPISODE Streaming OSGPR-VFE + MPPI\n",
    "#   ✅ One continuous episode (online updates every few steps)\n",
    "#   ✅ Explore early -> Exploit later (within episode)\n",
    "#   ✅ Optional: evaluation AFTER EVERY GP UPDATE (model at that time)\n",
    "#   ✅ At end:\n",
    "#        - plot evaluation steps-vs-update\n",
    "#        - plot final 3D surfaces (Δp + Δv) once\n",
    "#\n",
    "# IMPORTANT:\n",
    "#   - We ONLY train on EXECUTED real transitions (labels from env)\n",
    "#   - MPPI candidates are used ONLY for inducing point selection Z (inputs-only)\n",
    "# ===========================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "import gpflow\n",
    "from gpflow.utilities import deepcopy as gp_deepcopy\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ===================== EASY TUNING KNOBS =====================\n",
    "# ============================================================\n",
    "\n",
    "# Episode\n",
    "MAX_STEPS = 800\n",
    "SEED = 0\n",
    "\n",
    "# MPPI\n",
    "HORIZON     = 60\n",
    "NUM_SAMPLES = 128\n",
    "NOISE_SIGMA = 0.35\n",
    "LAM         = 1.0\n",
    "U_SMOOTH    = 0.65\n",
    "\n",
    "# Online update frequency\n",
    "UPDATE_EVERY            = 10\n",
    "ONLINE_BATCH            = 512\n",
    "MIN_STEPS_BEFORE_UPDATE = 25\n",
    "\n",
    "# Streaming update settings\n",
    "M_INDUCING    = 48\n",
    "TRAIN_ITERS   = 80\n",
    "LR            = 0.005\n",
    "MIN_NOISE_VAR = 1e-4\n",
    "\n",
    "# Rendering (training episode)\n",
    "RENDER = True\n",
    "FRAME_STRIDE = 2\n",
    "RESIZE = (720, 450)\n",
    "FPS = 15\n",
    "\n",
    "# Explore -> Exploit schedule WITHIN episode\n",
    "EXPLORE_STEPS = 300\n",
    "UNC_W_START   = 18.0\n",
    "UNC_EVERY     = 5\n",
    "UNC_SCALE     = 0.002\n",
    "\n",
    "# Explore-mode exploit weights (weak)\n",
    "EXPLORE_W_TIME = 0.10\n",
    "EXPLORE_W_GOAL = 0.00\n",
    "EXPLORE_W_TERM = 120.0\n",
    "\n",
    "# Exploit-mode weights (Strategy A)\n",
    "W_TIME     = 1.0\n",
    "W_GOAL     = 0.0\n",
    "W_TERMINAL = 350.0\n",
    "\n",
    "# ============================================================\n",
    "# ✅ NEW FEATURE: Evaluate after each model update\n",
    "# ============================================================\n",
    "EVAL_EACH_UPDATE          = True    # ✅ turn on/off this whole feature\n",
    "EVAL_MAX_STEPS            = 800     # eval horizon in env steps (usually same as MAX_STEPS)\n",
    "EVAL_RENDER_EACH_UPDATE   = False   # WARNING: slow if True (will show many videos)\n",
    "EVAL_RENDER_LAST_ONLY     = True    # render only the LAST update's evaluation (recommended)\n",
    "\n",
    "# Plot evaluation curve at end\n",
    "PLOT_EVAL_CURVE_AT_END    = True\n",
    "\n",
    "# ============================================================\n",
    "# Optional: final 3D plots only ONCE at end\n",
    "# ============================================================\n",
    "PLOT_FINAL_3D_SURFACES = True     # uses plot_surface_mean_colored_by_std_interactive from Cell 10\n",
    "PLOT_MAX_POINTS        = 3500     # overlay data amount for the surface plots\n",
    "\n",
    "# 3D surface plot settings\n",
    "SURF_N_GRID   = 80\n",
    "SURF_P_MIN    = -1.2\n",
    "SURF_P_MAX    = 0.6\n",
    "SURF_V_MIN    = -0.07\n",
    "SURF_V_MAX    = 0.07\n",
    "SURF_A_FIXED  = +1.0\n",
    "\n",
    "# optional z ranges\n",
    "SURF_ZMIN_DP = None\n",
    "SURF_ZMAX_DP = None\n",
    "SURF_ZMIN_DV = -0.0035\n",
    "SURF_ZMAX_DV = +0.0035\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ===================== Small utils ===========================\n",
    "# ============================================================\n",
    "\n",
    "def resize_frame(frame, size=(720, 450)):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "    return np.array(img)\n",
    "\n",
    "def show_frames(frames, fps=15):\n",
    "    if len(frames) == 0:\n",
    "        return\n",
    "    fig = plt.figure(figsize=(RESIZE[0]/120, RESIZE[1]/120))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "    im = ax.imshow(frames[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return (im,)\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(frames),\n",
    "                                  interval=1000/fps, blit=True)\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "def unc_weight_by_step(t):\n",
    "    if t >= EXPLORE_STEPS:\n",
    "        return 0.0\n",
    "    s = t / max(1, EXPLORE_STEPS)\n",
    "    return float(UNC_W_START * (1.0 - s)**2)\n",
    "\n",
    "def safe_set_min_noise(model, min_var=1e-4):\n",
    "    try:\n",
    "        cur = float(model.likelihood.variance.numpy())\n",
    "        model.likelihood.variance.assign(np.maximum(min_var, cur))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ============ k-center inducing point selection ==============\n",
    "# ============================================================\n",
    "\n",
    "def kcenter_greedy(Xcand, M, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "    Xcand = np.asarray(Xcand, dtype=np.float64)\n",
    "    N, D = Xcand.shape\n",
    "    M = int(min(M, N))\n",
    "\n",
    "    start = int(rng.integers(0, N))\n",
    "    chosen = [start]\n",
    "    d2 = np.sum((Xcand - Xcand[start])**2, axis=1)\n",
    "\n",
    "    for _ in range(1, M):\n",
    "        j = int(np.argmax(d2))\n",
    "        chosen.append(j)\n",
    "        d2 = np.minimum(d2, np.sum((Xcand - Xcand[j])**2, axis=1))\n",
    "\n",
    "    return Xcand[np.array(chosen)]\n",
    "\n",
    "def choose_Z_kcenter(Z_old, X_exec_batch, X_mppi_cand=None, M=48, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    Z_old = np.asarray(Z_old, dtype=np.float64)\n",
    "    X_exec_batch = np.asarray(X_exec_batch, dtype=np.float64)\n",
    "\n",
    "    if X_mppi_cand is not None and len(X_mppi_cand) > 0:\n",
    "        X_mppi_cand = np.asarray(X_mppi_cand, dtype=np.float64)\n",
    "        Xcand = np.vstack([Z_old, X_exec_batch, X_mppi_cand])\n",
    "    else:\n",
    "        Xcand = np.vstack([Z_old, X_exec_batch])\n",
    "\n",
    "    return kcenter_greedy(Xcand, M=M, rng=rng)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# =============== Online streaming update wrapper =============\n",
    "# ============================================================\n",
    "\n",
    "def streaming_update_online(m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "                            X_batch, ydp_batch, ydv_batch,\n",
    "                            X_mppi_cand=None,\n",
    "                            M=48, train_iters=80, lr=0.005,\n",
    "                            rng=None):\n",
    "    \"\"\"\n",
    "    Requires your existing functions:\n",
    "      - extract_summary_from_model\n",
    "      - OSGPR_VFE\n",
    "      - train_osgpr\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    # --- dp ---\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dp)\n",
    "    Z_new = choose_Z_kcenter(Z_old, X_batch, X_mppi_cand=X_mppi_cand, M=M, rng=rng)\n",
    "\n",
    "    m_dp_new = OSGPR_VFE(\n",
    "        data=(X_batch, ydp_batch),\n",
    "        kernel=kernel_dp,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_new\n",
    "    )\n",
    "    m_dp_new.likelihood.variance.assign(np.maximum(MIN_NOISE_VAR, float(m_dp.likelihood.variance.numpy())))\n",
    "    gpflow.set_trainable(m_dp_new.kernel, False)\n",
    "    gpflow.set_trainable(m_dp_new.likelihood, True)\n",
    "    t_dp, neg_dp = train_osgpr(m_dp_new, iters=train_iters, lr=lr)\n",
    "\n",
    "    # --- dv ---\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dv)\n",
    "    Z_new = choose_Z_kcenter(Z_old, X_batch, X_mppi_cand=X_mppi_cand, M=M, rng=rng)\n",
    "\n",
    "    m_dv_new = OSGPR_VFE(\n",
    "        data=(X_batch, ydv_batch),\n",
    "        kernel=kernel_dv,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_new\n",
    "    )\n",
    "    m_dv_new.likelihood.variance.assign(np.maximum(MIN_NOISE_VAR, float(m_dv.likelihood.variance.numpy())))\n",
    "    gpflow.set_trainable(m_dv_new.kernel, False)\n",
    "    gpflow.set_trainable(m_dv_new.likelihood, True)\n",
    "    t_dv, neg_dv = train_osgpr(m_dv_new, iters=train_iters, lr=lr)\n",
    "\n",
    "    return m_dp_new, m_dv_new, (t_dp, neg_dp, t_dv, neg_dv)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ===================== Evaluation rollout ====================\n",
    "# ============================================================\n",
    "\n",
    "def run_eval_episode(env, rng, pred_dp, pred_dv,\n",
    "                     eval_max_steps=800,\n",
    "                     render=False,\n",
    "                     w_time=1.0, w_goal=0.0, w_term=350.0):\n",
    "    \"\"\"\n",
    "    Real evaluation:\n",
    "      - w_unc = 0 (no exploration)\n",
    "      - Strategy A exploit\n",
    "    \"\"\"\n",
    "    obs, info = env.reset(seed=int(rng.integers(0, 2**31-1)))\n",
    "    u_nom = np.zeros(HORIZON, dtype=np.float64)\n",
    "    frames = []\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    success = False\n",
    "\n",
    "    for t in range(eval_max_steps):\n",
    "        p, v = float(obs[0]), float(obs[1])\n",
    "\n",
    "        u, u_nom, avg_cost, min_cost = mppi_plan_action_uncertainty(\n",
    "            pred_dp, pred_dv,\n",
    "            state0=np.array([p, v], dtype=np.float64),\n",
    "            u_nominal=u_nom,\n",
    "            rng=rng,\n",
    "            horizon=HORIZON,\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            noise_sigma=NOISE_SIGMA,\n",
    "            lam=LAM,\n",
    "            u_smooth=U_SMOOTH,\n",
    "            w_time=w_time,\n",
    "            w_goal=w_goal,\n",
    "            w_terminal=w_term,\n",
    "            w_unc=0.0,\n",
    "            unc_scale=UNC_SCALE,\n",
    "            unc_every=UNC_EVERY,\n",
    "            return_u_candidates=False\n",
    "        )\n",
    "\n",
    "        obs2, reward, terminated, truncated, info = env.step(np.array([u], dtype=np.float64))\n",
    "        obs = obs2\n",
    "\n",
    "        if render and ((t % FRAME_STRIDE) == 0):\n",
    "            frames.append(resize_frame(env.render(), RESIZE))\n",
    "\n",
    "        if float(obs[0]) >= GOAL_POS:\n",
    "            success = True\n",
    "            break\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    wall = time.perf_counter() - t0\n",
    "    steps_used = t + 1\n",
    "    return success, steps_used, wall, frames\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ===================== RUN ONLINE TRAINING ===================\n",
    "# ============================================================\n",
    "\n",
    "needed = [\"m_dp\", \"m_dv\", \"kernel_dp\", \"kernel_dv\", \"make_env\"]\n",
    "missing = [k for k in needed if k not in globals()]\n",
    "if len(missing) > 0:\n",
    "    raise NameError(f\"Missing before Cell 12: {missing}\")\n",
    "\n",
    "if PLOT_FINAL_3D_SURFACES and (\"plot_surface_mean_colored_by_std_interactive\" not in globals()):\n",
    "    print(\"[WARN] plot_surface_mean_colored_by_std_interactive not found. Run Cell 10 if you want final 3D plots.\")\n",
    "    PLOT_FINAL_3D_SURFACES = False\n",
    "\n",
    "# cached predictors\n",
    "pred_dp = build_cached_predictor_osgpr(m_dp)\n",
    "pred_dv = build_cached_predictor_osgpr(m_dv)\n",
    "\n",
    "safe_set_min_noise(m_dp, MIN_NOISE_VAR)\n",
    "safe_set_min_noise(m_dv, MIN_NOISE_VAR)\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "env = make_env(render_mode=(\"rgb_array\" if RENDER else None), seed=SEED)\n",
    "obs, info = env.reset(seed=SEED)\n",
    "\n",
    "u_nom = np.zeros(HORIZON, dtype=np.float64)\n",
    "\n",
    "X_exec   = []\n",
    "Ydp_exec = []\n",
    "Ydv_exec = []\n",
    "\n",
    "frames = []\n",
    "update_count = 0\n",
    "hit_goal = False\n",
    "\n",
    "# ==========================\n",
    "# Eval records per update\n",
    "# ==========================\n",
    "eval_log = []  # list of dicts\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "\n",
    "print(\"\\n\" + \"=\"*95)\n",
    "print(\"ONLINE TRAINING START\")\n",
    "print(\"=\"*95)\n",
    "\n",
    "for t in range(MAX_STEPS):\n",
    "    p, v = float(obs[0]), float(obs[1])\n",
    "\n",
    "    # explore -> exploit schedule\n",
    "    w_unc_t = unc_weight_by_step(t)\n",
    "    do_explore = (w_unc_t > 1e-12)\n",
    "\n",
    "    if do_explore:\n",
    "        w_time_use = EXPLORE_W_TIME\n",
    "        w_goal_use = EXPLORE_W_GOAL\n",
    "        w_term_use = EXPLORE_W_TERM\n",
    "        phase = \"EXPLORE\"\n",
    "    else:\n",
    "        w_time_use = W_TIME\n",
    "        w_goal_use = W_GOAL\n",
    "        w_term_use = W_TERMINAL\n",
    "        phase = \"EXPLOIT\"\n",
    "\n",
    "    # MPPI plan (+ candidates for inducing coverage)\n",
    "    u, u_nom, avg_cost, min_cost, u_candidates = mppi_plan_action_uncertainty(\n",
    "        pred_dp, pred_dv,\n",
    "        state0=np.array([p, v], dtype=np.float64),\n",
    "        u_nominal=u_nom,\n",
    "        rng=rng,\n",
    "        horizon=HORIZON,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        noise_sigma=NOISE_SIGMA,\n",
    "        lam=LAM,\n",
    "        u_smooth=U_SMOOTH,\n",
    "        w_time=w_time_use,\n",
    "        w_goal=w_goal_use,\n",
    "        w_terminal=w_term_use,\n",
    "        w_unc=w_unc_t,\n",
    "        unc_scale=UNC_SCALE,\n",
    "        unc_every=UNC_EVERY,\n",
    "        return_u_candidates=True\n",
    "    )\n",
    "\n",
    "    # execute real step\n",
    "    obs2, reward, terminated, truncated, info = env.step(np.array([u], dtype=np.float64))\n",
    "    p2, v2 = float(obs2[0]), float(obs2[1])\n",
    "\n",
    "    # store executed labeled transition\n",
    "    X_exec.append([p, v, float(u)])\n",
    "    Ydp_exec.append([p2 - p])\n",
    "    Ydv_exec.append([v2 - v])\n",
    "\n",
    "    obs = obs2\n",
    "\n",
    "    if RENDER and ((t % FRAME_STRIDE) == 0):\n",
    "        frames.append(resize_frame(env.render(), RESIZE))\n",
    "\n",
    "    if (t % 25) == 0:\n",
    "        print(f\"[t={t:03d}] {phase:<7s} | p={p:+.3f} v={v:+.3f} u={u:+.2f} | w_unc={w_unc_t:.2f}\")\n",
    "\n",
    "    # stop if goal reached\n",
    "    if p2 >= GOAL_POS:\n",
    "        hit_goal = True\n",
    "        print(f\"\\n✅ TRAIN HIT GOAL at step {t+1} (phase={phase}) p={p2:+.3f}\")\n",
    "        break\n",
    "\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "    # ============================\n",
    "    # ONLINE STREAMING UPDATE\n",
    "    # ============================\n",
    "    if (t >= MIN_STEPS_BEFORE_UPDATE) and ((t + 1) % UPDATE_EVERY == 0):\n",
    "        X_arr   = np.asarray(X_exec, dtype=np.float64)\n",
    "        ydp_arr = np.asarray(Ydp_exec, dtype=np.float64).reshape(-1, 1)\n",
    "        ydv_arr = np.asarray(Ydv_exec, dtype=np.float64).reshape(-1, 1)\n",
    "\n",
    "        n = X_arr.shape[0]\n",
    "        n_batch = int(min(ONLINE_BATCH, n))\n",
    "        Xb   = X_arr[-n_batch:]\n",
    "        ydpb = ydp_arr[-n_batch:]\n",
    "        ydvb = ydv_arr[-n_batch:]\n",
    "\n",
    "        # better Xcand: mix recent states with sampled candidate actions\n",
    "        S_STATE = 32\n",
    "        S_ACT   = 96\n",
    "\n",
    "        S = min(S_STATE, n)\n",
    "        SV = X_arr[-S:, :2]\n",
    "        A  = u_candidates.astype(np.float64).reshape(-1)\n",
    "\n",
    "        if A.shape[0] > S_ACT:\n",
    "            idxA = rng.choice(A.shape[0], size=S_ACT, replace=False)\n",
    "            A = A[idxA]\n",
    "\n",
    "        idxS = rng.integers(0, SV.shape[0], size=A.shape[0])\n",
    "        Xcand = np.column_stack([SV[idxS, 0], SV[idxS, 1], A])\n",
    "\n",
    "        # update\n",
    "        t_up0 = time.perf_counter()\n",
    "        m_dp, m_dv, (t_dp, neg_dp, t_dv, neg_dv) = streaming_update_online(\n",
    "            m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "            Xb, ydpb, ydvb,\n",
    "            X_mppi_cand=Xcand,\n",
    "            M=M_INDUCING, train_iters=TRAIN_ITERS, lr=LR,\n",
    "            rng=rng\n",
    "        )\n",
    "        t_up = time.perf_counter() - t_up0\n",
    "        update_count += 1\n",
    "\n",
    "        safe_set_min_noise(m_dp, MIN_NOISE_VAR)\n",
    "        safe_set_min_noise(m_dv, MIN_NOISE_VAR)\n",
    "\n",
    "        # rebuild cached predictors\n",
    "        pred_dp = build_cached_predictor_osgpr(m_dp)\n",
    "        pred_dv = build_cached_predictor_osgpr(m_dv)\n",
    "\n",
    "        print(f\"  [UPDATE #{update_count:02d}] at step={t+1:04d} | last {n_batch} exec \"\n",
    "              f\"| dp {t_dp:.2f}s negELBO={neg_dp:.2e} | dv {t_dv:.2f}s negELBO={neg_dv:.2e} | total {t_up:.2f}s\")\n",
    "\n",
    "        # =====================================================\n",
    "        # ✅ NEW: EVALUATE THIS MODEL RIGHT NOW\n",
    "        # =====================================================\n",
    "        if EVAL_EACH_UPDATE:\n",
    "            # render logic\n",
    "            do_render = False\n",
    "            if EVAL_RENDER_EACH_UPDATE:\n",
    "                do_render = True\n",
    "            elif EVAL_RENDER_LAST_ONLY:\n",
    "                do_render = False  # set True later for last update (handled after loop)\n",
    "\n",
    "            # snapshot current model for evaluation stability\n",
    "            m_dp_snap = gp_deepcopy(m_dp)\n",
    "            m_dv_snap = gp_deepcopy(m_dv)\n",
    "\n",
    "            pred_dp_snap = build_cached_predictor_osgpr(m_dp_snap)\n",
    "            pred_dv_snap = build_cached_predictor_osgpr(m_dv_snap)\n",
    "\n",
    "            rng_eval = np.random.default_rng(SEED + 999 + update_count)\n",
    "            env_eval = make_env(render_mode=(\"rgb_array\" if do_render else None), seed=SEED + 999 + update_count)\n",
    "\n",
    "            ok, steps_used, wall_used, frames_eval = run_eval_episode(\n",
    "                env_eval, rng_eval, pred_dp_snap, pred_dv_snap,\n",
    "                eval_max_steps=EVAL_MAX_STEPS,\n",
    "                render=do_render,\n",
    "                w_time=W_TIME, w_goal=W_GOAL, w_term=W_TERMINAL\n",
    "            )\n",
    "            env_eval.close()\n",
    "\n",
    "            eval_log.append({\n",
    "                \"update\": update_count,\n",
    "                \"train_step\": int(t + 1),\n",
    "                \"success\": bool(ok),\n",
    "                \"eval_steps\": int(steps_used),\n",
    "                \"eval_wall\": float(wall_used),\n",
    "                \"neg_elbo_dp\": float(neg_dp),\n",
    "                \"neg_elbo_dv\": float(neg_dv),\n",
    "            })\n",
    "\n",
    "            print(f\"    [EVAL @ update #{update_count:02d}] {'SUCCESS ✅' if ok else 'FAIL ❌'} \"\n",
    "                  f\"| steps={steps_used}/{EVAL_MAX_STEPS} | wall={wall_used:.2f}s\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "train_wall = time.perf_counter() - t_start\n",
    "\n",
    "print(\"\\n\" + \"=\"*95)\n",
    "print(f\"ONLINE TRAIN DONE | hit_goal={hit_goal} | steps={t+1} | updates={update_count} | wall={train_wall:.2f}s\")\n",
    "print(\"=\"*95)\n",
    "\n",
    "if RENDER:\n",
    "    show_frames(frames, fps=FPS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ Plot: Eval steps vs time/update\n",
    "# ============================================================\n",
    "\n",
    "if EVAL_EACH_UPDATE and PLOT_EVAL_CURVE_AT_END and (len(eval_log) > 0):\n",
    "    steps_x = np.array([d[\"train_step\"] for d in eval_log], dtype=int)\n",
    "    steps_y = np.array([d[\"eval_steps\"] for d in eval_log], dtype=int)\n",
    "    succ    = np.array([d[\"success\"] for d in eval_log], dtype=bool)\n",
    "\n",
    "    plt.figure(figsize=(8.5, 4.8))\n",
    "    plt.plot(steps_x, steps_y, marker=\"o\", linewidth=2.0)\n",
    "    plt.xlabel(\"Training step where model was updated\")\n",
    "    plt.ylabel(\"Evaluation steps-to-goal (lower is better)\")\n",
    "    plt.title(\"Model improvement over updates (evaluation after each GP update)\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "\n",
    "    # mark failures\n",
    "    if np.any(~succ):\n",
    "        fx = steps_x[~succ]\n",
    "        fy = steps_y[~succ]\n",
    "        plt.scatter(fx, fy, marker=\"x\", s=80, linewidths=2.0, label=\"fail\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nEval Summary (after each update):\")\n",
    "    for d in eval_log:\n",
    "        print(f\"  upd={d['update']:02d} | train_step={d['train_step']:04d} | \"\n",
    "              f\"{'SUCCESS' if d['success'] else 'FAIL'} | eval_steps={d['eval_steps']:03d} | \"\n",
    "              f\"dp_negELBO={d['neg_elbo_dp']:.2e} dv_negELBO={d['neg_elbo_dv']:.2e}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ Render LAST UPDATE evaluation (recommended)\n",
    "# ============================================================\n",
    "\n",
    "if EVAL_EACH_UPDATE and EVAL_RENDER_LAST_ONLY and (len(eval_log) > 0):\n",
    "    last = eval_log[-1]\n",
    "    print(\"\\n\" + \"=\"*95)\n",
    "    print(f\"RENDER LAST UPDATE EVAL — update #{last['update']} at train_step {last['train_step']}\")\n",
    "    print(\"=\"*95)\n",
    "\n",
    "    # Use current final model (after training)\n",
    "    pred_dp_final = build_cached_predictor_osgpr(m_dp)\n",
    "    pred_dv_final = build_cached_predictor_osgpr(m_dv)\n",
    "\n",
    "    rng_eval = np.random.default_rng(SEED + 888)\n",
    "    env_eval = make_env(render_mode=\"rgb_array\", seed=SEED + 888)\n",
    "\n",
    "    ok, steps_used, wall_used, frames_eval = run_eval_episode(\n",
    "        env_eval, rng_eval, pred_dp_final, pred_dv_final,\n",
    "        eval_max_steps=EVAL_MAX_STEPS,\n",
    "        render=True,\n",
    "        w_time=W_TIME, w_goal=W_GOAL, w_term=W_TERMINAL\n",
    "    )\n",
    "    env_eval.close()\n",
    "\n",
    "    print(f\"Rendered Eval: {'SUCCESS ✅' if ok else 'FAIL ❌'} | steps={steps_used}/{EVAL_MAX_STEPS} | wall={wall_used:.2f}s\")\n",
    "    show_frames(frames_eval, fps=FPS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ✅ Final 3D surfaces (Δp + Δv) once\n",
    "# ============================================================\n",
    "\n",
    "if PLOT_FINAL_3D_SURFACES:\n",
    "    if \"plot_surface_mean_colored_by_std_interactive\" in globals():\n",
    "        Nplot = min(len(X_exec), PLOT_MAX_POINTS)\n",
    "        idxP = np.linspace(max(0, len(X_exec)-Nplot), len(X_exec)-1, Nplot).astype(int)\n",
    "\n",
    "        X_plot   = np.asarray(X_exec, dtype=np.float64)[idxP]\n",
    "        ydp_plot = np.asarray(Ydp_exec, dtype=np.float64).reshape(-1)[idxP]\n",
    "        ydv_plot = np.asarray(Ydv_exec, dtype=np.float64).reshape(-1)[idxP]\n",
    "\n",
    "        print(\"\\n\" + \"=\"*95)\n",
    "        print(f\"FINAL 3D SURFACES (overlay n={X_plot.shape[0]})\")\n",
    "        print(\"=\"*95)\n",
    "\n",
    "        plot_surface_mean_colored_by_std_interactive(\n",
    "            m_dp, X_plot, ydp_plot,\n",
    "            title=\"FINAL OSGPR-VFE surface: Δp\",\n",
    "            z_label=\"Δp\",\n",
    "            a_fixed=SURF_A_FIXED,\n",
    "            n_grid=SURF_N_GRID,\n",
    "            p_min=SURF_P_MIN, p_max=SURF_P_MAX,\n",
    "            v_min=SURF_V_MIN, v_max=SURF_V_MAX,\n",
    "            z_min=SURF_ZMIN_DP, z_max=SURF_ZMAX_DP,\n",
    "            std_min=0.0, std_max=None,\n",
    "            show_inducing=True,\n",
    "            inducing_tol_a=0.2\n",
    "        )\n",
    "\n",
    "        plot_surface_mean_colored_by_std_interactive(\n",
    "            m_dv, X_plot, ydv_plot,\n",
    "            title=\"FINAL OSGPR-VFE surface: Δv\",\n",
    "            z_label=\"Δv\",\n",
    "            a_fixed=SURF_A_FIXED,\n",
    "            n_grid=SURF_N_GRID,\n",
    "            p_min=SURF_P_MIN, p_max=SURF_P_MAX,\n",
    "            v_min=SURF_V_MIN, v_max=SURF_V_MAX,\n",
    "            z_min=SURF_ZMIN_DV, z_max=SURF_ZMAX_DV,\n",
    "            std_min=0.0, std_max=None,\n",
    "            show_inducing=True,\n",
    "            inducing_tol_a=0.2\n",
    "        )\n",
    "    else:\n",
    "        print(\"[WARN] plot_surface_mean_colored_by_std_interactive not found. Run Cell 10 first.\")\n"
   ],
   "id": "3447365ac02aa5f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eebb25ca5009c592",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
