{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3a4760e7552a24",
   "metadata": {},
   "source": [
    "Envrionment Setup for MountainCarContinuous-v0"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd00b4b3fa16b522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:21.475928Z",
     "start_time": "2026-01-15T16:02:21.471682Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs visible to TF:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Optional: show detailed GPU info\n",
    "for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(\" -\", g)\n",
    "\n",
    "# If this prints [] => you're on CPU only\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.20.0\n",
      "Built with CUDA: False\n",
      "GPUs visible to TF: []\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:22.460838Z",
     "start_time": "2026-01-15T16:02:22.457287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, platform\n",
    "print(sys.executable)\n",
    "print(platform.platform())\n"
   ],
   "id": "d6d25fbe84cc8d47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wts28\\anaconda3\\python.exe\n",
      "Windows-11-10.0.26200-SP0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e430adcade89f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:23.110752Z",
     "start_time": "2026-01-15T16:02:23.107110Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:23.546646Z",
     "start_time": "2026-01-15T16:02:23.498623Z"
    }
   },
   "source": [
    "# ============================\n",
    "# Cell 1 — Imports + Config\n",
    "# ============================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d790741e343106ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:25.305067Z",
     "start_time": "2026-01-15T16:02:25.294915Z"
    }
   },
   "source": [
    "# ============================\n",
    "# Cell 2 — Env Factory + Basics\n",
    "# ============================\n",
    "\n",
    "ENV_ID = \"MountainCarContinuous-v0\"\n",
    "\n",
    "def make_env(render_mode=None, seed=0):\n",
    "    \"\"\"\n",
    "    render_mode:\n",
    "      - None: fastest (training)\n",
    "      - \"rgb_array\": frames for notebook animation\n",
    "      - \"human\": pops up window (not great for notebook)\n",
    "    \"\"\"\n",
    "    env = gym.make(ENV_ID, render_mode=render_mode)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    return env\n",
    "\n",
    "# Quick sanity check\n",
    "env = make_env(render_mode=None, seed=SEED)\n",
    "obs, info = env.reset()\n",
    "print(\"obs:\", obs, \"shape:\", obs.shape)\n",
    "print(\"action_space:\", env.action_space)\n",
    "print(\"observation_space:\", env.observation_space)\n",
    "\n",
    "# Useful constants\n",
    "OBS_DIM = env.observation_space.shape[0]   # 2: [position, velocity]\n",
    "ACT_DIM = env.action_space.shape[0]        # 1: [force]\n",
    "ACTION_LOW  = env.action_space.low.copy()\n",
    "ACTION_HIGH = env.action_space.high.copy()\n",
    "\n",
    "# Gym's goal is typically around position ~ 0.45 (varies by implementation)\n",
    "GOAL_POS_DEFAULT = 0.45\n",
    "env.close()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: [-0.546  0.   ] shape: (2,)\n",
      "action_space: Box(-1.0, 1.0, (1,), float32)\n",
      "observation_space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "87f2b1b277bad586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:02:25.866756Z",
     "start_time": "2026-01-15T16:02:25.861183Z"
    }
   },
   "source": [
    "# ============================\n",
    "# Cell 3 — Notebook Render Utilities\n",
    "# ============================\n",
    "\n",
    "def resize_frame(frame, size=(640, 400)):\n",
    "    \"\"\"frame: HxWx3 uint8\"\"\"\n",
    "    if size is None:\n",
    "        return frame\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize(size, resample=Image.BILINEAR)\n",
    "    return np.asarray(img)\n",
    "\n",
    "def rollout_and_render(env, policy_fn, steps=600, seed=0,\n",
    "                       frame_stride=1, resize=(640, 400), fps=30):\n",
    "    \"\"\"\n",
    "    env must be created with render_mode=\"rgb_array\"\n",
    "    policy_fn(obs) -> action in [-1,1] shape (1,)\n",
    "    \"\"\"\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    frames = []\n",
    "    traj = []\n",
    "\n",
    "    for t in range(steps):\n",
    "        action = np.asarray(policy_fn(obs), dtype=np.float32).reshape(ACT_DIM,)\n",
    "        action = np.clip(action, ACTION_LOW, ACTION_HIGH)\n",
    "\n",
    "        obs2, reward, terminated, truncated, info = env.step(action)\n",
    "        traj.append((obs.copy(), action.copy(), reward, terminated, truncated))\n",
    "\n",
    "        if t % frame_stride == 0:\n",
    "            frame = env.render()\n",
    "            frame = resize_frame(frame, size=resize)\n",
    "            frames.append(frame)\n",
    "\n",
    "        obs = obs2\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    # ---- animate ----\n",
    "    fig = plt.figure(figsize=(resize[0]/100, resize[1]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames),\n",
    "        interval=1000 / fps, blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "    return traj\n",
    "\n",
    "def random_policy(obs):\n",
    "    # MountainCarContinuous expects 1D action in [-1,1]\n",
    "    return rng.uniform(low=-1.0, high=1.0, size=(1,))\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "57e6e3d4e4eae106",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 4 — Demo: Random Rollout (rendered)\n",
    "# ============================\n",
    "env_vis = make_env(render_mode=\"rgb_array\", seed=SEED)\n",
    "\n",
    "traj = rollout_and_render(\n",
    "    env_vis,\n",
    "    policy_fn=random_policy,\n",
    "    steps=600,\n",
    "    seed=SEED,\n",
    "    frame_stride=1,\n",
    "    resize=(720, 450),\n",
    "    fps=30\n",
    ")\n",
    "\n",
    "env_vis.close()\n",
    "\n",
    "# Print final state\n",
    "final_obs = traj[-1][0]\n",
    "print(\"Final obs:\", final_obs)\n",
    "print(\"Steps executed:\", len(traj))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "795adeef7d84a562",
   "metadata": {},
   "source": [
    "Initial Random data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41ccb8f9d26af7aa",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Render the RANDOM collection path (and collect X,Y)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_random_transitions_rendered(n_steps=500, seed=0,\n",
    "                                       frame_stride=1, resize=(720, 450), fps=30):\n",
    "    \"\"\"\n",
    "    Runs random actions, collects (X,Y), AND renders the rollout.\n",
    "    X = [p,v,u], Y = [dp,dv]\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    env_vis = make_env(render_mode=\"rgb_array\", seed=seed)\n",
    "    obs, info = env_vis.reset(seed=seed)\n",
    "\n",
    "    X_list, Y_list = [], []\n",
    "    traj_p, traj_v, traj_u = [], [], []\n",
    "    frames = []\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        u = rng.uniform(-1.0, 1.0, size=(1,)).astype(np.float64)\n",
    "        obs2, reward, terminated, truncated, info = env_vis.step(u)\n",
    "\n",
    "        p, v = obs\n",
    "        p2, v2 = obs2\n",
    "        dp = p2 - p\n",
    "        dv = v2 - v\n",
    "\n",
    "        X_list.append([p, v, float(u[0])])\n",
    "        Y_list.append([dp, dv])\n",
    "\n",
    "        traj_p.append(p)\n",
    "        traj_v.append(v)\n",
    "        traj_u.append(float(u[0]))\n",
    "\n",
    "        # render frame\n",
    "        if (t % frame_stride) == 0:\n",
    "            frame = env_vis.render()\n",
    "            frame = resize_frame(frame, size=resize)\n",
    "            frames.append(frame)\n",
    "\n",
    "        obs = obs2\n",
    "        if terminated or truncated:\n",
    "            obs, info = env_vis.reset(seed=seed + 123 + t)\n",
    "\n",
    "    env_vis.close()\n",
    "\n",
    "    X = np.asarray(X_list, dtype=np.float64)\n",
    "    Y = np.asarray(Y_list, dtype=np.float64)\n",
    "\n",
    "    # ---- show animation ----\n",
    "    fig = plt.figure(figsize=(resize[0]/100, resize[1]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    from matplotlib import animation\n",
    "    from IPython.display import HTML, display\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames),\n",
    "        interval=1000 / fps, blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "    # ---- show trajectory plots ----\n",
    "    traj_p = np.array(traj_p)\n",
    "    traj_v = np.array(traj_v)\n",
    "    traj_u = np.array(traj_u)\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.plot(traj_p, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"position p\")\n",
    "    plt.title(\"Random collection: position vs time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.plot(traj_v, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"velocity v\")\n",
    "    plt.title(\"Random collection: velocity vs time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.scatter(traj_p, traj_v, s=8, alpha=0.6)\n",
    "    plt.xlabel(\"position p\")\n",
    "    plt.ylabel(\"velocity v\")\n",
    "    plt.title(\"Random collection path in state space (p vs v)\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 3.5))\n",
    "    plt.plot(traj_u, linewidth=2)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"action u\")\n",
    "    plt.title(\"Random actions over time\")\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Collected X shape:\", X.shape, \" (p,v,u)\")\n",
    "    print(\"Collected Y shape:\", Y.shape, \" (dp,dv)\")\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# ---- run it ----\n",
    "X0, Y0 = collect_random_transitions_rendered(\n",
    "    n_steps=500,\n",
    "    seed=SEED,\n",
    "    frame_stride=1,\n",
    "    resize=(720, 450),\n",
    "    fps=30\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "922fcd49f885b6c3",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Cell 7 — GPflow Setup (float64)\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPflow:\", gpflow.__version__)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afa4cb7cf3a5b0d7",
   "metadata": {},
   "source": [
    "OSGPR-VFE\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "56d818f37c15baa4",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 8 — Streaming OSGPR (VFE) — paper-style regression update (D-dim input)\n",
    "#   Works for MountainCar input x=[p,v,u] (D=3)\n",
    "#   Single-output GP (we will train two models: dp and dv)\n",
    "# ===========================\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "from gpflow.models import GPModel, InternalDataTrainingLossMixin\n",
    "from gpflow import covariances\n",
    "\n",
    "# --- make numerics stable ---\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-6)\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# helpers\n",
    "# ---------------------------\n",
    "def sym_jitter(A, jitter=1e-6):\n",
    "    A = np.asarray(A, dtype=np.float64)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    A = A + jitter * np.eye(A.shape[0], dtype=np.float64)\n",
    "    return A\n",
    "\n",
    "def finite_mask(*arrs):\n",
    "    m = None\n",
    "    for a in arrs:\n",
    "        a = np.asarray(a)\n",
    "        mm = np.isfinite(a).all(axis=1) if a.ndim == 2 else np.isfinite(a)\n",
    "        m = mm if m is None else (m & mm)\n",
    "    return m\n",
    "\n",
    "def choose_inducing_keep_old(Z_old, X_new, M, keep_frac=0.8, rng=None):\n",
    "    \"\"\"\n",
    "    D-dimensional inducing management:\n",
    "      keep_frac of old inducing points + rest from current batch.\n",
    "    Z_old: (M_old, D)\n",
    "    X_new: (N_new, D)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "    Z_old = np.asarray(Z_old, dtype=np.float64)\n",
    "    X_new = np.asarray(X_new, dtype=np.float64)\n",
    "\n",
    "    assert Z_old.ndim == 2 and X_new.ndim == 2\n",
    "    D = Z_old.shape[1]\n",
    "    assert X_new.shape[1] == D, f\"Dim mismatch: Z_old D={D}, X_new D={X_new.shape[1]}\"\n",
    "\n",
    "    M_keep = int(np.round(M * keep_frac))\n",
    "    M_new  = M - M_keep\n",
    "    M_keep = min(M_keep, Z_old.shape[0])\n",
    "    M_new  = min(M_new,  X_new.shape[0])\n",
    "\n",
    "    old_idx = rng.choice(Z_old.shape[0], size=M_keep, replace=False) if M_keep > 0 else np.array([], dtype=int)\n",
    "    new_idx = rng.choice(X_new.shape[0], size=M_new,  replace=False) if M_new  > 0 else np.array([], dtype=int)\n",
    "\n",
    "    Z = np.vstack([Z_old[old_idx], X_new[new_idx]]).astype(np.float64)\n",
    "\n",
    "    if Z.shape[0] < M:\n",
    "        need = M - Z.shape[0]\n",
    "        extra = rng.choice(X_new.shape[0], size=need, replace=True)\n",
    "        Z = np.vstack([Z, X_new[extra]])\n",
    "    return Z\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# OSGPR-VFE model (paper’s online regression VFE update)\n",
    "# ============================================================\n",
    "class OSGPR_VFE(GPModel, InternalDataTrainingLossMixin):\n",
    "    \"\"\"\n",
    "    Online Sparse Variational GP Regression (VFE), regression-only.\n",
    "    Matches Streaming Sparse GP Approximations (Bui et al., NIPS 2017) VFE case.\n",
    "\n",
    "    NOTE: This is SINGLE-OUTPUT. Train two models for dp and dv.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, kernel, mu_old, Su_old, Kaa_old, Z_old, Z, mean_function=None):\n",
    "        X, Y = gpflow.models.util.data_input_to_tensor(data)\n",
    "        self.X, self.Y = X, Y\n",
    "        likelihood = gpflow.likelihoods.Gaussian()\n",
    "        num_latent_gps = GPModel.calc_num_latent_gps_from_data(data, kernel, likelihood)\n",
    "        super().__init__(kernel, likelihood, mean_function, num_latent_gps)\n",
    "\n",
    "        Z = np.asarray(Z, dtype=np.float64)\n",
    "        assert Z.ndim == 2, \"Z must be (M, D)\"\n",
    "        self.inducing_variable = InducingPoints(Z)\n",
    "        self.num_data = tf.shape(self.X)[0]\n",
    "\n",
    "        # old summary (fixed)\n",
    "        mu_old  = np.asarray(mu_old, dtype=np.float64).reshape(-1, 1)\n",
    "        Su_old  = sym_jitter(Su_old, 1e-6)\n",
    "        Kaa_old = sym_jitter(Kaa_old, 1e-6)\n",
    "        Z_old   = np.asarray(Z_old, dtype=np.float64)\n",
    "        assert Z_old.ndim == 2, \"Z_old must be (M_old, D)\"\n",
    "\n",
    "        self.mu_old  = tf.Variable(mu_old,  trainable=False, dtype=gpflow.default_float())\n",
    "        self.Su_old  = tf.Variable(Su_old,  trainable=False, dtype=gpflow.default_float())\n",
    "        self.Kaa_old = tf.Variable(Kaa_old, trainable=False, dtype=gpflow.default_float())\n",
    "        self.Z_old   = tf.Variable(Z_old,   trainable=False, dtype=gpflow.default_float())\n",
    "\n",
    "        if self.mean_function is None:\n",
    "            self.mean_function = gpflow.mean_functions.Zero()\n",
    "\n",
    "    def _common_terms(self):\n",
    "        Mb = self.inducing_variable.num_inducing\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        sigma2 = self.likelihood.variance\n",
    "\n",
    "        Saa = self.Su_old\n",
    "        ma  = self.mu_old\n",
    "\n",
    "        # Kbf, Kbb, Kba, Kaa (old)\n",
    "        Kbf = covariances.Kuf(self.inducing_variable, self.kernel, self.X)                # [Mb, N]\n",
    "        Kbb = covariances.Kuu(self.inducing_variable, self.kernel, jitter=jitter)         # [Mb, Mb]\n",
    "        Kba = covariances.Kuf(self.inducing_variable, self.kernel, self.Z_old)            # [Mb, Ma]\n",
    "\n",
    "        # current kernel at Z_old (optional mismatch correction term)\n",
    "        Kaa_cur = gpflow.utilities.add_noise_cov(self.kernel(self.Z_old), jitter)         # current kernel(Z_old,Z_old)\n",
    "        Kaa = gpflow.utilities.add_noise_cov(self.Kaa_old, jitter)                        # stored old kernel(Z_old,Z_old)\n",
    "\n",
    "        err = self.Y - self.mean_function(self.X)\n",
    "\n",
    "        # c = Kbf * (Y/sigma2) + Kba * (Saa^{-1} ma)\n",
    "        Sainv_ma = tf.linalg.solve(Saa, ma)\n",
    "        c1 = tf.matmul(Kbf, self.Y / sigma2)                                              # [Mb,1]\n",
    "        c2 = tf.matmul(Kba, Sainv_ma)                                                     # [Mb,1]\n",
    "        c  = c1 + c2\n",
    "\n",
    "        # Cholesky(Kbb)\n",
    "        Lb = tf.linalg.cholesky(Kbb)\n",
    "        Lbinv_c   = tf.linalg.triangular_solve(Lb, c, lower=True)\n",
    "        Lbinv_Kba = tf.linalg.triangular_solve(Lb, Kba, lower=True)\n",
    "        Lbinv_Kbf = tf.linalg.triangular_solve(Lb, Kbf, lower=True) / tf.sqrt(sigma2)\n",
    "\n",
    "        d1 = tf.matmul(Lbinv_Kbf, Lbinv_Kbf, transpose_b=True)                            # [Mb,Mb]\n",
    "\n",
    "        # d2 = (LSa^{-1} Kab Lb^{-1})^T (LSa^{-1} Kab Lb^{-1})\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        Kab_Lbinv = tf.linalg.matrix_transpose(Lbinv_Kba)                                 # [Ma,Mb]\n",
    "        LSainv_Kab_Lbinv = tf.linalg.triangular_solve(LSa, Kab_Lbinv, lower=True)\n",
    "        d2 = tf.matmul(LSainv_Kab_Lbinv, LSainv_Kab_Lbinv, transpose_a=True)\n",
    "\n",
    "        # d3 = (La^{-1} Kab Lb^{-1})^T (La^{-1} Kab Lb^{-1})\n",
    "        La = tf.linalg.cholesky(Kaa)\n",
    "        Lainv_Kab_Lbinv = tf.linalg.triangular_solve(La, Kab_Lbinv, lower=True)\n",
    "        d3 = tf.matmul(Lainv_Kab_Lbinv, Lainv_Kab_Lbinv, transpose_a=True)\n",
    "\n",
    "        # D = I + d1 + d2 - d3\n",
    "        D = tf.eye(Mb, dtype=gpflow.default_float()) + d1 + d2 - d3\n",
    "        D = gpflow.utilities.add_noise_cov(D, jitter)\n",
    "        LD = tf.linalg.cholesky(D)\n",
    "\n",
    "        LDinv_Lbinv_c = tf.linalg.triangular_solve(LD, Lbinv_c, lower=True)\n",
    "\n",
    "        # Qff_diag term for trace: diag(Kfb Kbb^{-1} Kbf) / sigma2\n",
    "        Qff_diag = tf.reduce_sum(tf.square(Lbinv_Kbf), axis=0)                             # [N]\n",
    "\n",
    "        return (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "                Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag)\n",
    "\n",
    "    def maximum_log_likelihood_objective(self):\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "        sigma2 = self.likelihood.variance\n",
    "        N = tf.cast(self.num_data, gpflow.default_float())\n",
    "\n",
    "        Saa = self.Su_old\n",
    "        ma  = self.mu_old\n",
    "\n",
    "        # diag(Kff)\n",
    "        Kfdiag = self.kernel(self.X, full_cov=False)\n",
    "\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        # ma term\n",
    "        LSa = tf.linalg.cholesky(Saa)\n",
    "        Lainv_ma = tf.linalg.triangular_solve(LSa, ma, lower=True)\n",
    "\n",
    "        # bound terms (matches reference implementation structure)\n",
    "        bound = -0.5 * N * np.log(2.0 * np.pi)\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(err)) / sigma2\n",
    "        bound += -0.5 * tf.reduce_sum(tf.square(Lainv_ma))\n",
    "        bound +=  0.5 * tf.reduce_sum(tf.square(LDinv_Lbinv_c))\n",
    "\n",
    "        bound += -0.5 * N * tf.math.log(sigma2)\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LD)))\n",
    "\n",
    "        # trace-like term: -0.5/sigma2 tr(Kff - Qff)\n",
    "        bound += -0.5 * tf.reduce_sum(Kfdiag) / sigma2\n",
    "        bound +=  0.5 * tf.reduce_sum(Qff_diag)  # already has /sigma2 inside\n",
    "\n",
    "        # delta_a terms (old/new inducing mismatch)\n",
    "        bound += tf.reduce_sum(tf.math.log(tf.linalg.diag_part(La)))\n",
    "        bound += -tf.reduce_sum(tf.math.log(tf.linalg.diag_part(LSa)))\n",
    "\n",
    "        # Kaadiff = Kaa_cur - Kab Kbb^{-1} Kba\n",
    "        Kaadiff = Kaa_cur - tf.matmul(Lbinv_Kba, Lbinv_Kba, transpose_a=True)\n",
    "        Sainv_Kaadiff = tf.linalg.solve(Saa, Kaadiff)\n",
    "        Kainv_Kaadiff = tf.linalg.solve(Kaa, Kaadiff)\n",
    "\n",
    "        bound += -0.5 * tf.reduce_sum(\n",
    "            tf.linalg.diag_part(Sainv_Kaadiff) - tf.linalg.diag_part(Kainv_Kaadiff)\n",
    "        )\n",
    "        return bound\n",
    "\n",
    "    def predict_f(self, Xnew, full_cov=False):\n",
    "        jitter = gpflow.utilities.to_default_float(1e-6)\n",
    "\n",
    "        Kbs = covariances.Kuf(self.inducing_variable, self.kernel, Xnew)\n",
    "        (Kbf, Kba, Kaa, Kaa_cur, La, Kbb, Lb, D, LD,\n",
    "         Lbinv_Kba, LDinv_Lbinv_c, err, Qff_diag) = self._common_terms()\n",
    "\n",
    "        Lbinv_Kbs = tf.linalg.triangular_solve(Lb, Kbs, lower=True)\n",
    "        LDinv_Lbinv_Kbs = tf.linalg.triangular_solve(LD, Lbinv_Kbs, lower=True)\n",
    "        mean = tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_c, transpose_a=True)\n",
    "\n",
    "        if full_cov:\n",
    "            Kss = self.kernel(Xnew) + jitter * tf.eye(tf.shape(Xnew)[0], dtype=gpflow.default_float())\n",
    "            var = (\n",
    "                Kss\n",
    "                - tf.matmul(Lbinv_Kbs, Lbinv_Kbs, transpose_a=True)\n",
    "                + tf.matmul(LDinv_Lbinv_Kbs, LDinv_Lbinv_Kbs, transpose_a=True)\n",
    "            )\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "        else:\n",
    "            var = (\n",
    "                self.kernel(Xnew, full_cov=False)\n",
    "                - tf.reduce_sum(tf.square(Lbinv_Kbs), axis=0)\n",
    "                + tf.reduce_sum(tf.square(LDinv_Lbinv_Kbs), axis=0)\n",
    "            )\n",
    "            var = tf.maximum(var, tf.cast(1e-12, var.dtype))\n",
    "            return mean + self.mean_function(Xnew), var\n",
    "\n",
    "\n",
    "def train_osgpr(model, iters=250, lr=0.01):\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    @tf.function\n",
    "    def step():\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -model.maximum_log_likelihood_objective()\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients([(g, v) for g, v in zip(grads, model.trainable_variables) if g is not None])\n",
    "        return loss\n",
    "\n",
    "    t0 = time.time()\n",
    "    last = None\n",
    "    for _ in range(iters):\n",
    "        last = step()\n",
    "    dt = time.time() - t0\n",
    "    return dt, float(last.numpy())\n",
    "\n",
    "\n",
    "def prior_summary(kernel, Z):\n",
    "    Z = np.asarray(Z, dtype=np.float64)\n",
    "    Kzz = kernel.K(Z).numpy()\n",
    "    Kzz = sym_jitter(Kzz, 1e-6)\n",
    "    mu0 = np.zeros((Z.shape[0], 1), dtype=np.float64)\n",
    "    return mu0, Kzz, Kzz, Z\n",
    "\n",
    "\n",
    "def extract_summary_from_model(model):\n",
    "    Z = model.inducing_variable.Z.numpy()\n",
    "\n",
    "    mu_tf, Sigma_tf = model.predict_f(Z, full_cov=True)  # u = f(Z)\n",
    "    mu = mu_tf.numpy()\n",
    "\n",
    "    Sigma = Sigma_tf.numpy()\n",
    "    if Sigma.ndim == 3:\n",
    "        Sigma = Sigma[0]\n",
    "    Sigma = sym_jitter(Sigma, 1e-6)\n",
    "\n",
    "    Kaa = model.kernel.K(Z).numpy()\n",
    "    Kaa = sym_jitter(Kaa, 1e-6)\n",
    "\n",
    "    return mu, Sigma, Kaa, Z\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d67176c12e7c7fe",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 9 — Train initial streaming OSGPR-VFE GPs for dp and dv\n",
    "# ===========================\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# targets\n",
    "y_dp = Y0[:, 0:1].astype(np.float64)\n",
    "y_dv = Y0[:, 1:2].astype(np.float64)\n",
    "\n",
    "# inducing size\n",
    "M = 64\n",
    "idxZ = rng.choice(X0.shape[0], size=min(M, X0.shape[0]), replace=False)\n",
    "Z0 = X0[idxZ].copy()\n",
    "\n",
    "# kernels (3D input: p,v,u)\n",
    "kernel_dp = gpflow.kernels.SquaredExponential(lengthscales=[0.5, 0.2, 0.5], variance=1.0)\n",
    "kernel_dv = gpflow.kernels.SquaredExponential(lengthscales=[0.5, 0.2, 0.5], variance=1.0)\n",
    "\n",
    "# ===== dp model =====\n",
    "mu_old, Su_old, Kaa_old, Z_old = prior_summary(kernel_dp, Z0)\n",
    "m_dp = OSGPR_VFE(\n",
    "    data=(X0, y_dp),\n",
    "    kernel=kernel_dp,\n",
    "    mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "    Z=Z0\n",
    ")\n",
    "m_dp.likelihood.variance.assign(1e-4)\n",
    "\n",
    "print(\"Training dp model...\")\n",
    "t_dp, neg_dp = train_osgpr(m_dp, iters=300, lr=0.02)\n",
    "sum_dp = extract_summary_from_model(m_dp)\n",
    "print(f\"dp done | train={t_dp:.3f}s | neg_obj={neg_dp:.4f}\")\n",
    "\n",
    "# ===== dv model =====\n",
    "mu_old, Su_old, Kaa_old, Z_old = prior_summary(kernel_dv, Z0)\n",
    "m_dv = OSGPR_VFE(\n",
    "    data=(X0, y_dv),\n",
    "    kernel=kernel_dv,\n",
    "    mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "    Z=Z0\n",
    ")\n",
    "m_dv.likelihood.variance.assign(1e-4)\n",
    "\n",
    "print(\"\\nTraining dv model...\")\n",
    "t_dv, neg_dv = train_osgpr(m_dv, iters=300, lr=0.02)\n",
    "sum_dv = extract_summary_from_model(m_dv)\n",
    "print(f\"dv done | train={t_dv:.3f}s | neg_obj={neg_dv:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c23dab0388182a94",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# GP Visualization (FULL axis control)\n",
    "#   - Slice: v fixed, plot u=+1 and u=-1 together\n",
    "#   - 3D Surface: z = mean, color = std\n",
    "# Controls you can set per plot:\n",
    "#   - x_min, x_max\n",
    "#   - y_min, y_max\n",
    "#   - x_tick_step, y_tick_step\n",
    "#   - (3D) z_min, z_max\n",
    "#   - (3D) std_min, std_max (colorbar range)\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# MountainCar default bounds\n",
    "MC_P_MIN, MC_P_MAX = -1.2, 0.6\n",
    "MC_V_MIN, MC_V_MAX = -0.07, 0.07\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction helper\n",
    "# ----------------------------\n",
    "def gp_predict_mu_std(model, X):\n",
    "    \"\"\"X: (N,3) -> mu (N,), std (N,)\"\"\"\n",
    "    mu_tf, var_tf = model.predict_f(X, full_cov=False)\n",
    "    mu = mu_tf.numpy().reshape(-1)\n",
    "    var = var_tf.numpy().reshape(-1)\n",
    "    std = np.sqrt(np.maximum(var, 1e-12))\n",
    "    return mu, std\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Slice plot with FULL axis control\n",
    "# ============================================================\n",
    "def plot_slice_two_actions(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    title=\"Slice\",\n",
    "    y_label=\"Δy\",\n",
    "    v_fixed=0.0,\n",
    "    a_list=(+1.0, -1.0),\n",
    "    n_grid=280,\n",
    "    # ---- axis controls ----\n",
    "    x_min=MC_P_MIN, x_max=MC_P_MAX,\n",
    "    y_min=None, y_max=None,\n",
    "    x_tick_step=None,\n",
    "    y_tick_step=None,\n",
    "    # ---- data overlay controls ----\n",
    "    data_tol_v=0.01,\n",
    "    data_tol_a=0.2,\n",
    "    show_data=True,\n",
    "    show_minmax=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Slice along position p for fixed (v=u-fixed), plot two actions on same axes.\n",
    "    You can manually control x/y limits and tick units.\n",
    "    \"\"\"\n",
    "\n",
    "    p_grid = np.linspace(x_min, x_max, n_grid)\n",
    "\n",
    "    # compute all action curves first\n",
    "    curves = []\n",
    "    auto_ymin = +np.inf\n",
    "    auto_ymax = -np.inf\n",
    "\n",
    "    for a_fixed in a_list:\n",
    "        X_query = np.column_stack([\n",
    "            p_grid,\n",
    "            np.full_like(p_grid, v_fixed),\n",
    "            np.full_like(p_grid, a_fixed),\n",
    "        ]).astype(np.float64)\n",
    "\n",
    "        mu, std = gp_predict_mu_std(model, X_query)\n",
    "        lo = mu - 2 * std\n",
    "        hi = mu + 2 * std\n",
    "\n",
    "        curves.append((a_fixed, mu, std, lo, hi))\n",
    "\n",
    "        auto_ymin = min(auto_ymin, float(np.min(lo)))\n",
    "        auto_ymax = max(auto_ymax, float(np.max(hi)))\n",
    "\n",
    "    # auto y if not specified\n",
    "    if y_min is None:\n",
    "        y_min = auto_ymin\n",
    "    if y_max is None:\n",
    "        y_max = auto_ymax\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    for a_fixed, mu, std, lo, hi in curves:\n",
    "        plt.plot(p_grid, mu, lw=2.5, label=f\"mean (u={a_fixed:+.1f})\")\n",
    "        plt.fill_between(p_grid, lo, hi, alpha=0.18, label=f\"±2σ (u={a_fixed:+.1f})\")\n",
    "\n",
    "        # overlay training data near this slice\n",
    "        if show_data:\n",
    "            mask = (np.abs(X_train[:, 1] - v_fixed) < data_tol_v) & (np.abs(X_train[:, 2] - a_fixed) < data_tol_a)\n",
    "            if np.sum(mask) > 0:\n",
    "                plt.scatter(\n",
    "                    X_train[mask, 0], y_train[mask],\n",
    "                    s=22, alpha=0.65,\n",
    "                    label=f\"data (v≈{v_fixed:.2f}, u≈{a_fixed:+.1f}, n={np.sum(mask)})\"\n",
    "                )\n",
    "\n",
    "    # axis settings\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel(\"Position p\")\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    # ticks/grid units\n",
    "    ax = plt.gca()\n",
    "    if x_tick_step is not None:\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(float(x_tick_step)))\n",
    "    if y_tick_step is not None:\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(float(y_tick_step)))\n",
    "\n",
    "    plt.grid(True, alpha=0.25)\n",
    "\n",
    "    # min/max display\n",
    "    if show_minmax:\n",
    "        # summarize from all curves\n",
    "        mu_all = np.concatenate([c[1] for c in curves])\n",
    "        std_all = np.concatenate([c[2] for c in curves])\n",
    "        lo_all = np.concatenate([c[3] for c in curves])\n",
    "        hi_all = np.concatenate([c[4] for c in curves])\n",
    "\n",
    "        extra = (f\"\\nmean[min,max]=({mu_all.min():+.3e},{mu_all.max():+.3e})\"\n",
    "                 f\"  std[min,max]=({std_all.min():+.3e},{std_all.max():+.3e})\"\n",
    "                 f\"  band[min,max]=({lo_all.min():+.3e},{hi_all.max():+.3e})\")\n",
    "        plt.title(title + extra)\n",
    "    else:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) 3D Surface plot with FULL axis control\n",
    "#     - z = mean\n",
    "#     - color = std\n",
    "# ============================================================\n",
    "def plot_surface_mean_colored_by_std(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    title=\"3D Surface\",\n",
    "    z_label=\"Δy\",\n",
    "    a_fixed=-1.0,\n",
    "    n_grid=80,\n",
    "    # ---- axis controls ----\n",
    "    p_min=MC_P_MIN, p_max=MC_P_MAX,\n",
    "    v_min=MC_V_MIN, v_max=MC_V_MAX,\n",
    "    z_min=None, z_max=None,\n",
    "    # ---- std colorbar controls ----\n",
    "    std_min=None, std_max=None,\n",
    "    # ---- overlay controls ----\n",
    "    show_data=True,\n",
    "    data_tol_a=0.2,\n",
    "    show_minmax=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    3D plot: height=mean, facecolor=std (uncertainty).\n",
    "    Full manual control of p/v bounds, z bounds, and std color range.\n",
    "    \"\"\"\n",
    "    p_grid = np.linspace(p_min, p_max, n_grid)\n",
    "    v_grid = np.linspace(v_min, v_max, n_grid)\n",
    "    P, V = np.meshgrid(p_grid, v_grid)\n",
    "\n",
    "    X_grid = np.column_stack([\n",
    "        P.ravel(),\n",
    "        V.ravel(),\n",
    "        np.full_like(P.ravel(), a_fixed)\n",
    "    ]).astype(np.float64)\n",
    "\n",
    "    mu, std = gp_predict_mu_std(model, X_grid)\n",
    "    Mean = mu.reshape(P.shape)\n",
    "    Std  = std.reshape(P.shape)\n",
    "\n",
    "    # z limits\n",
    "    if z_min is None:\n",
    "        z_min = float(np.min(Mean))\n",
    "    if z_max is None:\n",
    "        z_max = float(np.max(Mean))\n",
    "\n",
    "    # std color range\n",
    "    if std_min is None:\n",
    "        std_min = float(np.min(Std))\n",
    "    if std_max is None:\n",
    "        std_max = float(np.max(Std))\n",
    "\n",
    "    norm = plt.Normalize(vmin=std_min, vmax=std_max)\n",
    "    colors = plt.cm.viridis(norm(Std))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    ax.plot_surface(\n",
    "        P, V, Mean,\n",
    "        facecolors=colors,\n",
    "        linewidth=0,\n",
    "        antialiased=False,\n",
    "        shade=False\n",
    "    )\n",
    "\n",
    "    # colorbar = std\n",
    "    m = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "    m.set_array(Std)\n",
    "    cbar = fig.colorbar(m, ax=ax, shrink=0.65, aspect=12)\n",
    "    cbar.set_label(\"GP Predictive Std (uncertainty)\")\n",
    "\n",
    "    # overlay training points near this action\n",
    "    if show_data:\n",
    "        act = X_train[:, 2]\n",
    "        mask = np.abs(act - a_fixed) < data_tol_a\n",
    "        if np.sum(mask) > 0:\n",
    "            ax.scatter(\n",
    "                X_train[mask, 0], X_train[mask, 1], y_train[mask],\n",
    "                color=\"k\", s=10, alpha=0.55, label=f\"train (u≈{a_fixed:+.1f})\"\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(p_min, p_max)\n",
    "    ax.set_ylim(v_min, v_max)\n",
    "    ax.set_zlim(z_min, z_max)\n",
    "\n",
    "    ax.set_xlabel(\"Position p\")\n",
    "    ax.set_ylabel(\"Velocity v\")\n",
    "    ax.set_zlabel(z_label)\n",
    "\n",
    "    if show_minmax:\n",
    "        extra = (f\"\\nmean[min,max]=({Mean.min():+.3e},{Mean.max():+.3e})\"\n",
    "                 f\"  std[min,max]=({Std.min():+.3e},{Std.max():+.3e})\")\n",
    "        ax.set_title(f\"{title} | u={a_fixed:+.1f}\" + extra)\n",
    "    else:\n",
    "        ax.set_title(f\"{title} | u={a_fixed:+.1f}\")\n",
    "\n",
    "    ax.view_init(elev=30, azim=230)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Example usage (YOU can change these numbers easily)\n",
    "# ============================================================\n",
    "\n",
    "# ---- Δp slice plot ----\n",
    "plot_slice_two_actions(\n",
    "    m_dp, X0, Y0[:, 0],\n",
    "    title=\"OSGPR-VFE slice: Δp\",\n",
    "    y_label=\"Δp\",\n",
    "    v_fixed=0.0,\n",
    "    a_list=(+1.0, -1.0),\n",
    "    n_grid=280,\n",
    "    x_min=-1.2, x_max=0.6,\n",
    "    y_min=-0.012, y_max=0.012,\n",
    "    x_tick_step=0.1,\n",
    "    y_tick_step=0.005\n",
    ")\n",
    "\n",
    "# # ---- Δv slice plot ----\n",
    "# plot_slice_two_actions(\n",
    "#     m_dv, X0, Y0[:, 1],\n",
    "#     title=\"OSGPR-VFE slice: Δv\",\n",
    "#     y_label=\"Δv\",\n",
    "#     v_fixed=0.0,\n",
    "#     a_list=(+1.0, -1.0),\n",
    "#     n_grid=280,\n",
    "#     x_min=-1.2, x_max=0.6,\n",
    "#     y_min=-0.015, y_max=0.015,\n",
    "#     x_tick_step=0.2,\n",
    "#     y_tick_step=0.001\n",
    "# )\n",
    "\n",
    "# ---- 3D surface Δv (u = -1) ----\n",
    "# plot_surface_mean_colored_by_std(\n",
    "#     m_dv, X0, Y0[:, 1],\n",
    "#     title=\"OSGPR-VFE surface: Δv\",\n",
    "#     z_label=\"Δv\",\n",
    "#     a_fixed=-1.0,\n",
    "#     n_grid=80,\n",
    "#     p_min=-1.2, p_max=0.6,\n",
    "#     v_min=-0.07, v_max=0.07,\n",
    "#     z_min=-0.0035, z_max=0.0035,\n",
    "#     std_min=0.0, std_max=None\n",
    "# )\n",
    "\n",
    "# ---- 3D surface Δv (u = +1) ----\n",
    "plot_surface_mean_colored_by_std(\n",
    "    m_dv, X0, Y0[:, 1],\n",
    "    title=\"OSGPR-VFE surface: Δv\",\n",
    "    z_label=\"Δv\",\n",
    "    a_fixed=+1.0,\n",
    "    n_grid=80,\n",
    "    p_min=-1.2, p_max=0.6,\n",
    "    v_min=-0.07, v_max=0.07,\n",
    "    z_min=-0.0035, z_max=0.0035,\n",
    "    std_min=0.0, std_max=None\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "745feae25e8c7846",
   "metadata": {},
   "source": [
    "MPPI\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "647dc81f21f89222",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 10 — MPPI planner using GP dynamics (m_dp, m_dv)\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# MountainCarContinuous bounds\n",
    "P_MIN, P_MAX = -1.2, 0.6\n",
    "V_MIN, V_MAX = -0.07, 0.07\n",
    "U_MIN, U_MAX = -1.0, 1.0\n",
    "GOAL_POS = 0.45   # goal position (typical for MountainCarContinuous)\n",
    "\n",
    "def gp_predict_mu(model, X):\n",
    "    \"\"\"Return mean only: X (N,3) -> mu (N,)\"\"\"\n",
    "    mu_tf, _ = model.predict_f(X, full_cov=False)\n",
    "    return mu_tf.numpy().reshape(-1)\n",
    "\n",
    "def gp_step_batch(m_dp, m_dv, states, actions):\n",
    "    \"\"\"\n",
    "    GP dynamics one-step:\n",
    "      state: [p,v]\n",
    "      input: [p,v,u] -> predict dp,dv\n",
    "      next = [p+dp, v+dv] (clipped)\n",
    "    states:  (K,2)\n",
    "    actions: (K,)\n",
    "    \"\"\"\n",
    "    states = np.asarray(states, dtype=np.float64)\n",
    "    actions = np.asarray(actions, dtype=np.float64).reshape(-1)\n",
    "    K = states.shape[0]\n",
    "\n",
    "    X = np.column_stack([states[:, 0], states[:, 1], actions]).astype(np.float64)\n",
    "\n",
    "    dp = gp_predict_mu(m_dp, X)\n",
    "    dv = gp_predict_mu(m_dv, X)\n",
    "\n",
    "    p2 = states[:, 0] + dp\n",
    "    v2 = states[:, 1] + dv\n",
    "\n",
    "    p2 = np.clip(p2, P_MIN, P_MAX)\n",
    "    v2 = np.clip(v2, V_MIN, V_MAX)\n",
    "    return np.stack([p2, v2], axis=1).astype(np.float64)\n",
    "\n",
    "def running_cost(states, actions,\n",
    "                 w_goal=25.0, w_vel=0.05, w_u=0.02):\n",
    "    \"\"\"\n",
    "    Cost to minimize (lower is better)\n",
    "    Goal: reach GOAL_POS as fast as possible.\n",
    "    \"\"\"\n",
    "    p = states[:, 0]\n",
    "    v = states[:, 1]\n",
    "    u = actions.reshape(-1)\n",
    "\n",
    "    goal_err = np.maximum(0.0, GOAL_POS - p)     # only penalize below goal\n",
    "    return (w_goal * goal_err**2 + w_vel * (v**2) + w_u * (u**2)).astype(np.float64)\n",
    "\n",
    "def terminal_cost(states, w_terminal=250.0):\n",
    "    p = states[:, 0]\n",
    "    goal_err = np.maximum(0.0, GOAL_POS - p)\n",
    "    return (w_terminal * goal_err**2).astype(np.float64)\n",
    "\n",
    "def mppi_plan_action(\n",
    "    m_dp, m_dv,\n",
    "    state0,\n",
    "    u_nominal,\n",
    "    rng,\n",
    "    horizon=30,\n",
    "    num_samples=512,\n",
    "    noise_sigma=0.35,\n",
    "    lam=1.0,\n",
    "    u_smooth=0.65,\n",
    "):\n",
    "    \"\"\"\n",
    "    MPPI with receding horizon:\n",
    "      - sample actions around u_nominal\n",
    "      - roll out with GP dynamics\n",
    "      - update u_nominal using exp(-cost/lam)\n",
    "    Returns:\n",
    "      u0 (float), updated u_nominal (H,)\n",
    "    \"\"\"\n",
    "    state0 = np.asarray(state0, dtype=np.float64).reshape(2,)\n",
    "    H = int(horizon)\n",
    "    K = int(num_samples)\n",
    "\n",
    "    if u_nominal is None:\n",
    "        u_nominal = np.zeros(H, dtype=np.float64)\n",
    "    else:\n",
    "        u_nominal = np.asarray(u_nominal, dtype=np.float64).reshape(H,)\n",
    "\n",
    "    # sample noise\n",
    "    noise = rng.normal(loc=0.0, scale=noise_sigma, size=(K, H)).astype(np.float64)\n",
    "    U = u_nominal[None, :] + noise\n",
    "    U = np.clip(U, U_MIN, U_MAX)\n",
    "\n",
    "    # rollout\n",
    "    states = np.repeat(state0[None, :], K, axis=0)  # (K,2)\n",
    "    total_cost = np.zeros(K, dtype=np.float64)\n",
    "\n",
    "    for t in range(H):\n",
    "        a_t = U[:, t]\n",
    "        states = gp_step_batch(m_dp, m_dv, states, a_t)\n",
    "        total_cost += running_cost(states, a_t)\n",
    "\n",
    "    total_cost += terminal_cost(states)\n",
    "\n",
    "    # weights\n",
    "    beta = np.min(total_cost)\n",
    "    w = np.exp(-(total_cost - beta) / max(1e-9, lam))\n",
    "    w = w / (np.sum(w) + 1e-12)\n",
    "\n",
    "    # MPPI update: u_new = u_nom + Σ w_k * noise_k\n",
    "    du = np.sum(w[:, None] * noise, axis=0)\n",
    "    u_new = u_nominal + du\n",
    "    u_new = np.clip(u_new, U_MIN, U_MAX)\n",
    "\n",
    "    # smooth for stability\n",
    "    u_nominal = u_smooth * u_nominal + (1.0 - u_smooth) * u_new\n",
    "\n",
    "    # receding horizon: take first action\n",
    "    u0 = float(u_nominal[0])\n",
    "\n",
    "    # shift nominal sequence (warm start next step)\n",
    "    u_nominal = np.roll(u_nominal, -1)\n",
    "    u_nominal[-1] = u_nominal[-2]\n",
    "\n",
    "    return u0, u_nominal, float(np.mean(total_cost)), float(np.min(total_cost))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d34b9d2eba090a66",
   "metadata": {},
   "source": [
    "# ===========================\n",
    "# Cell 12 — Episodic MPPI + Streaming OSGPR-VFE\n",
    "#   Each episode:\n",
    "#     - MPPI rollout until success OR max steps\n",
    "#     - record wall-clock time + steps + success/fail\n",
    "#     - SAVE ALL transitions of that episode as batch\n",
    "#     - ONE streaming update using ONLY this batch (no replay buffer)\n",
    "#     - render episode + show 2 plots:\n",
    "#         (1) Δp slice plot (u=+1/-1)\n",
    "#         (2) Δv surface plot (u=+1, mean height, std color)\n",
    "# ===========================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "# ----------------------------\n",
    "# Controls (you can change)\n",
    "# ----------------------------\n",
    "NUM_EPISODES = 10\n",
    "MAX_STEPS    = 500\n",
    "\n",
    "# render settings\n",
    "RENDER = True\n",
    "FRAME_STRIDE = 1\n",
    "RESIZE = (720, 450)\n",
    "FPS = 30\n",
    "\n",
    "# MPPI params\n",
    "HORIZON     = 35\n",
    "NUM_SAMPLES = 256\n",
    "NOISE_SIGMA = 0.35\n",
    "LAM         = 1.0\n",
    "U_SMOOTH    = 0.65\n",
    "\n",
    "# streaming update params (ONE update per episode)\n",
    "M_INDUCING  = 32\n",
    "KEEP_FRAC   = 0.8\n",
    "TRAIN_ITERS = 100\n",
    "LR          = 0.02\n",
    "\n",
    "# MountainCar bounds/constants\n",
    "P_MIN, P_MAX = -1.2, 0.6\n",
    "V_MIN, V_MAX = -0.07, 0.07\n",
    "U_MIN, U_MAX = -1.0, 1.0\n",
    "GOAL_POS = 0.45\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Render helpers\n",
    "# ----------------------------\n",
    "def resize_frame(frame, size=(720, 450)):\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize(size, resample=Image.BILINEAR)\n",
    "    return np.asarray(img)\n",
    "\n",
    "def show_frames(frames, fps=30):\n",
    "    if len(frames) == 0:\n",
    "        print(\"[Render] No frames to display.\")\n",
    "        return\n",
    "\n",
    "    fig = plt.figure(figsize=(frames[0].shape[1]/100, frames[0].shape[0]/100), dpi=100)\n",
    "    plt.axis(\"off\")\n",
    "    im = plt.imshow(frames[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(frames[i])\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(frames), interval=1000/fps, blit=True)\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Inducing update helper (3D input)\n",
    "# ----------------------------\n",
    "def choose_inducing_keep_old_nd(Z_old, X_new, M, keep_frac=0.8, rng=None):\n",
    "    \"\"\"\n",
    "    Z_old: (M_old, D), X_new: (N, D)  -> Z: (M, D)\n",
    "    Keep some old inducing, add some new batch points.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    Z_old = np.asarray(Z_old, dtype=np.float64)\n",
    "    X_new = np.asarray(X_new, dtype=np.float64)\n",
    "\n",
    "    M_keep = int(np.round(M * keep_frac))\n",
    "    M_new  = M - M_keep\n",
    "\n",
    "    M_keep = min(M_keep, Z_old.shape[0])\n",
    "    M_new  = min(M_new,  X_new.shape[0])\n",
    "\n",
    "    old_idx = rng.choice(Z_old.shape[0], size=M_keep, replace=False) if M_keep > 0 else np.array([], dtype=int)\n",
    "    new_idx = rng.choice(X_new.shape[0], size=M_new,  replace=False) if M_new  > 0 else np.array([], dtype=int)\n",
    "\n",
    "    Z = np.vstack([Z_old[old_idx], X_new[new_idx]]).astype(np.float64)\n",
    "\n",
    "    if Z.shape[0] < M:\n",
    "        need = M - Z.shape[0]\n",
    "        extra = rng.choice(X_new.shape[0], size=need, replace=True)\n",
    "        Z = np.vstack([Z, X_new[extra]]).astype(np.float64)\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# ONE streaming update using ONLY the new episode batch\n",
    "# ----------------------------\n",
    "def streaming_update_once(m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "                          X_batch, ydp_batch, ydv_batch,\n",
    "                          M=64, keep_frac=0.8, train_iters=250, lr=0.02,\n",
    "                          rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    # ===== dp update =====\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dp)\n",
    "    Z_new = choose_inducing_keep_old_nd(Z_old, X_batch, M=M, keep_frac=keep_frac, rng=rng)\n",
    "\n",
    "    m_dp_new = OSGPR_VFE(\n",
    "        data=(X_batch, ydp_batch),\n",
    "        kernel=kernel_dp,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_new\n",
    "    )\n",
    "    m_dp_new.likelihood.variance.assign(np.maximum(1e-8, float(m_dp.likelihood.variance.numpy())))\n",
    "    t_dp, neg_dp = train_osgpr(m_dp_new, iters=train_iters, lr=lr)\n",
    "\n",
    "    # ===== dv update =====\n",
    "    mu_old, Su_old, Kaa_old, Z_old = extract_summary_from_model(m_dv)\n",
    "    Z_new = choose_inducing_keep_old_nd(Z_old, X_batch, M=M, keep_frac=keep_frac, rng=rng)\n",
    "\n",
    "    m_dv_new = OSGPR_VFE(\n",
    "        data=(X_batch, ydv_batch),\n",
    "        kernel=kernel_dv,\n",
    "        mu_old=mu_old, Su_old=Su_old, Kaa_old=Kaa_old, Z_old=Z_old,\n",
    "        Z=Z_new\n",
    "    )\n",
    "    m_dv_new.likelihood.variance.assign(np.maximum(1e-8, float(m_dv.likelihood.variance.numpy())))\n",
    "    t_dv, neg_dv = train_osgpr(m_dv_new, iters=train_iters, lr=lr)\n",
    "\n",
    "    return m_dp_new, m_dv_new, (t_dp, neg_dp, t_dv, neg_dv)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main episodic loop\n",
    "# ----------------------------\n",
    "episode_logs = []\n",
    "\n",
    "rng_master = np.random.default_rng(SEED)\n",
    "\n",
    "for ep in range(NUM_EPISODES):\n",
    "    ep_seed = SEED + 1000 * ep\n",
    "    rng = np.random.default_rng(ep_seed)\n",
    "\n",
    "    env = make_env(render_mode=\"rgb_array\" if RENDER else None, seed=ep_seed)\n",
    "    obs, info = env.reset(seed=ep_seed)\n",
    "\n",
    "    # MPPI warm start\n",
    "    u_nom = np.zeros(HORIZON, dtype=np.float64)\n",
    "\n",
    "    # Episode buffers (SAVE ALL transitions)\n",
    "    X_ep  = []\n",
    "    Ydp_ep = []\n",
    "    Ydv_ep = []\n",
    "\n",
    "    # Render frames\n",
    "    frames = []\n",
    "\n",
    "    start_t = time.perf_counter()\n",
    "\n",
    "    success = False\n",
    "    steps_taken = 0\n",
    "\n",
    "    for t in range(MAX_STEPS):\n",
    "        p, v = float(obs[0]), float(obs[1])\n",
    "\n",
    "        # MPPI plan (uses GP model dynamics)\n",
    "        u, u_nom, avg_cost, min_cost = mppi_plan_action(\n",
    "            m_dp, m_dv,\n",
    "            state0=np.array([p, v], dtype=np.float64),\n",
    "            u_nominal=u_nom,\n",
    "            rng=rng,\n",
    "            horizon=HORIZON,\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            noise_sigma=NOISE_SIGMA,\n",
    "            lam=LAM,\n",
    "            u_smooth=U_SMOOTH,\n",
    "        )\n",
    "\n",
    "        # step real env\n",
    "        obs2, reward, terminated, truncated, info = env.step(np.array([u], dtype=np.float64))\n",
    "        p2, v2 = float(obs2[0]), float(obs2[1])\n",
    "\n",
    "        dp = p2 - p\n",
    "        dv = v2 - v\n",
    "\n",
    "        # ✅ SAVE ALL transitions from episode\n",
    "        X_ep.append([p, v, float(u)])\n",
    "        Ydp_ep.append([dp])\n",
    "        Ydv_ep.append([dv])\n",
    "\n",
    "        obs = obs2\n",
    "        steps_taken = t + 1\n",
    "\n",
    "        # render\n",
    "        if RENDER and ((t % FRAME_STRIDE) == 0):\n",
    "            frame = env.render()\n",
    "            frame = resize_frame(frame, RESIZE)\n",
    "            frames.append(frame)\n",
    "\n",
    "        # success check\n",
    "        if p2 >= GOAL_POS:\n",
    "            success = True\n",
    "            break\n",
    "\n",
    "        # reset if environment terminates/truncates early\n",
    "        if terminated or truncated:\n",
    "            obs, info = env.reset(seed=ep_seed + 777 + t)\n",
    "            u_nom[:] = 0.0\n",
    "\n",
    "    end_t = time.perf_counter()\n",
    "    wall_time = end_t - start_t\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # Convert episode batch to numpy\n",
    "    X_ep = np.asarray(X_ep, dtype=np.float64)          # (N,3)\n",
    "    ydp_ep = np.asarray(Ydp_ep, dtype=np.float64)      # (N,1)\n",
    "    ydv_ep = np.asarray(Ydv_ep, dtype=np.float64)      # (N,1)\n",
    "\n",
    "    # Print episode summary\n",
    "    status = \"SUCCESS ✅\" if success else \"FAIL ❌\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"[Episode {ep+1}/{NUM_EPISODES}] {status}\")\n",
    "    print(f\"  steps_taken = {steps_taken} / {MAX_STEPS}\")\n",
    "    print(f\"  wall_time   = {wall_time:.3f} sec\")\n",
    "    print(f\"  batch_size  = {X_ep.shape[0]} transitions  (ALL episode samples)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ✅ ONE streaming update using ONLY this batch\n",
    "    t0_upd = time.perf_counter()\n",
    "    m_dp, m_dv, stats = streaming_update_once(\n",
    "        m_dp, m_dv, kernel_dp, kernel_dv,\n",
    "        X_ep, ydp_ep, ydv_ep,\n",
    "        M=M_INDUCING, keep_frac=KEEP_FRAC,\n",
    "        train_iters=TRAIN_ITERS, lr=LR,\n",
    "        rng=rng\n",
    "    )\n",
    "    t_upd = time.perf_counter() - t0_upd\n",
    "    t_dp, neg_dp, t_dv, neg_dv = stats\n",
    "\n",
    "    print(f\"[Streaming Update] total={t_upd:.3f}s | \"\n",
    "          f\"dp(train={t_dp:.3f}s, neg={neg_dp:.4f}) | \"\n",
    "          f\"dv(train={t_dv:.3f}s, neg={neg_dv:.4f})\")\n",
    "\n",
    "    # ===== Render the episode =====\n",
    "    if RENDER:\n",
    "        print(\"[Render] Episode playback:\")\n",
    "        show_frames(frames, fps=FPS)\n",
    "\n",
    "    # ===== Your 2 evaluation plots (use CURRENT episode data for overlay) =====\n",
    "    # Δp slice plot (exactly your settings)\n",
    "    plot_slice_two_actions(\n",
    "        m_dp, X_ep, ydp_ep.reshape(-1),\n",
    "        title=\"OSGPR-VFE slice: Δp\",\n",
    "        y_label=\"Δp\",\n",
    "        v_fixed=0.0,\n",
    "        a_list=(+1.0, -1.0),\n",
    "        n_grid=280,\n",
    "        x_min=-1.2, x_max=0.6,\n",
    "        y_min=-0.012, y_max=0.012,\n",
    "        x_tick_step=0.1,\n",
    "        y_tick_step=0.005\n",
    "    )\n",
    "\n",
    "    # Δv surface plot (exactly your settings)\n",
    "    plot_surface_mean_colored_by_std(\n",
    "        m_dv, X_ep, ydv_ep.reshape(-1),\n",
    "        title=\"OSGPR-VFE surface: Δv\",\n",
    "        z_label=\"Δv\",\n",
    "        a_fixed=+1.0,\n",
    "        n_grid=80,\n",
    "        p_min=-1.2, p_max=0.6,\n",
    "        v_min=-0.07, v_max=0.07,\n",
    "        z_min=-0.0035, z_max=0.0035,\n",
    "        std_min=0.0, std_max=None\n",
    "    )\n",
    "\n",
    "    # log it\n",
    "    episode_logs.append({\n",
    "        \"episode\": ep + 1,\n",
    "        \"success\": bool(success),\n",
    "        \"steps\": int(steps_taken),\n",
    "        \"wall_time_s\": float(wall_time),\n",
    "        \"batch_size\": int(X_ep.shape[0]),\n",
    "        \"update_time_s\": float(t_upd),\n",
    "        \"dp_train_s\": float(t_dp),\n",
    "        \"dv_train_s\": float(t_dv),\n",
    "        \"dp_negobj\": float(neg_dp),\n",
    "        \"dv_negobj\": float(neg_dv),\n",
    "    })\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# Summary table at the end\n",
    "# ===========================\n",
    "print(\"\\n\" + \"#\"*90)\n",
    "print(\"EPISODE SUMMARY\")\n",
    "print(\"#\"*90)\n",
    "for row in episode_logs:\n",
    "    status = \"SUCCESS\" if row[\"success\"] else \"FAIL\"\n",
    "    print(f\"Ep {row['episode']:02d} | {status:7s} | steps={row['steps']:4d} | \"\n",
    "          f\"wall={row['wall_time_s']:.2f}s | batch={row['batch_size']:4d} | upd={row['update_time_s']:.2f}s\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45861cca6bab1f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
