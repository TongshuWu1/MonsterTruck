{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f776de",
   "metadata": {},
   "source": [
    "# MANUAL DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4748723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:56:49.471202Z",
     "start_time": "2025-11-19T15:56:49.189221Z"
    }
   },
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # <--- THIS IS THE FIX\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d6d8320d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T17:07:19.319165Z",
     "start_time": "2025-11-19T17:05:19.259853Z"
    }
   },
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import mujoco as mj\n",
    "import mujoco.viewer as viewer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt # <--- Added for offline filtering\n",
    "\n",
    "# --- GUI Backend Setup ---\n",
    "try:\n",
    "    matplotlib.use('TkAgg')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "class Config:\n",
    "    XML_PATH   = \"monstertruck.xml\"\n",
    "    DURATION   = 100.0\n",
    "    CTRL_DT    = 0.1\n",
    "    REFRESH_HZ = 10\n",
    "    RTF        = 1.0\n",
    "\n",
    "    # --- BINNING SETTINGS ---\n",
    "    N_BINS_PHI   = 50\n",
    "    N_BINS_OMEGA = 50\n",
    "    MAX_SAMPLES  = 40\n",
    "    OMEGA_RANGE  = 5.0\n",
    "\n",
    "# ==========================================\n",
    "# 2. MATH & HELPERS\n",
    "# ==========================================\n",
    "class MathUtils:\n",
    "    @staticmethod\n",
    "    def get_flip_pitch(qw, qx, qy, qz):\n",
    "        r22 = 1 - 2 * (qx * qx + qy * qy)\n",
    "        r02 = 2 * (qx * qz + qw * qy)\n",
    "        return math.atan2(r02, -r22)\n",
    "\n",
    "    @staticmethod\n",
    "    def angdiff(a, b):\n",
    "        return ((a - b + math.pi) % (2.0 * math.pi)) - math.pi\n",
    "\n",
    "def lowpass_offline(acc, dt, cutoff_hz=5.0, order=2):\n",
    "    \"\"\"\n",
    "    Applies Zero-Phase filtering (forward + backward).\n",
    "    No time delay! Perfect for training data.\n",
    "    \"\"\"\n",
    "    acc = np.asarray(acc, dtype=float)\n",
    "    if len(acc) < 10: return acc # Safety check\n",
    "\n",
    "    fs = 1.0 / dt\n",
    "    wn = cutoff_hz / (fs / 2.0)\n",
    "    wn = min(max(wn, 1e-6), 0.999999)\n",
    "\n",
    "    b, a = butter(order, wn, btype='low')\n",
    "    acc_filt = filtfilt(b, a, acc)\n",
    "    return acc_filt\n",
    "\n",
    "# ==========================================\n",
    "# 3. VISUALIZATION (Live = Raw)\n",
    "# ==========================================\n",
    "class LivePlotter:\n",
    "    def __init__(self):\n",
    "        plt.ion()\n",
    "        self.fig, (self.ax1, self.ax2, self.ax3, self.ax4) = plt.subplots(4, 1, figsize=(8, 10), sharex=True)\n",
    "        self.fig.canvas.manager.set_window_title(\"Collecting Raw Data...\")\n",
    "\n",
    "        self.line_pitch, = self.ax1.plot([], [], lw=2, c='blue')\n",
    "        self.line_u,     = self.ax2.plot([], [], lw=1.5, c='orange')\n",
    "        self.line_rate,  = self.ax3.plot([], [], lw=1.5, c='green', label=\"Raw Rate\")\n",
    "        self.line_acc,   = self.ax4.plot([], [], lw=0.5, c='gray', alpha=0.5, label=\"Raw Acc\")\n",
    "\n",
    "        self._style_ax(self.ax1, \"Pitch (rad)\", -3.5, 3.5)\n",
    "        self._style_ax(self.ax2, \"Throttle\", -1.1, 1.1)\n",
    "        self._style_ax(self.ax3, \"Rate (rad/s)\", -10.0, 10.0)\n",
    "        self._style_ax(self.ax4, \"Acc (m/s^2)\", -20.0, 20.0)\n",
    "\n",
    "        self.ax1.axhline(math.pi, c='g', ls=':', alpha=0.6)\n",
    "        self.ax1.axhline(-math.pi, c='g', ls=':', alpha=0.6)\n",
    "\n",
    "        plt.show(block=False)\n",
    "        self.last_time = time.perf_counter()\n",
    "\n",
    "    def _style_ax(self, ax, label, ymin, ymax):\n",
    "        ax.set_ylabel(label); ax.set_ylim(ymin, ymax); ax.grid(True, alpha=0.5)\n",
    "\n",
    "    def update(self, t, pitch, u, rate, acc):\n",
    "        now = time.perf_counter()\n",
    "        if now - self.last_time < (1.0 / Config.REFRESH_HZ): return True\n",
    "        try:\n",
    "            self.line_pitch.set_data(t, pitch)\n",
    "            self.line_u.set_data(t, u)\n",
    "            self.line_rate.set_data(t, rate)\n",
    "            self.line_acc.set_data(t, acc)\n",
    "            curr_t = t[-1] if t else 0\n",
    "            self.ax1.set_xlim(max(0, curr_t - 10), curr_t + 0.2)\n",
    "            self.fig.canvas.draw(); self.fig.canvas.flush_events()\n",
    "            self.last_time = now\n",
    "            return True\n",
    "        except: return False\n",
    "\n",
    "    def close(self): plt.ioff(); plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN EXECUTION (Collect Raw -> Filter Later)\n",
    "# ==========================================\n",
    "m = mj.MjModel.from_xml_path(Config.XML_PATH)\n",
    "data = mj.MjData(m)\n",
    "mj.mj_resetData(m, data); mj.mj_forward(m, data)\n",
    "\n",
    "gyro_id = mj.mj_name2id(m, mj.mjtObj.mjOBJ_SENSOR, \"imu_gyro\")\n",
    "acc_id  = mj.mj_name2id(m, mj.mjtObj.mjOBJ_SENSOR, \"imu_acc\")\n",
    "gyro_adr = m.sensor_adr[gyro_id] if gyro_id >= 0 else 0\n",
    "acc_adr  = m.sensor_adr[acc_id] if acc_id >= 0 else 0\n",
    "qadr     = m.jnt_qposadr[next(j for j in range(m.njnt) if m.jnt_type[j] == mj.mjtJoint.mjJNT_FREE)] + 3\n",
    "sim_dt   = m.opt.timestep\n",
    "\n",
    "plotter = LivePlotter()\n",
    "logs = {'t':[], 'pitch':[], 'u':[], 'rate':[], 'acc':[]}\n",
    "\n",
    "t0_sim = data.time\n",
    "t0_wall = time.perf_counter()\n",
    "next_cmd = t0_sim\n",
    "prev_pitch = None\n",
    "\n",
    "print(\">>> Recording RAW data... (Offline filter applied after)\")\n",
    "\n",
    "with viewer.launch_passive(m, data) as v:\n",
    "    while data.time - t0_sim < Config.DURATION:\n",
    "\n",
    "        if data.time >= next_cmd:\n",
    "            data.ctrl[:] = float(np.random.uniform(-1.0, 1.0))\n",
    "            next_cmd += Config.CTRL_DT\n",
    "\n",
    "        mj.mj_step(m, data)\n",
    "\n",
    "        # 1. Sensing (RAW)\n",
    "        qw, qx, qy, qz = data.qpos[qadr:qadr+4]\n",
    "        pitch = MathUtils.get_flip_pitch(qw, qx, qy, qz)\n",
    "\n",
    "        if gyro_id >= 0: raw_rate = float(data.sensordata[gyro_adr + 1])\n",
    "        else: raw_rate = MathUtils.angdiff(pitch, prev_pitch)/sim_dt if prev_pitch else 0.0\n",
    "\n",
    "        raw_acc = float(data.sensordata[acc_adr + 0]) if acc_id >= 0 else 0.0\n",
    "        prev_pitch = pitch\n",
    "\n",
    "        # 2. Log Raw\n",
    "        t_rel = data.time - t0_sim\n",
    "        logs['t'].append(t_rel)\n",
    "        logs['pitch'].append(pitch)\n",
    "        logs['u'].append(data.ctrl[0])\n",
    "        logs['rate'].append(raw_rate)\n",
    "        logs['acc'].append(raw_acc)\n",
    "\n",
    "        # 3. Plot Raw (Just to monitor)\n",
    "        if not plotter.update(logs['t'], logs['pitch'], logs['u'], logs['rate'], logs['acc']):\n",
    "            break\n",
    "\n",
    "        rt_target = t0_wall + (data.time - t0_sim) / Config.RTF\n",
    "        sleep_needed = rt_target - time.perf_counter()\n",
    "        if sleep_needed > 0: time.sleep(min(sleep_needed, 0.01))\n",
    "        v.sync()\n",
    "\n",
    "plotter.close()\n",
    "print(f\"\\n>>> Collection Finished. Raw Samples: {len(logs['t'])}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. OFFLINE FILTERING (The User's Logic)\n",
    "# ==========================================\n",
    "print(\"\\n>>> Applying Offline Zero-Phase Filter...\")\n",
    "\n",
    "# Convert lists to arrays\n",
    "t_arr = np.array(logs['t'])\n",
    "acc_raw = np.array(logs['acc'])\n",
    "rate_raw = np.array(logs['rate'])\n",
    "\n",
    "# Calculate average dt from the logs\n",
    "dt_avg = np.mean(np.diff(t_arr))\n",
    "\n",
    "# --- APPLY YOUR FUNCTION HERE ---\n",
    "acc_filtered = lowpass_offline(acc_raw, dt_avg, cutoff_hz=5.0, order=2)\n",
    "# We also filter rate slightly to match the smoothness\n",
    "rate_filtered = lowpass_offline(rate_raw, dt_avg, cutoff_hz=10.0, order=2)\n",
    "\n",
    "# Update logs with clean data for binning\n",
    "logs['acc']  = acc_filtered\n",
    "logs['rate'] = rate_filtered\n",
    "\n",
    "print(\">>> Filtering Complete. No Phase Lag!\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. POST-PROCESSING (Binning with Clean Data)\n",
    "# ==========================================\n",
    "print(\"\\n>>> Applying Binning / Rejection Sampling...\")\n",
    "\n",
    "occupancy = np.zeros((Config.N_BINS_PHI, Config.N_BINS_OMEGA), dtype=np.int32)\n",
    "X_filtered, Y_filtered = [], []\n",
    "\n",
    "phi_min, phi_max = -math.pi, math.pi\n",
    "om_min, om_max   = -Config.OMEGA_RANGE, Config.OMEGA_RANGE\n",
    "\n",
    "saved_count = 0\n",
    "extreme_count = 0\n",
    "\n",
    "for i in range(len(logs['t']) - 1):\n",
    "    # Current State (Now using Zero-Phase Filtered Data)\n",
    "    curr_phi = logs['pitch'][i]\n",
    "    curr_om  = logs['rate'][i]\n",
    "    curr_acc = logs['acc'][i]\n",
    "\n",
    "    # Targets\n",
    "    d_phi = MathUtils.angdiff(logs['pitch'][i+1], curr_phi)\n",
    "    d_om  = logs['rate'][i+1] - curr_om\n",
    "\n",
    "    # Outlier Check\n",
    "    if (curr_om < om_min) or (curr_om > om_max):\n",
    "        X_filtered.append([curr_phi, curr_om, curr_acc])\n",
    "        Y_filtered.append([d_phi, d_om])\n",
    "        extreme_count += 1\n",
    "        continue\n",
    "\n",
    "    # Binning\n",
    "    p_norm = (curr_phi - phi_min) / (phi_max - phi_min)\n",
    "    o_norm = (curr_om - om_min) / (om_max - om_min)\n",
    "    idx_p = max(0, min(Config.N_BINS_PHI - 1, int(p_norm * (Config.N_BINS_PHI - 1))))\n",
    "    idx_o = max(0, min(Config.N_BINS_OMEGA - 1, int(o_norm * (Config.N_BINS_OMEGA - 1))))\n",
    "\n",
    "    if occupancy[idx_p, idx_o] < Config.MAX_SAMPLES:\n",
    "        occupancy[idx_p, idx_o] += 1\n",
    "        X_filtered.append([curr_phi, curr_om, curr_acc])\n",
    "        Y_filtered.append([d_phi, d_om])\n",
    "        saved_count += 1\n",
    "\n",
    "X = np.array(X_filtered)\n",
    "Y = np.array(Y_filtered)\n",
    "\n",
    "# --- DETAILED STATS (Restored) ---\n",
    "unique_bins = np.count_nonzero(occupancy)\n",
    "total_bins = Config.N_BINS_PHI * Config.N_BINS_OMEGA\n",
    "num_steps = len(logs['t'])\n",
    "\n",
    "print(f\"------------------------------------------------\")\n",
    "print(f\"Raw Data Points:    {num_steps}\")\n",
    "print(f\"Filtered Data (X):  {X.shape[0]} (Saved)\")\n",
    "print(f\"Rejection Ratio:    {(1 - (X.shape[0]/num_steps))*100:.1f}% rejected\")\n",
    "print(f\"Extreme Speed Pts:  {extreme_count} (Saved automatically)\")\n",
    "print(f\"Unique Bins Filled: {unique_bins} / {total_bins}\")\n",
    "print(f\"------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- ORIGINAL VISUALIZATION (Restored) ---\n",
    "plt.ioff() # Turn off interactive mode so this plot stays open\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig.canvas.manager.set_window_title(\"Data Distribution Analysis\")\n",
    "\n",
    "# Plot 1: Heatmap (The Bins)\n",
    "\n",
    "img = ax1.imshow(occupancy.T, origin='lower', aspect='auto',\n",
    "                 extent=[phi_min, phi_max, om_min, om_max], cmap='viridis')\n",
    "ax1.set_title(f\"Bin Occupancy (Max {Config.MAX_SAMPLES})\")\n",
    "ax1.set_xlabel(\"Pitch (rad)\")\n",
    "ax1.set_ylabel(\"Rate (rad/s)\")\n",
    "plt.colorbar(img, ax=ax1, label=\"Count\")\n",
    "\n",
    "# Plot 2: Scatter (The Saved Points)\n",
    "ax2.scatter(X[:, 0], X[:, 1], s=2, alpha=0.3, c='blue', label='Saved Data')\n",
    "\n",
    "# Draw the \"Binning Box\" to see where the grid ends\n",
    "ax2.vlines([phi_min, phi_max], om_min, om_max, colors='red', linestyles='--')\n",
    "ax2.hlines([om_min, om_max], phi_min, phi_max, colors='red', linestyles='--', label='Grid Limit')\n",
    "\n",
    "ax2.set_title(f\"Saved Points (Includes Extreme Speeds: {extreme_count})\")\n",
    "ax2.set_xlabel(\"Pitch (rad)\")\n",
    "ax2.set_ylabel(\"Rate (rad/s)\")\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Recording RAW data... (Offline filter applied after)\n",
      "\n",
      ">>> Collection Finished. Raw Samples: 100000\n",
      "\n",
      ">>> Applying Offline Zero-Phase Filter...\n",
      ">>> Filtering Complete. No Phase Lag!\n",
      "\n",
      ">>> Applying Binning / Rejection Sampling...\n",
      "------------------------------------------------\n",
      "Raw Data Points:    100000\n",
      "Filtered Data (X):  14786 (Saved)\n",
      "Rejection Ratio:    85.2% rejected\n",
      "Extreme Speed Pts:  0 (Saved automatically)\n",
      "Unique Bins Filled: 425 / 2500\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "f8b2ec71",
   "metadata": {},
   "source": [
    "# GAUSSIAN PROCESS DYNAMICS"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c94c628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T17:07:42.264444Z",
     "start_time": "2025-11-19T17:07:42.255443Z"
    }
   },
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# ---- Base Exact GP model -----------------------------------\n",
    "# ============================================================\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel='RBF', ard_dims=None):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "        # Kernel Choice\n",
    "        if kernel == 'RBF':\n",
    "            base_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=ard_dims)\n",
    "        elif kernel == 'Matern':\n",
    "            base_kernel = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=ard_dims)\n",
    "        elif kernel == 'RQ':\n",
    "            base_kernel = gpytorch.kernels.RQKernel(ard_num_dims=ard_dims)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported kernel type: {kernel}\")\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ---- Individual GP Manager: data + normalization -----------\n",
    "# ============================================================\n",
    "\n",
    "class GPManager:\n",
    "    def __init__(self, kernel='RBF', lr=0.05, iters=300, device=device):\n",
    "        self.kernel = kernel\n",
    "        self.lr = lr\n",
    "        self.iters = iters\n",
    "        self.device = device\n",
    "\n",
    "        self.trained = False\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "\n",
    "        self.likelihood = None\n",
    "        self.model = None\n",
    "\n",
    "    # ----------------------------- #\n",
    "    #        FIT / INITIAL TRAIN    #\n",
    "    # ----------------------------- #\n",
    "    def fit(self, X, Y):\n",
    "        # --- FIX 1: USE FLOAT64 (Double Precision) ---\n",
    "        X = torch.tensor(X, dtype=torch.float64, device=self.device)\n",
    "        Y = torch.tensor(Y, dtype=torch.float64, device=self.device).flatten()\n",
    "\n",
    "        self.X_train = X.clone()\n",
    "        self.Y_train = Y.clone()\n",
    "\n",
    "        self.retrain()\n",
    "\n",
    "    def retrain(self):\n",
    "        self._compute_normalization()\n",
    "        self._train_model()\n",
    "\n",
    "    def add_data(self, X_new, Y_new, retrain=True):\n",
    "        # --- FIX 1: USE FLOAT64 ---\n",
    "        X_new = torch.tensor(X_new, dtype=torch.float64, device=self.device)\n",
    "        Y_new = torch.tensor(Y_new, dtype=torch.float64, device=self.device).flatten()\n",
    "\n",
    "        if self.Y_train.ndim > 1:\n",
    "            self.Y_train = self.Y_train.flatten()\n",
    "\n",
    "        self.X_train = torch.cat([self.X_train, X_new], dim=0)\n",
    "        self.Y_train = torch.cat([self.Y_train, Y_new], dim=0)\n",
    "\n",
    "        if retrain:\n",
    "            self.retrain()\n",
    "\n",
    "    def _compute_normalization(self):\n",
    "        self.X_mean = self.X_train.mean(0)\n",
    "        self.X_std  = self.X_train.std(0)\n",
    "        self.X_std[self.X_std < 1e-6] = 1.0\n",
    "\n",
    "        self.Y_mean = self.Y_train.mean()\n",
    "        self.Y_std  = self.Y_train.std()\n",
    "\n",
    "        # Use tensor(1.0) with float64\n",
    "        if self.Y_std < 1e-6:\n",
    "            self.Y_std = torch.tensor(1.0, dtype=torch.float64, device=self.device)\n",
    "\n",
    "        self.Xn = (self.X_train - self.X_mean) / self.X_std\n",
    "        self.Yn = (self.Y_train - self.Y_mean) / self.Y_std\n",
    "\n",
    "    def _train_model(self):\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood().to(self.device)\n",
    "        # Initialize noise slightly higher for stability\n",
    "        self.likelihood.noise_covar.initialize(noise=1e-2)\n",
    "\n",
    "        self.model = ExactGPModel(\n",
    "            self.Xn, self.Yn, self.likelihood,\n",
    "            kernel=self.kernel,\n",
    "            ard_dims=self.X_train.shape[-1]\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Move model to float64\n",
    "        self.model.double()\n",
    "        self.likelihood.double()\n",
    "\n",
    "        self.train_gp(self.model, self.likelihood, self.Xn, self.Yn)\n",
    "        self.trained = True\n",
    "\n",
    "    def train_gp(self, model, likelihood, x, y):\n",
    "        model.train(); likelihood.train()\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        # --- FIX 2: STABILITY SETTINGS ---\n",
    "        # cholesky_jitter: Adds noise to diagonal to prevent crash\n",
    "        # max_cg_iterations: Gives solver more attempts\n",
    "        with gpytorch.settings.cholesky_jitter(1e-4), gpytorch.settings.max_cg_iterations(2000):\n",
    "            for i in range(self.iters):\n",
    "                opt.zero_grad()\n",
    "                out = model(x)\n",
    "                loss = -mll(out, y)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "        model.eval(); likelihood.eval()\n",
    "\n",
    "    def predict_torch(self, X):\n",
    "        if not self.trained:\n",
    "            raise RuntimeError(\"GP has not been trained yet.\")\n",
    "\n",
    "        # Ensure input is float64\n",
    "        X = torch.as_tensor(X, dtype=torch.float64, device=self.device)\n",
    "        Xn = (X - self.X_mean) / self.X_std\n",
    "\n",
    "        # Use fast prediction settings\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cholesky_jitter(1e-4):\n",
    "            pred = self.likelihood(self.model(Xn))\n",
    "            mean = pred.mean * self.Y_std + self.Y_mean\n",
    "            var  = pred.variance * (self.Y_std ** 2)\n",
    "\n",
    "        # Return as float32 for compatibility with other parts of your code (MPPI usually likes float32)\n",
    "        return mean.float(), var.float()"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "22b4e86e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T17:08:36.129101Z",
     "start_time": "2025-11-19T17:07:44.998093Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# ==============================================================\n",
    "# 1. PREPARE DATA\n",
    "# ==============================================================\n",
    "\n",
    "def lowpass_offline(acc, dt, cutoff_hz=5.0, order=2):\n",
    "    acc = np.asarray(acc, dtype=float)\n",
    "    if len(acc) < 10: return acc\n",
    "    fs = 1.0 / dt\n",
    "    wn = cutoff_hz / (fs / 2.0)\n",
    "    wn = min(max(wn, 1e-6), 0.999999)\n",
    "    b, a = butter(order, wn, btype='low')\n",
    "    return filtfilt(b, a, acc)\n",
    "\n",
    "# Extract Logs\n",
    "t_arr = np.array(logs['t'])\n",
    "u_arr = np.array(logs['u'])\n",
    "pitch_arr = np.array(logs['pitch'])\n",
    "rate_raw = np.array(logs['rate'])\n",
    "acc_raw  = np.array(logs['acc'])\n",
    "\n",
    "# Filter\n",
    "dt_avg = np.mean(np.diff(t_arr))\n",
    "acc_clean  = lowpass_offline(acc_raw, dt_avg, cutoff_hz=5.0)\n",
    "rate_clean = lowpass_offline(rate_raw, dt_avg, cutoff_hz=10.0)\n",
    "\n",
    "# ==============================================================\n",
    "# 2. BUILD DATASET (With Throttle!)\n",
    "# ==============================================================\n",
    "print(\"Building Dataset (X=[Pitch, Rate, Throttle] -> Y=[Rate, Acc])...\")\n",
    "\n",
    "N_BINS = 40\n",
    "MAX_SAMPLES = 20\n",
    "OMEGA_RANGE = 15.0\n",
    "occupancy = np.zeros((N_BINS, N_BINS), dtype=np.int32)\n",
    "\n",
    "X_list = []\n",
    "Y_list = []\n",
    "\n",
    "for i in range(len(t_arr) - 1):\n",
    "\n",
    "    # State Variables\n",
    "    p = pitch_arr[i]\n",
    "    r = rate_clean[i]\n",
    "    a = acc_clean[i]\n",
    "    u = u_arr[i]     # <--- We use this now\n",
    "\n",
    "    # --- DEFINITION OF X AND Y ---\n",
    "\n",
    "    # Input X: [Pitch, Rate, Throttle]\n",
    "    # This allows the model to learn f(state, action)\n",
    "    x_sample = [p, r, u]\n",
    "\n",
    "    # Target Y: [Rate (Velocity), Accel (Derivative of Rate)]\n",
    "    y_sample = [r, a]\n",
    "\n",
    "    # --- BINNING LOGIC ---\n",
    "\n",
    "    # 1. Outliers\n",
    "    if (r < -OMEGA_RANGE) or (r > OMEGA_RANGE):\n",
    "        X_list.append(x_sample)\n",
    "        Y_list.append(y_sample)\n",
    "        continue\n",
    "\n",
    "    # 2. Binning\n",
    "    p_norm = (p - (-np.pi)) / (2 * np.pi)\n",
    "    r_norm = (r - (-OMEGA_RANGE)) / (2 * OMEGA_RANGE)\n",
    "\n",
    "    idx_p = max(0, min(N_BINS - 1, int(p_norm * (N_BINS - 1))))\n",
    "    idx_r = max(0, min(N_BINS - 1, int(r_norm * (N_BINS - 1))))\n",
    "\n",
    "    if occupancy[idx_p, idx_r] < MAX_SAMPLES:\n",
    "        occupancy[idx_p, idx_r] += 1\n",
    "        X_list.append(x_sample)\n",
    "        Y_list.append(y_sample)\n",
    "\n",
    "# Convert\n",
    "X = np.array(X_list, dtype=np.float32)\n",
    "Y = np.array(Y_list, dtype=np.float32)\n",
    "\n",
    "print(f\"Data Processing Complete.\")\n",
    "print(f\"Selected Samples: {X.shape[0]}\")\n",
    "print(f\"X Shape: {X.shape} -> [Pitch, Rate, Throttle]\")\n",
    "print(f\"Y Shape: {Y.shape} -> [Rate, Accel]\")\n",
    "\n",
    "# ==============================================================\n",
    "# 3. TRAIN GPs\n",
    "# ==============================================================\n",
    "\n",
    "CHOSEN_KERNEL = 'RQ'\n",
    "\n",
    "print(f\"\\nTraining GPs with kernel: {CHOSEN_KERNEL}...\")\n",
    "\n",
    "# 1. Train Derivative 1 (Rate)\n",
    "print(\"--- Training GP for Output 1: Pitch Rate ---\")\n",
    "gp_rate = GPManager(kernel=CHOSEN_KERNEL, iters=300)\n",
    "gp_rate.fit(X, Y[:, 0]) # Target: Rate\n",
    "\n",
    "# 2. Train Derivative 2 (Acceleration)\n",
    "print(\"--- Training GP for Output 2: Pitch Acceleration ---\")\n",
    "gp_acc = GPManager(kernel=CHOSEN_KERNEL, iters=300)\n",
    "gp_acc.fit(X, Y[:, 1]) # Target: Accel\n",
    "\n",
    "print(\"\\n>>> Models Trained.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dataset (X=[Pitch, Rate, Throttle] -> Y=[Rate, Acc])...\n",
      "Data Processing Complete.\n",
      "Selected Samples: 1962\n",
      "X Shape: (1962, 3) -> [Pitch, Rate, Throttle]\n",
      "Y Shape: (1962, 2) -> [Rate, Accel]\n",
      "\n",
      "Training GPs with kernel: RQ...\n",
      "--- Training GP for Output 1: Pitch Rate ---\n",
      "--- Training GP for Output 2: Pitch Acceleration ---\n",
      "\n",
      ">>> Models Trained.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "655d94bf",
   "metadata": {},
   "source": [
    "# Visualize Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "102276b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T17:17:26.245723Z",
     "start_time": "2025-11-19T17:17:13.968863Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Use the Acceleration model (Torque dynamics)\n",
    "target_gp = gp_acc\n",
    "actions = [-1.0, 0.0, 1.0]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FIX: Access tensors directly instead of using .dataset()\n",
    "# ---------------------------------------------------------\n",
    "# 1. Get data from GPU/Torch -> CPU/Numpy\n",
    "X_train = target_gp.X_train.detach().cpu().numpy()\n",
    "Y_train = target_gp.Y_train.detach().cpu().numpy()\n",
    "\n",
    "pitch_data = X_train[:, 0]\n",
    "rate_data  = X_train[:, 1]\n",
    "act_data   = X_train[:, 2]\n",
    "acc_data   = Y_train\n",
    "\n",
    "# Create Grid for plotting\n",
    "p_grid = np.linspace(pitch_data.min(), pitch_data.max(), 60)\n",
    "r_grid = np.linspace(rate_data.min(), rate_data.max(), 60)\n",
    "P, R = np.meshgrid(p_grid, r_grid)\n",
    "\n",
    "for a in actions:\n",
    "    # Query: [Pitch, Rate, Fixed_Action]\n",
    "    X_query = np.column_stack([\n",
    "        P.ravel(),\n",
    "        R.ravel(),\n",
    "        np.full(P.size, a)\n",
    "    ])\n",
    "\n",
    "    # Predict\n",
    "    # Note: predict_torch expects float64 now, so we ensure the input matches\n",
    "    mean_t, var_t = target_gp.predict_torch(X_query)\n",
    "    Mean = mean_t.detach().cpu().numpy().reshape(P.shape)\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    surf = ax.plot_surface(P, R, Mean, cmap='viridis', alpha=0.8, edgecolor='none')\n",
    "\n",
    "    # Overlay data points near this action\n",
    "    # We use a small threshold to find points where throttle was close to 'a'\n",
    "    mask = np.abs(act_data - a) < 0.15\n",
    "\n",
    "    if np.sum(mask) > 0:\n",
    "        ax.scatter(\n",
    "            pitch_data[mask], rate_data[mask], acc_data[mask],\n",
    "            color='black', s=5, label=f'Data (u≈{a})'\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel('Pitch')\n",
    "    ax.set_ylabel('Rate')\n",
    "    ax.set_zlabel('Predicted Accel')\n",
    "    ax.set_title(f\"GP Dynamics Surface: Throttle = {a}\")\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10)\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "d42afee4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Choose which GP to visualize\n",
    "# --------------------------------------------------------\n",
    "gp = gps[1]   # e.g. GP for Δpitch_rate (index 0 would be Δpitch)\n",
    "a_fixed = 1.0 # fixed continuous action (maximum thrust)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Get training data (NumPy from dataset())\n",
    "# --------------------------------------------------------\n",
    "X_train, Y_train = gp.dataset()\n",
    "pitch, pitch_rate, act = X_train[:, 0], X_train[:, 1], X_train[:, 2]\n",
    "d_pitch_rate = Y_train  # targets for this GP\n",
    "\n",
    "# Select samples close to a = a_fixed for overlay\n",
    "mask = np.abs(act - a_fixed) < 0.5\n",
    "print(f\"Values near action a={a_fixed} → n={np.sum(mask)}\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Define pitch–pitch_rate grid\n",
    "# --------------------------------------------------------\n",
    "p_min, p_max = pitch.min(), pitch.max()\n",
    "v_min, v_max = pitch_rate.min(), pitch_rate.max()\n",
    "\n",
    "p_grid = np.linspace(p_min, p_max, 80)\n",
    "v_grid = np.linspace(v_min, v_max, 80)\n",
    "P, V = np.meshgrid(p_grid, v_grid)\n",
    "\n",
    "# Query points for the fixed action: [pitch, pitch_rate, a_fixed]\n",
    "X_grid = np.column_stack([\n",
    "    P.ravel(),                     # pitch\n",
    "    V.ravel(),                     # pitch_rate\n",
    "    np.full_like(P.ravel(), a_fixed)  # fixed action\n",
    "])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# GP predictions (torch -> numpy)\n",
    "# --------------------------------------------------------\n",
    "Mean_t, Var_t = gp.predict_torch(X_grid)   # torch tensors on GPU\n",
    "\n",
    "# move to CPU and numpy for plotting\n",
    "Mean = Mean_t.detach().cpu().numpy().reshape(P.shape)\n",
    "Var  = Var_t.detach().cpu().numpy().reshape(P.shape)\n",
    "Std  = np.sqrt(Var)\n",
    "\n",
    "# Normalize Std for color mapping\n",
    "norm = plt.Normalize(vmin=Std.min(), vmax=Std.max())\n",
    "colors = plt.cm.viridis(norm(Std))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Plot surface: Mean as height, Std as color\n",
    "# --------------------------------------------------------\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(\n",
    "    P, V, Mean,\n",
    "    facecolors=colors,\n",
    "    linewidth=0, antialiased=False, shade=False\n",
    ")\n",
    "\n",
    "# Colorbar = predictive uncertainty\n",
    "m = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "m.set_array(Std)\n",
    "cbar = fig.colorbar(m, ax=ax, shrink=0.6, aspect=10)\n",
    "cbar.set_label('GP Predictive Std (uncertainty)')\n",
    "\n",
    "# Overlay raw data (samples with similar a)\n",
    "ax.scatter(\n",
    "    pitch[mask], pitch_rate[mask], d_pitch_rate[mask],\n",
    "    color='k', s=15, alpha=0.6, label=f'training data (a≈{a_fixed})'\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Labels and title\n",
    "# --------------------------------------------------------\n",
    "ax.set_xlabel('Pitch')\n",
    "ax.set_ylabel('Pitch Rate')\n",
    "ax.set_zlabel('ΔPitch Rate')\n",
    "ax.set_title(f\"GP Model for Action a={a_fixed:.1f} — Mean Surface (height), Std (color)\")\n",
    "ax.view_init(elev=30, azim=230)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "347dab5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T17:19:14.388771Z",
     "start_time": "2025-11-19T17:19:03.255830Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Choose GP Model & Slice\n",
    "# --------------------------------------------------------\n",
    "# In previous cell, we named them gp_rate and gp_acc\n",
    "gp = gp_rate      # Predicting Pitch Rate (dPhi/dt)\n",
    "model_name = \"Pitch Rate\"\n",
    "\n",
    "v_fixed = 0.0     # Slice: Car is currently not rotating\n",
    "a_fixed = 1.0     # Slice: Full Throttle (+1.0)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Define Query Grid\n",
    "# --------------------------------------------------------\n",
    "p_min, p_max = -3.14, 3.14\n",
    "p_grid = np.linspace(p_min, p_max, 200)\n",
    "\n",
    "# Construct query: [Pitch, Rate_Fixed, Action_Fixed]\n",
    "X_query = np.column_stack([\n",
    "    p_grid,\n",
    "    np.full_like(p_grid, v_fixed),\n",
    "    np.full_like(p_grid, a_fixed)\n",
    "])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Predict (Torch -> Numpy)\n",
    "# --------------------------------------------------------\n",
    "# The predict_torch method handles the float64 conversion internally\n",
    "Mean_t, Var_t = gp.predict_torch(X_query)\n",
    "\n",
    "Mean = Mean_t.detach().cpu().numpy()\n",
    "Var  = Var_t.detach().cpu().numpy()\n",
    "Std  = np.sqrt(Var)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Get Training Data for Overlay\n",
    "# --------------------------------------------------------\n",
    "# FIX: Access data directly from tensors\n",
    "X_train = gp.X_train.detach().cpu().numpy()\n",
    "Y_train = gp.Y_train.detach().cpu().numpy()\n",
    "\n",
    "# Extract columns for masking\n",
    "data_pitch = X_train[:, 0]\n",
    "data_rate  = X_train[:, 1]\n",
    "data_act   = X_train[:, 2]\n",
    "data_y     = Y_train\n",
    "\n",
    "# Create mask to find data points \"near\" this slice\n",
    "# Rate within 0.5 rad/s, Action within 0.2 units\n",
    "mask = (np.abs(data_rate - v_fixed) < 0.5) & (np.abs(data_act - a_fixed) < 0.2)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5. Plot\n",
    "# --------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot GP Confidence Region\n",
    "plt.plot(p_grid, Mean, 'b-', lw=2, label=f'GP Mean {model_name}')\n",
    "plt.fill_between(\n",
    "    p_grid,\n",
    "    Mean - 2 * Std,\n",
    "    Mean + 2 * Std,\n",
    "    color='blue',\n",
    "    alpha=0.2,\n",
    "    label='±2σ Uncertainty'\n",
    ")\n",
    "\n",
    "# Plot Raw Data\n",
    "if np.sum(mask) > 0:\n",
    "    plt.scatter(\n",
    "        data_pitch[mask],\n",
    "        data_y[mask],\n",
    "        color='k', s=25, alpha=0.7,\n",
    "        label=f'Data (v≈{v_fixed}, u≈{a_fixed})'\n",
    "    )\n",
    "else:\n",
    "    print(\"No training data found near this slice to plot.\")\n",
    "\n",
    "plt.xlabel(\"Pitch Angle (rad)\")\n",
    "plt.ylabel(f\"Predicted {model_name} (rad/s)\")\n",
    "plt.title(f\"GP Slice: {model_name} vs Pitch\\n(Fixed Rate={v_fixed}, Fixed Throttle={a_fixed})\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "ea9b342b",
   "metadata": {},
   "source": [
    "# MPPI CONTROLLER"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GP step for the MuJoCo car (using your learned GP)",
   "id": "8c867af6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "473a4a45",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
